{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots \n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium.plugins import DualMap, HeatMap\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from dbfread import DBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dissimilarity function\n",
    "def dissimilarity(df):\n",
    "    dissimilarity_results = {}\n",
    "    for col in df.columns:\n",
    "        col_numerator = []\n",
    "        for i in range(df.shape[0]):\n",
    "            col_numerator.append((df.iloc[i,:].sum() / df.sum().sum()) *\n",
    "                                 np.abs((df.loc[i, col] / df.iloc[i,:].sum() - (df[col].sum() / df.sum().sum()))))\n",
    "        col_numerator = sum(col_numerator)\n",
    "        col_denominator = 2 * (df[col].sum() / df.sum().sum()) * (1 - (df[col].sum() / df.sum().sum()))\n",
    "        dissimilarity_results[col] = round(col_numerator / col_denominator, 3)\n",
    "\n",
    "        # print(f'dissimilarity {col} = {col_numerator/col_denominator}')\n",
    "    return dissimilarity_results              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "# defining simpson function\n",
    "\n",
    "def simpson(df):\n",
    "    simpson_series = []\n",
    "    for i in range(df.shape[0]):\n",
    "        area_ethnic_fraction_2 = []\n",
    "        for col in df.columns:\n",
    "            if col != 'other':\n",
    "                area_ethnic_fraction_2.append((df.loc[i,col]/(df.iloc[i,:].sum()))**2)\n",
    "        sum_area_ethnic_fraction_2 = sum(area_ethnic_fraction_2)\n",
    "        simpson_series.append(sum_area_ethnic_fraction_2)\n",
    "        \n",
    "    simpson_series = pd.Series(simpson_series)\n",
    "    simpson_index = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        simpson_index += (simpson_series.iloc[i] * df.iloc[i, :].sum() / df.sum().sum())\n",
    "    \n",
    "    area_simpson = []\n",
    "    for col in df.columns:\n",
    "        if col != 'other':\n",
    "            area_simpson.append((df[col].sum()/df.sum().sum())**2)\n",
    "    area_simpson_index = sum(area_simpson)\n",
    "    simpson_index = round(simpson_index, 3)\n",
    "    area_simpson_index = round(area_simpson_index, 3)\n",
    "    return [simpson_index, area_simpson_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining moran I function\n",
    "\n",
    "def moran(df,border):\n",
    "    positive_weights = []\n",
    "    for key in border.keys():\n",
    "        positive_weights.append(len(border[key]))\n",
    "       \n",
    "    fraction = {}\n",
    "    for col in df.columns:\n",
    "        # df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        fraction[col] = []\n",
    "        for i in df.index:\n",
    "            fraction[col].append(df.loc[i, col] / df.loc[i, :].sum())\n",
    "    \n",
    "    col_moran = {} \n",
    "    for col in df.columns:\n",
    "        col_moran_list = []\n",
    "        for i in df.index:\n",
    "            morani = []\n",
    "            for common in border[i]:    \n",
    "                morani.append(((df.loc[i, col] / df.loc[i, :].sum()) - np.mean(fraction[col])) * ((df.loc[common, col] / df.loc[common, :].sum()) - np.mean(fraction[col])))\n",
    "            row_moran = sum(morani)\n",
    "            col_moran_list.append(row_moran)\n",
    "        col_moran[col] = col_moran_list\n",
    "    moran_results= {}\n",
    "    for col in df.columns:\n",
    "        moran_numerator = sum(col_moran[col])*df.shape[0]\n",
    "        moran_denominator = sum((fraction[col] - np.mean(fraction[col]))**2)*sum(positive_weights)\n",
    "        # moran_index = moran_numerator/moran_denominator\n",
    "        moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
    "    return moran_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2011 = pd.read_csv('Census2011\\\\census2011.csv', encoding= 'latin1', delimiter= ',', skiprows= 7, skipfooter= 8, engine= 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011 output area</th>\n",
       "      <th>White: English/Welsh/Scottish/Northern Irish/British</th>\n",
       "      <th>White: Irish</th>\n",
       "      <th>White: Gypsy or Irish Traveller</th>\n",
       "      <th>White: Other White</th>\n",
       "      <th>Mixed/multiple ethnic groups: White and Black Caribbean</th>\n",
       "      <th>Mixed/multiple ethnic groups: White and Black African</th>\n",
       "      <th>Mixed/multiple ethnic groups: White and Asian</th>\n",
       "      <th>Mixed/multiple ethnic groups: Other Mixed</th>\n",
       "      <th>Asian/Asian British: Indian</th>\n",
       "      <th>Asian/Asian British: Pakistani</th>\n",
       "      <th>Asian/Asian British: Bangladeshi</th>\n",
       "      <th>Asian/Asian British: Chinese</th>\n",
       "      <th>Asian/Asian British: Other Asian</th>\n",
       "      <th>Black/African/Caribbean/Black British: African</th>\n",
       "      <th>Black/African/Caribbean/Black British: Caribbean</th>\n",
       "      <th>Black/African/Caribbean/Black British: Other Black</th>\n",
       "      <th>Other ethnic group: Arab</th>\n",
       "      <th>Other ethnic group: Any other ethnic group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>254</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2011 output area  White: English/Welsh/Scottish/Northern Irish/British  \\\n",
       "0        E00000001                                                150      \n",
       "1        E00000003                                                177      \n",
       "2        E00000005                                                254      \n",
       "3        E00000007                                                 55      \n",
       "4        E00000010                                                 62      \n",
       "\n",
       "   White: Irish  White: Gypsy or Irish Traveller  White: Other White  \\\n",
       "0             7                                0                  18   \n",
       "1             2                                1                  26   \n",
       "2            14                                0                  53   \n",
       "3             0                                0                  40   \n",
       "4             3                                0                  15   \n",
       "\n",
       "   Mixed/multiple ethnic groups: White and Black Caribbean  \\\n",
       "0                                                  3         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   Mixed/multiple ethnic groups: White and Black African  \\\n",
       "0                                                  0       \n",
       "1                                                  1       \n",
       "2                                                  2       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "   Mixed/multiple ethnic groups: White and Asian  \\\n",
       "0                                              4   \n",
       "1                                              7   \n",
       "2                                              5   \n",
       "3                                              2   \n",
       "4                                              1   \n",
       "\n",
       "   Mixed/multiple ethnic groups: Other Mixed  Asian/Asian British: Indian  \\\n",
       "0                                          3                            2   \n",
       "1                                          1                           17   \n",
       "2                                          5                            9   \n",
       "3                                          0                            4   \n",
       "4                                          2                            2   \n",
       "\n",
       "   Asian/Asian British: Pakistani  Asian/Asian British: Bangladeshi  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 3   \n",
       "2                               1                                 0   \n",
       "3                               2                                 0   \n",
       "4                               1                                 3   \n",
       "\n",
       "   Asian/Asian British: Chinese  Asian/Asian British: Other Asian  \\\n",
       "0                             4                                 0   \n",
       "1                             3                                 3   \n",
       "2                            10                                 5   \n",
       "3                            10                                 4   \n",
       "4                             5                                 1   \n",
       "\n",
       "   Black/African/Caribbean/Black British: African  \\\n",
       "0                                               0   \n",
       "1                                               3   \n",
       "2                                               2   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   Black/African/Caribbean/Black British: Caribbean  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 4   \n",
       "\n",
       "   Black/African/Caribbean/Black British: Other Black  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  2    \n",
       "3                                                  0    \n",
       "4                                                  1    \n",
       "\n",
       "   Other ethnic group: Arab  Other ethnic group: Any other ethnic group  \n",
       "0                         0                                           3  \n",
       "1                         0                                           6  \n",
       "2                         0                                           5  \n",
       "3                         0                                           6  \n",
       "4                         2                                           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181408, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2011.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011 output area</th>\n",
       "      <th>Ethnic group</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>White: English/Welsh/Scottish/Northern Irish/B...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>White: English/Welsh/Scottish/Northern Irish/B...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>White: English/Welsh/Scottish/Northern Irish/B...</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>White: English/Welsh/Scottish/Northern Irish/B...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>White: English/Welsh/Scottish/Northern Irish/B...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2011 output area                                       Ethnic group  \\\n",
       "0        E00000001  White: English/Welsh/Scottish/Northern Irish/B...   \n",
       "1        E00000003  White: English/Welsh/Scottish/Northern Irish/B...   \n",
       "2        E00000005  White: English/Welsh/Scottish/Northern Irish/B...   \n",
       "3        E00000007  White: English/Welsh/Scottish/Northern Irish/B...   \n",
       "4        E00000010  White: English/Welsh/Scottish/Northern Irish/B...   \n",
       "\n",
       "   Observation  \n",
       "0          150  \n",
       "1          177  \n",
       "2          254  \n",
       "3           55  \n",
       "4           62  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011 = data_2011.melt(id_vars=['2011 output area'], value_vars= data_2011.columns[1:], \n",
    "                           var_name='Ethnic group', value_name='Observation')\n",
    "melt_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White: English/Welsh/Scottish/Northern Irish/British',\n",
       "       'White: Irish', 'White: Gypsy or Irish Traveller',\n",
       "       'White: Other White',\n",
       "       'Mixed/multiple ethnic groups: White and Black Caribbean',\n",
       "       'Mixed/multiple ethnic groups: White and Black African',\n",
       "       'Mixed/multiple ethnic groups: White and Asian',\n",
       "       'Mixed/multiple ethnic groups: Other Mixed',\n",
       "       'Asian/Asian British: Indian', 'Asian/Asian British: Pakistani',\n",
       "       'Asian/Asian British: Bangladeshi', 'Asian/Asian British: Chinese',\n",
       "       'Asian/Asian British: Other Asian',\n",
       "       'Black/African/Caribbean/Black British: African',\n",
       "       'Black/African/Caribbean/Black British: Caribbean',\n",
       "       'Black/African/Caribbean/Black British: Other Black',\n",
       "       'Other ethnic group: Arab',\n",
       "       'Other ethnic group: Any other ethnic group'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011['Ethnic group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011 output area</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>150</td>\n",
       "      <td>White</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>177</td>\n",
       "      <td>White</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>254</td>\n",
       "      <td>White</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>55</td>\n",
       "      <td>White</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>62</td>\n",
       "      <td>White</td>\n",
       "      <td>English/Welsh/Scottish/Northern Irish/British</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2011 output area  Observation ethnicity  \\\n",
       "0        E00000001          150     White   \n",
       "1        E00000003          177     White   \n",
       "2        E00000005          254     White   \n",
       "3        E00000007           55     White   \n",
       "4        E00000010           62     White   \n",
       "\n",
       "                                    sub_ethnicity  \n",
       "0   English/Welsh/Scottish/Northern Irish/British  \n",
       "1   English/Welsh/Scottish/Northern Irish/British  \n",
       "2   English/Welsh/Scottish/Northern Irish/British  \n",
       "3   English/Welsh/Scottish/Northern Irish/British  \n",
       "4   English/Welsh/Scottish/Northern Irish/British  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011['ethnicity'] = melt_2011['Ethnic group'].apply( lambda x: x.split(':')[0])\n",
    "melt_2011['sub_ethnicity'] = melt_2011['Ethnic group'].apply( lambda x: x.split(':')[1])\n",
    "melt_2011.drop('Ethnic group', axis= 1, inplace= True)\n",
    "melt_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56075912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011['Observation'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Mixed/multiple ethnic groups', 'Asian/Asian British',\n",
       "       'Black/African/Caribbean/Black British', 'Other ethnic group'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_2011['ethnicity'] = melt_2011['ethnicity'].apply(lambda x: 'white' if 'White' in x else\n",
    "                                                                'asian' if 'Asian' in x else \n",
    "                                                                'black' if 'Black' in x else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_2011['sub_ethnicity'] = melt_2011['sub_ethnicity'].apply(lambda x: 'British' if '/British' in x else\n",
    "                                                                        'Irish' if 'Irish' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_2011['sub_ethnicity']= melt_2011['sub_ethnicity'].apply(str.lstrip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011 output area</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>150</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>177</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>254</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>55</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>62</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2011 output area  Observation ethnicity sub_ethnicity\n",
       "0        E00000001          150     white       British\n",
       "1        E00000003          177     white       British\n",
       "2        E00000005          254     white       British\n",
       "3        E00000007           55     white       British\n",
       "4        E00000010           62     white       British"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>LAD11NMW</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA11CD   LSOA11CD             LSOA11NM   MSOA11CD            MSOA11NM  \\\n",
       "0  E00000001  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "1  E00000003  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "2  E00000005  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "3  E00000007  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "4  E00000010  E01000003  City of London 001C  E02000001  City of London 001   \n",
       "\n",
       "     LAD11CD         LAD11NM LAD11NMW  ObjectId  \n",
       "0  E09000001  City of London      NaN         1  \n",
       "1  E09000001  City of London      NaN         2  \n",
       "2  E09000001  City of London      NaN         3  \n",
       "3  E09000001  City of London      NaN         4  \n",
       "4  E09000001  City of London      NaN         5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_2011= pd.read_csv('Census2011\\\\lookup2011.csv', low_memory= False)\n",
    "lookup_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011 output area</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>LAD11NMW</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>150</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>177</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>254</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>E00000005</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2011 output area  Observation ethnicity sub_ethnicity     OA11CD   LSOA11CD  \\\n",
       "0        E00000001          150     white       British  E00000001  E01000001   \n",
       "1        E00000003          177     white       British  E00000003  E01000001   \n",
       "2        E00000005          254     white       British  E00000005  E01000001   \n",
       "\n",
       "              LSOA11NM   MSOA11CD            MSOA11NM    LAD11CD  \\\n",
       "0  City of London 001A  E02000001  City of London 001  E09000001   \n",
       "1  City of London 001A  E02000001  City of London 001  E09000001   \n",
       "2  City of London 001A  E02000001  City of London 001  E09000001   \n",
       "\n",
       "          LAD11NM LAD11NMW  ObjectId  \n",
       "0  City of London      NaN         1  \n",
       "1  City of London      NaN         2  \n",
       "2  City of London      NaN         3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2011 = pd.merge(melt_2011, lookup_2011, left_on= '2011 output area', right_on= 'OA11CD', how= 'left')\n",
    "merged_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA11CD   LSOA11CD   MSOA11CD    LAD11CD             LSOA11NM  \\\n",
       "0  E00000001  E01000001  E02000001  E09000001  City of London 001A   \n",
       "1  E00000003  E01000001  E02000001  E09000001  City of London 001A   \n",
       "2  E00000005  E01000001  E02000001  E09000001  City of London 001A   \n",
       "3  E00000007  E01000001  E02000001  E09000001  City of London 001A   \n",
       "4  E00000010  E01000003  E02000001  E09000001  City of London 001C   \n",
       "\n",
       "             MSOA11NM         LAD11NM ethnicity sub_ethnicity  Observation  \n",
       "0  City of London 001  City of London     white       British          150  \n",
       "1  City of London 001  City of London     white       British          177  \n",
       "2  City of London 001  City of London     white       British          254  \n",
       "3  City of London 001  City of London     white       British           55  \n",
       "4  City of London 001  City of London     white       British           62  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_order = ['OA11CD', 'LSOA11CD', 'MSOA11CD', 'LAD11CD', 'LSOA11NM',  \n",
    "                'MSOA11NM', 'LAD11NM', 'ethnicity', 'sub_ethnicity', 'Observation']\n",
    "merged_2011 = merged_2011[column_order]\n",
    "# merged_2011.rename(columns={'2011 output area':'OA11CD'}, inplace= True)\n",
    "merged_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['British', 'Irish', 'Other White', 'White and Black Caribbean',\n",
       "       'White and Black African', 'White and Asian', 'Other Mixed',\n",
       "       'Indian', 'Pakistani', 'Bangladeshi', 'Chinese', 'Other Asian',\n",
       "       'African', 'Caribbean', 'Other Black', 'Arab',\n",
       "       'Any other ethnic group'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2011['sub_ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181408"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2011['OA11CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34753"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2011['LSOA11CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7201"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2011['MSOA11CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2011['LAD11CD'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>asian</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>other</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA11CD   LSOA11CD   MSOA11CD    LAD11CD             LSOA11NM  \\\n",
       "0  E00000001  E01000001  E02000001  E09000001  City of London 001A   \n",
       "1  E00000001  E01000001  E02000001  E09000001  City of London 001A   \n",
       "2  E00000001  E01000001  E02000001  E09000001  City of London 001A   \n",
       "\n",
       "             MSOA11NM         LAD11NM ethnicity  Observation  \n",
       "0  City of London 001  City of London     asian            6  \n",
       "1  City of London 001  City of London     black            0  \n",
       "2  City of London 001  City of London     other           13  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2011 = merged_2011.groupby(['OA11CD','LSOA11CD', 'MSOA11CD', 'LAD11CD', 'LSOA11NM', 'MSOA11NM', 'LAD11NM',\n",
    "                                      'ethnicity'])['Observation'].sum().reset_index()\n",
    "ethnicity_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>175</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>206</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>321</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA11CD   LSOA11CD   MSOA11CD    LAD11CD             LSOA11NM  \\\n",
       "0  E00000001  E01000001  E02000001  E09000001  City of London 001A   \n",
       "1  E00000003  E01000001  E02000001  E09000001  City of London 001A   \n",
       "2  E00000005  E01000001  E02000001  E09000001  City of London 001A   \n",
       "\n",
       "             MSOA11NM         LAD11NM  asian  black  other  white  total_pop  \n",
       "0  City of London 001  City of London      6      0     13    175        194  \n",
       "1  City of London 001  City of London     26      3     15    206        250  \n",
       "2  City of London 001  City of London     25      4     17    321        367  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2011 = ethnicity_2011.pivot(index = ['OA11CD','LSOA11CD', 'MSOA11CD', 'LAD11CD', 'LSOA11NM', 'MSOA11NM', 'LAD11NM'], \n",
    "                                      columns = 'ethnicity', values = 'Observation').reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "ethnicity_2011['total_pop']= ethnicity_2011['white']+ethnicity_2011['asian']+ethnicity_2011['black']+ethnicity_2011['other']\n",
    "\n",
    "ethnicity_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181408, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2011.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56075912"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2011[['asian', 'black', 'other','white']].sum(axis= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.to_csv('preprocessed files/2011/ethnicity_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-Ethnicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2011 = merged_2011.groupby(['OA11CD','LSOA11CD', 'MSOA11CD', 'LAD11CD', 'LSOA11NM', 'MSOA11NM', 'LAD11NM',\n",
    "                                          'sub_ethnicity'])['Observation'].sum().reset_index()\n",
    "sub_ethnicity_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2011 = sub_ethnicity_2011.pivot(index = ['OA11CD','LSOA11CD', 'MSOA11CD', 'LAD11CD', 'LSOA11NM', 'MSOA11NM', 'LAD11NM'],\n",
    "                                              columns = 'sub_ethnicity', values = 'Observation').reset_index().rename_axis(None, axis=1)\n",
    "sub_ethnicity_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2011.to_csv('preprocessed files/2011/sub_ethnicity_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2011 = gpd.read_file('Census2011\\\\shape_2011\\\\OA_2011_EW_BGC_V2.shp')\n",
    "# shape_2011.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2011 = shape_2011.rename(columns={'geometry': 'OA_geometry'})\n",
    "shape_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2011 = shape_2011.merge(ethnicity_2011[['OA11CD', 'LSOA11CD', 'MSOA11CD', 'LAD11CD']], on = 'OA11CD', how= 'left')\n",
    "shape_column_order = ['OA11CD', 'LSOA11CD', 'MSOA11CD', 'LAD11CD_x', 'GlobalID', 'OA_geometry']\n",
    "shape_2011 = shape_2011[shape_column_order]\n",
    "shape_2011.rename(columns= {'LAD11CD_x': 'LAD11CD'}, inplace= True)\n",
    "shape_2011 = gpd.GeoDataFrame(shape_2011, geometry='OA_geometry')\n",
    "shape_2011.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving OA_2011 into a shape file\n",
    "shape_2011.to_file('preprocessed files/2011/OA_2011.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myshape = gpd.read_file('preprocessed files/2011/OA_2011.shp').set_geometry('geometry')\n",
    "myshape.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for LSOA geometry\n",
    "lsoa_geom_2011 = shape_2011.groupby('LSOA11CD')['OA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2011['LSOA_geometry'] = shape_2011['LSOA11CD'].map(lsoa_geom_2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving LSOA_2011 into a shape file\n",
    "LSOA_2011 = shape_2011.groupby('LSOA11CD').agg({'LSOA_geometry': 'first'}).reset_index()\n",
    "LSOA_2011 = LSOA_2011.merge(ethnicity_2011.groupby('LSOA11CD')[['asian', 'black', 'other', 'white']].sum().reset_index(), on='LSOA11CD' ,how= 'left')\n",
    "\n",
    "LSOA_2011['total'] = LSOA_2011['white'] + LSOA_2011['asian']+ LSOA_2011['black']+ LSOA_2011['other']\n",
    "\n",
    "for col in LSOA_2011[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    LSOA_2011[new_name] = round(LSOA_2011[col]/LSOA_2011['total'], 3)\n",
    "\n",
    "LSOA_2011['year'] = 2011\n",
    "LSOA_2011.rename(columns={'LSOA11CD':'LSOACD'}, inplace = True)\n",
    "column_order = ['year', 'LSOACD', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'total', 'LSOA_geometry']\n",
    "LSOA_2011 = LSOA_2011[column_order]\n",
    "\n",
    "\n",
    "LSOA_2011 = gpd.GeoDataFrame(LSOA_2011, geometry='LSOA_geometry')\n",
    "LSOA_2011.to_file('preprocessed files/2011/LSOA_2011.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_2011 = gpd.read_file('preprocessed files/2011/LSOA_2011.shp').set_geometry('geometry')\n",
    "LSOA_2011.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for MSOA geometry\n",
    "msoa_geom_2011 = shape_2011.groupby('MSOA11CD')['LSOA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2011['MSOA_geometry'] = shape_2011['MSOA11CD'].map(msoa_geom_2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving MSOA_2011 into a shape file\n",
    "MSOA_2011 = shape_2011.groupby('MSOA11CD').agg({'MSOA_geometry': 'first'}).reset_index()\n",
    "MSOA_2011 = MSOA_2011.merge(ethnicity_2011.groupby('MSOA11CD')[['asian', 'black', 'other', 'white']].sum().reset_index(), on='MSOA11CD' ,how= 'left')\n",
    "\n",
    "MSOA_2011['total'] = MSOA_2011['white'] + MSOA_2011['asian']+ MSOA_2011['black']+ MSOA_2011['other']\n",
    "\n",
    "for col in MSOA_2011[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    MSOA_2011[new_name] = round(MSOA_2011[col]/MSOA_2011['total'], 3)\n",
    "\n",
    "MSOA_2011['year'] = 2011\n",
    "MSOA_2011.rename(columns={'MSOA11CD':'MSOACD'}, inplace = True)\n",
    "column_order = ['year', 'MSOACD', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'total', 'MSOA_geometry']\n",
    "MSOA_2011 = MSOA_2011[column_order]\n",
    "\n",
    "MSOA_2011 = gpd.GeoDataFrame(MSOA_2011, geometry='MSOA_geometry')\n",
    "MSOA_2011.to_file('preprocessed files/2011/MSOA_2011.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_2011 = gpd.read_file('preprocessed files/2011/MSOA_2011.shp').set_geometry('geometry')\n",
    "MSOA_2011.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for LAD geometry\n",
    "lad_geom_2011 = shape_2011.groupby('LAD11CD')['MSOA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2011['LAD_geometry'] = shape_2011['LAD11CD'].map(lad_geom_2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order t have better and clearer borders of LAD, I took border info from another files and mixed it with LAD borders of 2021\n",
    "# For the LADs that geometry was unavailable in new_borders, I took LAD geopmetry from year 2011\n",
    "new_borders = gpd.read_file('May_2020_Boundaries/LAD_May_2020_Boundaries_UK_BFE_2022_4839426458879395509.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving LAD_2011 into a shape file\n",
    "LAD_2011 = shape_2011.groupby('LAD11CD').agg({'LAD_geometry': 'first'}).reset_index()\n",
    "LAD_2011 = LAD_2011.merge(ethnicity_2011.groupby(['LAD11CD','LAD11NM'])[['asian', 'black', 'other', 'white']].sum().reset_index(), on='LAD11CD' ,how= 'left')\n",
    "LAD_2011['LAD_pop'] = LAD_2011['white'] + LAD_2011['asian']+ LAD_2011['black']+ LAD_2011['other']\n",
    "\n",
    "for col in LAD_2011[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    LAD_2011[new_name] = round(LAD_2011[col]/LAD_2011['LAD_pop'], 3)\n",
    "\n",
    "LAD_2011['year'] = 2011\n",
    "LAD_2011.rename(columns={'LAD11CD':'LADCD', 'LAD11NM':'LADNM'}, inplace = True)\n",
    "column_order = ['year', 'LADCD', 'LADNM', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'LAD_pop', 'LAD_geometry']\n",
    "LAD_2011 = LAD_2011[column_order]\n",
    "\n",
    "LAD_2011 =  pd.merge(LAD_2011, new_borders[['lad20nm', 'geometry']], left_on= 'LADNM',right_on='lad20nm', how= 'left')\n",
    "\n",
    "LAD_2011['geometry']= LAD_2011['geometry'].fillna(LAD_2011['LAD_geometry'])\n",
    "LAD_2011.drop(columns=['LAD_geometry','lad20nm'], axis= 1, inplace= True)\n",
    "LAD_2011.rename(columns={'geometry':'LAD_geometry'}, inplace= True)\n",
    "LAD_2011 = gpd.GeoDataFrame(LAD_2011, geometry='LAD_geometry')\n",
    "LAD_2011.to_file('preprocessed files/2011/LAD_2011.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2011 = gpd.read_file('preprocessed files/2011/LAD_2011.shp').set_geometry('geometry')\n",
    "LAD_2011.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# Simpson Index at coutry level in 2011\n",
    "OA_simp_2011 = simpson(ethnicity_2011[['white','asian','black','other']])\n",
    "LSOA_simp_2011 = simpson(ethnicity_2011.groupby(['LSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_simp_2011 = simpson(ethnicity_2011.groupby(['MSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_simp_2011 = simpson(ethnicity_2011.groupby(['LAD11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "\n",
    "country_dic_sim_2011 = {'OA':OA_simp_2011[0], 'LSOA':LSOA_simp_2011[0],\n",
    "                        'MSOA':MSOA_simp_2011[0], 'LAD':LAD_simp_2011[0], 'country':LAD_simp_2011[1]}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'total_population': ethnicity_2011['total_pop'].sum(),\n",
    "              'white_frac': round(ethnicity_2011['white'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'asian_frac': round(ethnicity_2011['asian'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'black_frac': round(ethnicity_2011['black'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'other_frac': round(ethnicity_2011['other'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'OA':OA_simp_2011[0], 'LSOA':LSOA_simp_2011[0],'MSOA':MSOA_simp_2011[0], 'LAD':LAD_simp_2011[0], 'country':LAD_simp_2011[1]}]\n",
    "\n",
    "country_simpson_2011 = pd.DataFrame(flat_dict)\n",
    "country_simpson_2011.to_csv('preprocessed files/2011/country_simpson_2011.csv', index= False)\n",
    "country_simpson_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# Creating LAD level simpson index dataset for year 2011.\n",
    "# Calculating OA, LSOA and MSOA level simpson index inside each LAD\n",
    "LAD_list_2011= ethnicity_2011['LAD11CD'].unique()\n",
    "LAD_dic = {}\n",
    "for LAD in LAD_list_2011:\n",
    "    df = ethnicity_2011[ethnicity_2011['LAD11CD'] == LAD].reset_index(drop= True)\n",
    "    OA_LADsimp_2011 = simpson(df[['white','asian','black','other']])\n",
    "    LSOA_LADsimp_2011 = simpson(df.groupby(['LSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    MSOA_LADsimp_2011 = simpson(df.groupby(['MSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    LAD_dic[LAD] = {'OA':OA_LADsimp_2011, 'LSOA':LSOA_LADsimp_2011,'MSOA':MSOA_LADsimp_2011}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'LADCD': key, \n",
    "              'OA': value['OA'][0], 'LSOA': value['LSOA'][0],\n",
    "              'MSOA': value['MSOA'][0], 'LAD': value['MSOA'][1]} for key, value in LAD_dic.items()]\n",
    "\n",
    "LAD_simpson_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_simpson_2011 = LAD_simpson_2011.merge(\n",
    "                         LAD_2011.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "\n",
    "LAD_simpson_2011.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population',\n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac', \n",
    "                'OA', 'LSOA', 'MSOA', 'LAD']\n",
    "\n",
    "LAD_simpson_2011 = LAD_simpson_2011[column_order]\n",
    "LAD_simpson_2011.to_csv('preprocessed files/2011/LAD_simpson_2011.csv', index= False)\n",
    "LAD_simpson_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_borders_2011 = {}\n",
    "\n",
    "for idx, row in shape_2011.groupby('LAD11CD').agg({'LAD_geometry': 'first'}).iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in shape_2011.groupby('LAD11CD').agg({'LAD_geometry': 'first'}).iterrows():\n",
    "        if idx != idx2:\n",
    "            if row.LAD_geometry.intersects(row2.LAD_geometry):\n",
    "                borders.append(idx2)\n",
    "    LAD_borders_2011[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/LAD_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(LAD_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_borders_2011 = {}\n",
    "for lad_code in shape_2011['LAD11CD'].unique():\n",
    "    df_lad = shape_2011[shape_2011['LAD11CD'] == lad_code]\n",
    "    MSOA_borders_2011[lad_code] = {}\n",
    "    df_msoa =df_lad.groupby('MSOA11CD').agg({'MSOA_geometry': 'first'})\n",
    "    for idx, row in df_msoa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_msoa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['MSOA_geometry'].intersects(row2['MSOA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        MSOA_borders_2011[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/MSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(MSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LSOA_borders_2011 = {}\n",
    "df_lad = shape_2011[shape_2011['LAD11CD'] == 'E09000001']\n",
    "df_lsoa =df_lad.groupby('LSOA11CD').agg({'LSOA_geometry': 'first'})\n",
    "df_lsoa\n",
    "for idx, row in df_lsoa.iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in df_lsoa.iterrows():\n",
    "        if idx != idx2:\n",
    "            if row['LSOA_geometry'].intersects(row2['LSOA_geometry']):\n",
    "                borders.append(idx2)\n",
    "    LSOA_borders_2011[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2011['LSOA_geometry'] = shape_2011['LSOA_geometry'].buffer(0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_borders_2011 = {}\n",
    "for lad_code in shape_2011['LAD11CD'].unique():\n",
    "    df_lad = shape_2011[shape_2011['LAD11CD'] == lad_code]\n",
    "    LSOA_borders_2011[lad_code] = {}\n",
    "    df_lsoa =df_lad.groupby('LSOA11CD').agg({'LSOA_geometry': 'first'})\n",
    "    for idx, row in df_lsoa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_lsoa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['LSOA_geometry'].intersects(row2['LSOA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        LSOA_borders_2011[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_borders_2011 = {}\n",
    "for lad_code in shape_2011['LAD11CD'].unique():\n",
    "    df_lad = shape_2011[shape_2011['LAD11CD'] == lad_code]\n",
    "    OA_borders_2011[lad_code] = {}\n",
    "    df_oa = df_lad.set_index('OA11CD')\n",
    "    for idx, row in df_oa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_oa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['OA_geometry'].intersects(row2['OA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        OA_borders_2011[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating country level dissimilarity index dataset for year 2011.\n",
    "# Calculating OA, LSOA, MSOA and LAD level dissimilarity index inside england\n",
    "\n",
    "OA_diss_2011 = dissimilarity(ethnicity_2011[['white','asian','black','other']])\n",
    "LSOA_diss_2011 = dissimilarity(ethnicity_2011.groupby(['LSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_diss_2011 = dissimilarity(ethnicity_2011.groupby(['MSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_diss_2011 = dissimilarity(ethnicity_2011.groupby(['LAD11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "country_dic_diss_2011 = {'OA_level': OA_diss_2011, 'LSOA_level': LSOA_diss_2011,\n",
    "                        'MSOA_level': MSOA_diss_2011, 'LAD_level': LAD_diss_2011}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'total_population': ethnicity_2011['total_pop'].sum(),\n",
    "              'white_frac': round(ethnicity_2011['white'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'asian_frac': round(ethnicity_2011['asian'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'black_frac': round(ethnicity_2011['black'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'other_frac': round(ethnicity_2011['other'].sum()/ethnicity_2011['total_pop'].sum(),3),\n",
    "              'OA_white': country_dic_diss_2011['OA_level']['white'], 'LSOA_white': country_dic_diss_2011['LSOA_level']['white'],\n",
    "              'MSOA_white': country_dic_diss_2011['MSOA_level']['white'], 'LAD_white': country_dic_diss_2011['LAD_level']['white'],\n",
    "              'OA_asian': country_dic_diss_2011['OA_level']['asian'], 'LSOA_asian': country_dic_diss_2011['LSOA_level']['asian'],\n",
    "              'MSOA_asian': country_dic_diss_2011['MSOA_level']['asian'], 'LAD_asian': country_dic_diss_2011['LAD_level']['asian'],\n",
    "              'OA_black': country_dic_diss_2011['OA_level']['black'], 'LSOA_black': country_dic_diss_2011['LSOA_level']['black'],\n",
    "              'MSOA_black': country_dic_diss_2011['MSOA_level']['black'], 'LAD_black': country_dic_diss_2011['LAD_level']['black'],\n",
    "              'OA_other': country_dic_diss_2011['OA_level']['other'], 'LSOA_other': country_dic_diss_2011['LSOA_level']['other'],\n",
    "              'MSOA_other': country_dic_diss_2011['MSOA_level']['other'], 'LAD_other': country_dic_diss_2011['LAD_level']['other']}]\n",
    "\n",
    "country_dissimilarity_2011 = pd.DataFrame(flat_dict)\n",
    "country_dissimilarity_2011\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dissimilarity_2011.to_csv('preprocessed files/2011/country_dissimilarity_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LAD level dissimilarity index dataset for year 2011.\n",
    "# Calculating OA, LSOA and MSOA level dissimilarity index inside each LAD\n",
    "LAD_list_2011= ethnicity_2011['LAD11CD'].unique()\n",
    "LAD_dic_diss_2011 = {}\n",
    "for LAD in LAD_list_2011:\n",
    "    df = ethnicity_2011[ethnicity_2011['LAD11CD'] == LAD].reset_index(drop= True)\n",
    "    OA_diss_2011 = dissimilarity(df[['white','asian','black','other']])\n",
    "    LSOA_diss_2011 = dissimilarity(df.groupby(['LSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    MSOA_diss_2011 = dissimilarity(df.groupby(['MSOA11CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    LAD_dic_diss_2011[LAD] = {'OA_level':OA_diss_2011, 'LSOA_level':LSOA_diss_2011, 'MSOA_level':MSOA_diss_2011}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'LADCD': key,\n",
    "              'OA_white': value['OA_level']['white'], 'LSOA_white': value['LSOA_level']['white'], 'MSOA_white': value['MSOA_level']['white'],\n",
    "              'OA_asian': value['OA_level']['asian'], 'LSOA_asian': value['LSOA_level']['asian'], 'MSOA_asian': value['MSOA_level']['asian'],\n",
    "              'OA_black': value['OA_level']['black'], 'LSOA_black': value['LSOA_level']['black'], 'MSOA_black': value['MSOA_level']['black'],\n",
    "              'OA_other': value['OA_level']['other'], 'LSOA_other': value['LSOA_level']['other'], 'MSOA_other': value['MSOA_level']['other'],\n",
    "              } for key, value in LAD_dic_diss_2011.items()]\n",
    "\n",
    "LAD_dissimilarity_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_dissimilarity_2011 = LAD_dissimilarity_2011.merge(\n",
    "                         LAD_2011.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "LAD_dissimilarity_2011.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "# LAD_dissimilarity_2011.drop(['LAD'], axis= 1, inplace= True)\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population',\n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac',\n",
    "                'OA_white', 'LSOA_white', 'MSOA_white',\n",
    "                'OA_asian', 'LSOA_asian', 'MSOA_asian',\n",
    "                'OA_black', 'LSOA_black', 'MSOA_black',\n",
    "                'OA_other', 'LSOA_other', 'MSOA_other']\n",
    "\n",
    "LAD_dissimilarity_2011 = LAD_dissimilarity_2011[column_order]\n",
    "LAD_dissimilarity_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_dissimilarity_2011.to_csv('preprocessed files/2011/LAD_dissimilarity_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2011 = gpd.read_file('preprocessed files/2011/LAD_2011.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/OA_borders_2011.pkl', 'rb') as f:\n",
    "    OA_borders_2011 = pickle.load(f)\n",
    "with open('preprocessed files/2011/LSOA_borders_2011.pkl', 'rb') as f:\n",
    "    LSOA_borders_2011 = pickle.load(f)\n",
    "with open('preprocessed files/2011/MSOA_borders_2011.pkl', 'rb') as f:\n",
    "    MSOA_borders_2011 = pickle.load(f)\n",
    "with open('preprocessed files/2011/LAD_borders_2011.pkl', 'rb') as f:\n",
    "    LAD_borders_2011 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LAD level dissimilarity index dataset for year 2011.\n",
    "# Calculating OA, LSOA and MSOA level dissimilarity index inside each LAD\n",
    "LAD_list_2011= ethnicity_2011['LAD11CD'].unique()\n",
    "LAD_dic_mor_2011 = {}\n",
    "for LAD in LAD_list_2011:\n",
    "    df = ethnicity_2011[ethnicity_2011['LAD11CD'] == LAD].reset_index(drop= True)\n",
    "    OA_mor_2011 = moran(df[['OA11CD','white','asian','black','other']].set_index('OA11CD'),OA_borders_2011[LAD])\n",
    "    LSOA_mor_2011 = moran(df.groupby(['LSOA11CD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],LSOA_borders_2011[LAD])\n",
    "    MSOA_mor_2011 = moran(df.groupby(['MSOA11CD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],MSOA_borders_2011[LAD])\n",
    "    LAD_dic_mor_2011[LAD] = {'OA_level':OA_mor_2011, 'LSOA_level':LSOA_mor_2011, 'MSOA_level':MSOA_mor_2011}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'LADCD': key,\n",
    "              'OA_white': value['OA_level']['white'], 'LSOA_white': value['LSOA_level']['white'], 'MSOA_white': value['MSOA_level']['white'],\n",
    "              'OA_asian': value['OA_level']['asian'], 'LSOA_asian': value['LSOA_level']['asian'], 'MSOA_asian': value['MSOA_level']['asian'],\n",
    "              'OA_black': value['OA_level']['black'], 'LSOA_black': value['LSOA_level']['black'], 'MSOA_black': value['MSOA_level']['black'],\n",
    "              'OA_other': value['OA_level']['other'], 'LSOA_other': value['LSOA_level']['other'], 'MSOA_other': value['MSOA_level']['other'],\n",
    "              } for key, value in LAD_dic_mor_2011.items()]\n",
    "\n",
    "LAD_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_moran_2011 = LAD_moran_2011.merge(\n",
    "                         LAD_2011.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "LAD_moran_2011.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population', \n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac',\n",
    "                'OA_white', 'LSOA_white', 'MSOA_white',\n",
    "                'OA_asian', 'LSOA_asian', 'MSOA_asian',\n",
    "                'OA_black', 'LSOA_black', 'MSOA_black',\n",
    "                'OA_other', 'LSOA_other', 'MSOA_other']\n",
    "\n",
    "LAD_moran_2011 = LAD_moran_2011[column_order]\n",
    "LAD_moran_2011.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_moran_2011.to_csv('preprocessed files/2011/LAD_moran_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OA_border_2011 = {}\n",
    "\n",
    "# for idx, row in shape_2011.set_index(keys='OA11CD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in shape_2011.set_index(keys='OA11CD').iterrows():\n",
    "#         if idx != idx2:\n",
    "#             if row.OA_geometry.intersects(row2.OA_geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     OA_border_2011[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSOA_border_2011 = {}\n",
    "\n",
    "# for idx, row in shape_2011.groupby('LSOA11CD').agg({'LSOA_geometry': 'first'}).iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in shape_2011.groupby('LSOA11CD').agg({'LSOA_geometry': 'first'}).iterrows():\n",
    "#         if idx != idx2:\n",
    "#             if row.LSOA_geometry.intersects(row2.LSOA_geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     LSOA_border_2011[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_border_2011 = {}\n",
    "\n",
    "# for idx, row in shape_2011.groupby('MSOA11CD').agg({'MSOA_geometry': 'first'}).iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in shape_2011.groupby('MSOA11CD').agg({'MSOA_geometry': 'first'}).iterrows():\n",
    "#         if idx != idx2:\n",
    "#             if row.MSOA_geometry.intersects(row2.MSOA_geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     MSOA_border_2011[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.groupby(['LSOA11CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.groupby(['MSOA11CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.groupby(['LAD11CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.groupby(['LAD11CD'])['OA11CD'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2011.groupby(['MSOA11CD'])['LSOA11CD'].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_2011 = gpd.read_file('preprocessed files/2011/OA_2011.shp')\n",
    "OA_2021 = gpd.read_file('preprocessed files/2021/OA_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  birmingham_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  birmingham_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leicester_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leicester_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bradford_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bradford_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blackburn_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blackburn_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oldham_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oldham_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pendle_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pendle_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_2011['year']= '2011'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_24760\\3124646003.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n"
     ]
    }
   ],
   "source": [
    "# Creating city datasets\n",
    "birmingham_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Birmingham')]\n",
    "birmingham_2011['year']= '2011'\n",
    "birmingham_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "birmingham_2011 = pd.merge(birmingham_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "birmingham_2011['geometry'] = birmingham_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(birmingham_2011['geometry'])\n",
    "\n",
    "cols = list(birmingham_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "birmingham_2011 = birmingham_2011[cols]\n",
    "# birmingham_2011 = birmingham_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "birmingham_2011 = birmingham_2011.set_geometry('geometry')\n",
    "\n",
    "leicester_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Leicester') &\n",
    "                                ~ethnicity_2011['LAD11NM'].str.contains('North West Leicestershire')]\n",
    "leicester_2011['year']= '2011'\n",
    "leicester_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "leicester_2011 = pd.merge(leicester_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "leicester_2011['geometry'] = leicester_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(leicester_2011['geometry'])\n",
    "\n",
    "cols = list(leicester_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "leicester_2011 = leicester_2011[cols]\n",
    "# leicester_2011 = leicester_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "leicester_2011 = leicester_2011.set_geometry('geometry')\n",
    "\n",
    "bradford_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Bradford')]\n",
    "bradford_2011['year']= '2011'\n",
    "bradford_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "bradford_2011 = pd.merge(bradford_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "bradford_2011['geometry'] = bradford_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(bradford_2011['geometry'])\n",
    "\n",
    "cols = list(bradford_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "bradford_2011 = bradford_2011[cols]\n",
    "# bradford_2011 = bradford_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "bradford_2011 = bradford_2011.set_geometry('geometry')\n",
    "\n",
    "blackburn_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Blackburn')]\n",
    "blackburn_2011['year']= '2011'\n",
    "blackburn_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "blackburn_2011 = pd.merge(blackburn_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "blackburn_2011['geometry'] = blackburn_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(blackburn_2011['geometry'])\n",
    "\n",
    "cols = list(blackburn_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "blackburn_2011 = blackburn_2011[cols]\n",
    "# blackburn_2011 = blackburn_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "blackburn_2011 = blackburn_2011.set_geometry('geometry')\n",
    "\n",
    "oldham_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Oldham')]\n",
    "oldham_2011['year']= '2011'\n",
    "oldham_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "oldham_2011 = pd.merge(oldham_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "oldham_2011['geometry'] = oldham_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(oldham_2011['geometry'])\n",
    "\n",
    "cols = list(oldham_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "oldham_2011 = oldham_2011[cols]\n",
    "# oldham_2011 = oldham_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "oldham_2011 = oldham_2011.set_geometry('geometry')\n",
    "\n",
    "pendle_2011= ethnicity_2011[ethnicity_2011['LAD11NM'].str.contains('Pendle')]\n",
    "pendle_2011['year']= '2011'\n",
    "pendle_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "pendle_2011 = pd.merge(pendle_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "pendle_2011['geometry'] = pendle_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(pendle_2011['geometry'])\n",
    "\n",
    "cols = list(pendle_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "pendle_2011 = pendle_2011[cols]\n",
    "# pendle_2011 = pendle_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "pendle_2011 = pendle_2011.set_geometry('geometry')\n",
    "\n",
    "london_2011= ethnicity_2011[ethnicity_2011.LAD11CD.str.extract('([a-zA-Z]+)([^a-zA-Z]+)', expand=True)[1].astype(int).between(9000001,9000034)]\n",
    "london_2011['year']= '2011'\n",
    "london_2011.rename(columns={'OA11CD':'OACD', 'LSOA11CD':'LSOACD', 'MSOA11CD':'MSOACD', 'LAD11CD':'LADCD',\n",
    "                        'LSOA11NM':'LSOANM', 'MSOA11NM':'MSOANM', 'LAD11NM':'LADNM'}, inplace=True)\n",
    "\n",
    "london_2011 = pd.merge(london_2011,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "london_2011['geometry'] = london_2011['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(london_2011['geometry'])\n",
    "\n",
    "cols = list(london_2011.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "london_2011 = london_2011[cols]\n",
    "# london_2011 = london_2011.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "london_2011 = london_2011.set_geometry('geometry')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Columns\n",
    "ethnicity_list = ['asian', 'black', 'other', 'white']\n",
    "col_order = ['year', 'OACD', 'LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM', 'LADNM', 'OA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_2011[f'{ethnicity}_fraction'] = round(birmingham_2011[ethnicity]/birmingham_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in birmingham_2011['OACD']:\n",
    "    df = birmingham_2011[birmingham_2011['OACD']== OA]\n",
    "    birmingham_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(birmingham_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_2011['OA_simpson']= OA_simpson\n",
    "birmingham_2011 = birmingham_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_2011[f'{ethnicity}_fraction'] = round(leicester_2011[ethnicity]/leicester_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in leicester_2011['OACD']:\n",
    "    df = leicester_2011[leicester_2011['OACD']== OA]\n",
    "    leicester_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(leicester_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_2011['OA_simpson']= OA_simpson\n",
    "leicester_2011 = leicester_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_2011[f'{ethnicity}_fraction'] = round(bradford_2011[ethnicity]/bradford_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in bradford_2011['OACD']:\n",
    "    df = bradford_2011[bradford_2011['OACD']== OA]\n",
    "    bradford_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(bradford_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_2011['OA_simpson']= OA_simpson\n",
    "bradford_2011 = bradford_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_2011[f'{ethnicity}_fraction'] = round(blackburn_2011[ethnicity]/blackburn_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in blackburn_2011['OACD']:\n",
    "    df = blackburn_2011[blackburn_2011['OACD']== OA]\n",
    "    blackburn_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(blackburn_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_2011['OA_simpson']= OA_simpson\n",
    "blackburn_2011 = blackburn_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_2011[f'{ethnicity}_fraction'] = round(oldham_2011[ethnicity]/oldham_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in oldham_2011['OACD']:\n",
    "    df = oldham_2011[oldham_2011['OACD']== OA]\n",
    "    oldham_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(oldham_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_2011['OA_simpson']= OA_simpson\n",
    "oldham_2011 = oldham_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_2011[f'{ethnicity}_fraction'] = round(pendle_2011[ethnicity]/pendle_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in pendle_2011['OACD']:\n",
    "    df = pendle_2011[pendle_2011['OACD']== OA]\n",
    "    pendle_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(pendle_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_2011['OA_simpson']= OA_simpson\n",
    "pendle_2011 = pendle_2011[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_2011[f'{ethnicity}_fraction'] = round(london_2011[ethnicity]/london_2011['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in london_2011['OACD']:\n",
    "    df = london_2011[london_2011['OACD']== OA]\n",
    "    london_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(london_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "london_2011['OA_simpson']= OA_simpson\n",
    "london_2011 = london_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_2011.to_csv('preprocessed files/2011/birmingham_2011.csv', index= False)\n",
    "leicester_2011.to_csv('preprocessed files/2011/leicester_2011.csv', index= False)\n",
    "bradford_2011.to_csv('preprocessed files/2011/bradford_2011.csv', index= False)\n",
    "blackburn_2011.to_csv('preprocessed files/2011/blackburn_2011.csv', index= False)\n",
    "oldham_2011.to_csv('preprocessed files/2011/oldham_2011.csv', index= False)\n",
    "pendle_2011.to_csv('preprocessed files/2011/pendle_2011.csv', index= False)\n",
    "london_2011.to_csv('preprocessed files/2011/london_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_2011 = gpd.read_file('preprocessed files/2011/LSOA_2011.shp')\n",
    "LSOA_2021 = gpd.read_file('preprocessed files/2021/LSOA_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin city LSOA datasets\n",
    "birmingham_LSOA_2011 = birmingham_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "birmingham_LSOA_2011['geometry'] = birmingham_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(birmingham_LSOA_2011['geometry'])\n",
    "birmingham_LSOA_2011= birmingham_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "leicester_LSOA_2011 = leicester_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "leicester_LSOA_2011['geometry'] = leicester_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(leicester_LSOA_2011['geometry'])\n",
    "leicester_LSOA_2011= leicester_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "bradford_LSOA_2011 = bradford_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "bradford_LSOA_2011['geometry'] = bradford_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(bradford_LSOA_2011['geometry'])\n",
    "bradford_LSOA_2011= bradford_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "blackburn_LSOA_2011 = blackburn_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "blackburn_LSOA_2011['geometry'] = blackburn_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(blackburn_LSOA_2011['geometry'])\n",
    "blackburn_LSOA_2011= blackburn_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "oldham_LSOA_2011 = oldham_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "oldham_LSOA_2011['geometry'] = oldham_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(oldham_LSOA_2011['geometry'])\n",
    "oldham_LSOA_2011= oldham_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "pendle_LSOA_2011 = pendle_2011.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "pendle_LSOA_2011['geometry'] = pendle_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(pendle_LSOA_2011['geometry'])\n",
    "pendle_LSOA_2011= pendle_LSOA_2011.set_geometry('geometry')\n",
    "\n",
    "london_LSOA_2011 = london_2011.groupby(['LSOACD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "london_LSOA_2011['geometry'] = london_LSOA_2011['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(london_LSOA_2011['geometry'])\n",
    "london_LSOA_2011= london_LSOA_2011.set_geometry('geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['year', 'LSOACD', 'LSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "birmingham_LSOA_2011['total_pop'] = (birmingham_LSOA_2011['white'] + birmingham_LSOA_2011['asian'] +\n",
    "                                     birmingham_LSOA_2011['black'] + birmingham_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_LSOA_2011[f'{ethnicity}_fraction'] = round(birmingham_LSOA_2011[ethnicity]/birmingham_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in birmingham_LSOA_2011['LSOACD']:\n",
    "    df = birmingham_LSOA_2011[birmingham_LSOA_2011['LSOACD']== LSOA]\n",
    "    birmingham_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(birmingham_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "birmingham_LSOA_2011 = birmingham_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "leicester_LSOA_2011['total_pop'] = (leicester_LSOA_2011['white'] + leicester_LSOA_2011['asian'] +\n",
    "                                    leicester_LSOA_2011['black'] + leicester_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_LSOA_2011[f'{ethnicity}_fraction'] = round(leicester_LSOA_2011[ethnicity]/leicester_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in leicester_LSOA_2011['LSOACD']:\n",
    "    df = leicester_LSOA_2011[leicester_LSOA_2011['LSOACD']== LSOA]\n",
    "    leicester_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(leicester_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "leicester_LSOA_2011 = leicester_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "bradford_LSOA_2011['total_pop'] = (bradford_LSOA_2011['white'] + bradford_LSOA_2011['asian'] +\n",
    "                                   bradford_LSOA_2011['black'] + bradford_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_LSOA_2011[f'{ethnicity}_fraction'] = round(bradford_LSOA_2011[ethnicity]/bradford_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in bradford_LSOA_2011['LSOACD']:\n",
    "    df = bradford_LSOA_2011[bradford_LSOA_2011['LSOACD']== LSOA]\n",
    "    bradford_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(bradford_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "bradford_LSOA_2011 = bradford_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "blackburn_LSOA_2011['total_pop'] = (blackburn_LSOA_2011['white'] + blackburn_LSOA_2011['asian'] +\n",
    "                                    blackburn_LSOA_2011['black'] + blackburn_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_LSOA_2011[f'{ethnicity}_fraction'] = round(blackburn_LSOA_2011[ethnicity]/blackburn_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in blackburn_LSOA_2011['LSOACD']:\n",
    "    df = blackburn_LSOA_2011[blackburn_LSOA_2011['LSOACD']== LSOA]\n",
    "    blackburn_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(blackburn_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "blackburn_LSOA_2011 = blackburn_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "oldham_LSOA_2011['total_pop'] = (oldham_LSOA_2011['white'] + oldham_LSOA_2011['asian'] +\n",
    "                                 oldham_LSOA_2011['black'] + oldham_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_LSOA_2011[f'{ethnicity}_fraction'] = round(oldham_LSOA_2011[ethnicity]/oldham_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in oldham_LSOA_2011['LSOACD']:\n",
    "    df = oldham_LSOA_2011[oldham_LSOA_2011['LSOACD']== LSOA]\n",
    "    oldham_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(oldham_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "oldham_LSOA_2011 = oldham_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "pendle_LSOA_2011['total_pop'] = (pendle_LSOA_2011['white'] + pendle_LSOA_2011['asian'] +\n",
    "                                 pendle_LSOA_2011['black'] + pendle_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_LSOA_2011[f'{ethnicity}_fraction'] =  round(pendle_LSOA_2011[ethnicity]/pendle_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in pendle_LSOA_2011['LSOACD']:\n",
    "    df = pendle_LSOA_2011[pendle_LSOA_2011['LSOACD']== LSOA]\n",
    "    pendle_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(pendle_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "pendle_LSOA_2011 = pendle_LSOA_2011[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "london_LSOA_2011['total_pop'] = (london_LSOA_2011['white'] + london_LSOA_2011['asian'] +\n",
    "                                     london_LSOA_2011['black'] + london_LSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_LSOA_2011[f'{ethnicity}_fraction'] = round(london_LSOA_2011[ethnicity]/london_LSOA_2011['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in london_LSOA_2011['LSOACD']:\n",
    "    df = london_LSOA_2011[london_LSOA_2011['LSOACD']== LSOA]\n",
    "    london_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(london_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_LSOA_2011['LSOA_simpson']= LSOA_simpson\n",
    "col_order = ['year', 'LSOACD','LADNM', 'LSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_LSOA_2011 = london_LSOA_2011[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_2011 = gpd.read_file('preprocessed files/2011/MSOA_2011.shp')\n",
    "MSOA_2021 = gpd.read_file('preprocessed files/2021/MSOA_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin city MSOA datasets\n",
    "birmingham_MSOA_2011 = birmingham_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "birmingham_MSOA_2011['geometry'] = birmingham_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(birmingham_MSOA_2011['geometry'])\n",
    "birmingham_MSOA_2011= birmingham_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "leicester_MSOA_2011 = leicester_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "leicester_MSOA_2011['geometry'] = leicester_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(leicester_MSOA_2011['geometry'])\n",
    "leicester_MSOA_2011= leicester_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "bradford_MSOA_2011 = bradford_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "bradford_MSOA_2011['geometry'] = bradford_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(bradford_MSOA_2011['geometry'])\n",
    "bradford_MSOA_2011= bradford_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "blackburn_MSOA_2011 = blackburn_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "blackburn_MSOA_2011['geometry'] = blackburn_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(blackburn_MSOA_2011['geometry'])\n",
    "blackburn_MSOA_2011= blackburn_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "oldham_MSOA_2011 = oldham_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "oldham_MSOA_2011['geometry'] = oldham_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(oldham_MSOA_2011['geometry'])\n",
    "oldham_MSOA_2011= oldham_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "pendle_MSOA_2011 = pendle_2011.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "pendle_MSOA_2011['geometry'] = pendle_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(pendle_MSOA_2011['geometry'])\n",
    "pendle_MSOA_2011= pendle_MSOA_2011.set_geometry('geometry')\n",
    "\n",
    "london_MSOA_2011 = london_2011.groupby(['MSOACD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "london_MSOA_2011['geometry'] = london_MSOA_2011['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(london_MSOA_2011['geometry'])\n",
    "london_MSOA_2011= london_MSOA_2011.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['year', 'MSOACD', 'MSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "birmingham_MSOA_2011['total_pop'] = (birmingham_MSOA_2011['white'] + birmingham_MSOA_2011['asian'] +\n",
    "                                     birmingham_MSOA_2011['black'] + birmingham_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_MSOA_2011[f'{ethnicity}_fraction'] = round(birmingham_MSOA_2011[ethnicity]/birmingham_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in birmingham_MSOA_2011['MSOACD']:\n",
    "    df = birmingham_MSOA_2011[birmingham_MSOA_2011['MSOACD']== MSOA]\n",
    "    birmingham_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(birmingham_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "birmingham_MSOA_2011 = birmingham_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "leicester_MSOA_2011['total_pop'] = (leicester_MSOA_2011['white'] + leicester_MSOA_2011['asian'] +\n",
    "                                    leicester_MSOA_2011['black'] + leicester_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_MSOA_2011[f'{ethnicity}_fraction'] = round(leicester_MSOA_2011[ethnicity]/leicester_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in leicester_MSOA_2011['MSOACD']:\n",
    "    df = leicester_MSOA_2011[leicester_MSOA_2011['MSOACD']== MSOA]\n",
    "    leicester_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(leicester_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "leicester_MSOA_2011 = leicester_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "bradford_MSOA_2011['total_pop'] = (bradford_MSOA_2011['white'] + bradford_MSOA_2011['asian'] +\n",
    "                                   bradford_MSOA_2011['black'] + bradford_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_MSOA_2011[f'{ethnicity}_fraction'] = round(bradford_MSOA_2011[ethnicity]/bradford_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in bradford_MSOA_2011['MSOACD']:\n",
    "    df = bradford_MSOA_2011[bradford_MSOA_2011['MSOACD']== MSOA]\n",
    "    bradford_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(bradford_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "bradford_MSOA_2011 = bradford_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "blackburn_MSOA_2011['total_pop'] = (blackburn_MSOA_2011['white'] + blackburn_MSOA_2011['asian'] +\n",
    "                                    blackburn_MSOA_2011['black'] + blackburn_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_MSOA_2011[f'{ethnicity}_fraction'] = round(blackburn_MSOA_2011[ethnicity]/blackburn_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in blackburn_MSOA_2011['MSOACD']:\n",
    "    df = blackburn_MSOA_2011[blackburn_MSOA_2011['MSOACD']== MSOA]\n",
    "    blackburn_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(blackburn_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "blackburn_MSOA_2011 = blackburn_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "oldham_MSOA_2011['total_pop'] = (oldham_MSOA_2011['white'] + oldham_MSOA_2011['asian'] +\n",
    "                                 oldham_MSOA_2011['black'] + oldham_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_MSOA_2011[f'{ethnicity}_fraction'] = round(oldham_MSOA_2011[ethnicity]/oldham_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in oldham_MSOA_2011['MSOACD']:\n",
    "    df = oldham_MSOA_2011[oldham_MSOA_2011['MSOACD']== MSOA]\n",
    "    oldham_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(oldham_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "oldham_MSOA_2011 = oldham_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "pendle_MSOA_2011['total_pop'] = (pendle_MSOA_2011['white'] + pendle_MSOA_2011['asian'] +\n",
    "                                 pendle_MSOA_2011['black'] + pendle_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_MSOA_2011[f'{ethnicity}_fraction'] = round(pendle_MSOA_2011[ethnicity]/pendle_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in pendle_MSOA_2011['MSOACD']:\n",
    "    df = pendle_MSOA_2011[pendle_MSOA_2011['MSOACD']== MSOA]\n",
    "    pendle_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(pendle_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "pendle_MSOA_2011 = pendle_MSOA_2011[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "london_MSOA_2011['total_pop'] = (london_MSOA_2011['white'] + london_MSOA_2011['asian'] +\n",
    "                                 london_MSOA_2011['black'] + london_MSOA_2011['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_MSOA_2011[f'{ethnicity}_fraction'] = round(london_MSOA_2011[ethnicity]/london_MSOA_2011['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in london_MSOA_2011['MSOACD']:\n",
    "    df = london_MSOA_2011[london_MSOA_2011['MSOACD']== MSOA]\n",
    "    london_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(london_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_MSOA_2011['MSOA_simpson']= MSOA_simpson\n",
    "col_order = ['year', 'MSOACD','LADNM', 'MSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_MSOA_2011 = london_MSOA_2011[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2011 = gpd.read_file('preprocessed files/2011/LAD_2011.shp')\n",
    "LAD_2021 = gpd.read_file('preprocessed files/2021/LAD_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_LAD_2011 = london_2011.groupby(['LADCD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(LAD_2021[['LADCD','geometry']], on='LADCD', how= 'left')\n",
    "london_LAD_2011['geometry'] = london_LAD_2011['LADCD'].map(LAD_2011.set_index('LADCD')['geometry']).fillna(london_LAD_2011['geometry'])\n",
    "london_LAD_2011= london_LAD_2011.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating LAD_simpson and fraction column\n",
    "london_LAD_2011['total_pop'] = (london_LAD_2011['white'] + london_LAD_2011['asian'] +\n",
    "                                london_LAD_2011['black'] + london_LAD_2011['other'])\n",
    "# Creating LAD_simpson and fraction column\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_LAD_2011[f'{ethnicity}_fraction'] = round(london_LAD_2011[ethnicity]/london_LAD_2011['total_pop'],3)\n",
    "LAD_simpson = []\n",
    "for LAD in london_LAD_2011['LADCD']:\n",
    "    df = london_LAD_2011[london_LAD_2011['LADCD']== LAD]\n",
    "    london_LAD_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LAD_simpson.append(london_LAD_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_LAD_2011['LAD_simpson']= LAD_simpson\n",
    "col_order = ['year', 'LADCD','LADNM', 'LAD_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_LAD_2011 = london_LAD_2011[col_order]\n",
    "# london_LAD_2011\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birmingham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Birmingham\n",
    "# birmingham_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in birmingham_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in birmingham_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     birmingham_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/birmingham_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(birmingham_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Birmingham\n",
    "birmingham_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in birmingham_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in birmingham_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    birmingham_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/birmingham_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Birmingham\n",
    "birmingham_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in birmingham_2011['LSOACD'].unique():\n",
    "    lsoa_df = birmingham_2011[birmingham_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    birmingham_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/birmingham_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding moran index to the city LSOA dataset- Birmingham\n",
    "birmingham_LSOA_OA_moran = {}\n",
    "for lsoa in birmingham_2011['LSOACD'].unique():\n",
    "    lsoa_df = birmingham_2011[birmingham_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),birmingham_LSOA_OA_borders_2011[lsoa])\n",
    "    birmingham_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in birmingham_LSOA_OA_moran.items()]\n",
    "\n",
    "birmingham_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_LSOA_2011 = birmingham_LSOA_2011.merge(birmingham_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "birmingham_LSOA_2011=birmingham_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Birmingham\n",
    "birmingham_MSOA_OA_borders_2011 = {}\n",
    "for msoa in birmingham_2011['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2011[birmingham_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    birmingham_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/birmingham_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Birmingham\n",
    "birmingham_MSOA_LSOA = pd.merge(birmingham_LSOA_2011,birmingham_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "birmingham_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in birmingham_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = birmingham_MSOA_LSOA[birmingham_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    birmingham_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/birmingham_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Birmingham\n",
    "birmingham_MSOA_OA_moran = {}\n",
    "for msoa in birmingham_2011['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2011[birmingham_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),birmingham_MSOA_OA_borders_2011[msoa])\n",
    "    birmingham_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in birmingham_MSOA_OA_moran.items()]\n",
    "\n",
    "birmingham_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_MSOA_2011 = birmingham_MSOA_2011.merge(birmingham_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Birmingham\n",
    "birmingham_MSOA_LSOA_moran = {}\n",
    "for msoa in birmingham_2011['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2011[birmingham_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,birmingham_MSOA_LSOA_borders_2011[msoa])\n",
    "    birmingham_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in birmingham_MSOA_LSOA_moran.items()]\n",
    "\n",
    "birmingham_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_MSOA_2011 = birmingham_MSOA_2011.merge(birmingham_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "birmingham_MSOA_2011=birmingham_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leicester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Leicester\n",
    "# leicester_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in leicester_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in leicester_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     leicester_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/leicester_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(leicester_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Leicester\n",
    "leicester_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in leicester_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in leicester_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    leicester_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/leicester_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Leicester\n",
    "leicester_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in leicester_2011['LSOACD'].unique():\n",
    "    lsoa_df = leicester_2011[leicester_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    leicester_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/leicester_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding moran index to the city LSOA dataset- Leicester\n",
    "leicester_LSOA_OA_moran = {}\n",
    "for lsoa in leicester_2011['LSOACD'].unique():\n",
    "    lsoa_df = leicester_2011[leicester_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),leicester_LSOA_OA_borders_2011[lsoa])\n",
    "    leicester_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in leicester_LSOA_OA_moran.items()]\n",
    "\n",
    "leicester_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_LSOA_2011 = leicester_LSOA_2011.merge(leicester_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "leicester_LSOA_2011=leicester_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Leicester\n",
    "leicester_MSOA_OA_borders_2011 = {}\n",
    "for msoa in leicester_2011['MSOACD'].unique():\n",
    "    msoa_df = leicester_2011[leicester_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    leicester_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/leicester_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Leicester\n",
    "leicester_MSOA_LSOA = pd.merge(leicester_LSOA_2011,leicester_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "leicester_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in leicester_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = leicester_MSOA_LSOA[leicester_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    leicester_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/leicester_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Leicester\n",
    "leicester_MSOA_OA_moran = {}\n",
    "for msoa in leicester_2011['MSOACD'].unique():\n",
    "    msoa_df = leicester_2011[leicester_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),leicester_MSOA_OA_borders_2011[msoa])\n",
    "    leicester_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in leicester_MSOA_OA_moran.items()]\n",
    "\n",
    "leicester_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_MSOA_2011 = leicester_MSOA_2011.merge(leicester_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Leicester\n",
    "leicester_MSOA_LSOA_moran = {}\n",
    "for msoa in leicester_2011['MSOACD'].unique():\n",
    "    msoa_df = leicester_2011[leicester_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,leicester_MSOA_LSOA_borders_2011[msoa])\n",
    "    leicester_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in leicester_MSOA_LSOA_moran.items()]\n",
    "\n",
    "leicester_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_MSOA_2011 = leicester_MSOA_2011.merge(leicester_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "leicester_MSOA_2011=leicester_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bradford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Bradford\n",
    "# bradford_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in bradford_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in bradford_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     bradford_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/bradford_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(bradford_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Bradford\n",
    "bradford_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in bradford_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in bradford_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    bradford_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/bradford_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Bradford\n",
    "bradford_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in bradford_2011['LSOACD'].unique():\n",
    "    lsoa_df = bradford_2011[bradford_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    bradford_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/bradford_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Bradford\n",
    "bradford_LSOA_OA_moran = {}\n",
    "for lsoa in bradford_2011['LSOACD'].unique():\n",
    "    lsoa_df = bradford_2011[bradford_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),bradford_LSOA_OA_borders_2011[lsoa])\n",
    "    bradford_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in bradford_LSOA_OA_moran.items()]\n",
    "\n",
    "bradford_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_LSOA_2011 = bradford_LSOA_2011.merge(bradford_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "bradford_LSOA_2011=bradford_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Bradford\n",
    "bradford_MSOA_OA_borders_2011 = {}\n",
    "for msoa in bradford_2011['MSOACD'].unique():\n",
    "    msoa_df = bradford_2011[bradford_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    bradford_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/bradford_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Bradford\n",
    "bradford_MSOA_LSOA = pd.merge(bradford_LSOA_2011,bradford_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "bradford_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in bradford_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = bradford_MSOA_LSOA[bradford_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    bradford_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/bradford_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Bradford\n",
    "bradford_MSOA_OA_moran = {}\n",
    "for msoa in bradford_2011['MSOACD'].unique():\n",
    "    msoa_df = bradford_2011[bradford_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),bradford_MSOA_OA_borders_2011[msoa])\n",
    "    bradford_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in bradford_MSOA_OA_moran.items()]\n",
    "\n",
    "bradford_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_MSOA_2011 = bradford_MSOA_2011.merge(bradford_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Bradford\n",
    "bradford_MSOA_LSOA_moran = {}\n",
    "for msoa in bradford_2011['MSOACD'].unique():\n",
    "    msoa_df = bradford_2011[bradford_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,bradford_MSOA_LSOA_borders_2011[msoa])\n",
    "    bradford_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in bradford_MSOA_LSOA_moran.items()]\n",
    "\n",
    "bradford_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_MSOA_2011 = bradford_MSOA_2011.merge(bradford_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "bradford_MSOA_2011=bradford_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackburn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Blackburn\n",
    "# blackburn_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in blackburn_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in blackburn_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     blackburn_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/blackburn_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(blackburn_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Blackburn\n",
    "blackburn_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in blackburn_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in blackburn_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    blackburn_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/blackburn_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Blackburn\n",
    "blackburn_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in blackburn_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in blackburn_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    blackburn_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/blackburn_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Blackburn\n",
    "blackburn_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in blackburn_2011['LSOACD'].unique():\n",
    "    lsoa_df = blackburn_2011[blackburn_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    blackburn_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/blackburn_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Blackburn\n",
    "blackburn_LSOA_OA_moran = {}\n",
    "for lsoa in blackburn_2011['LSOACD'].unique():\n",
    "    lsoa_df = blackburn_2011[blackburn_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),blackburn_LSOA_OA_borders_2011[lsoa])\n",
    "    blackburn_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in blackburn_LSOA_OA_moran.items()]\n",
    "\n",
    "blackburn_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_LSOA_2011 = blackburn_LSOA_2011.merge(blackburn_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "blackburn_LSOA_2011=blackburn_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Blackburn\n",
    "blackburn_MSOA_OA_borders_2011 = {}\n",
    "for msoa in blackburn_2011['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2011[blackburn_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    blackburn_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/blackburn_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Blackburn\n",
    "blackburn_MSOA_LSOA = pd.merge(blackburn_LSOA_2011,blackburn_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "blackburn_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in blackburn_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = blackburn_MSOA_LSOA[blackburn_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    blackburn_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/blackburn_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Blackburn\n",
    "blackburn_MSOA_OA_moran = {}\n",
    "for msoa in blackburn_2011['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2011[blackburn_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),blackburn_MSOA_OA_borders_2011[msoa])\n",
    "    blackburn_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in blackburn_MSOA_OA_moran.items()]\n",
    "\n",
    "blackburn_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_MSOA_2011 = blackburn_MSOA_2011.merge(blackburn_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Blackburn\n",
    "blackburn_MSOA_LSOA_moran = {}\n",
    "for msoa in blackburn_2011['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2011[blackburn_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,blackburn_MSOA_LSOA_borders_2011[msoa])\n",
    "    blackburn_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in blackburn_MSOA_LSOA_moran.items()]\n",
    "\n",
    "blackburn_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_MSOA_2011 = blackburn_MSOA_2011.merge(blackburn_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "blackburn_MSOA_2011=blackburn_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oldham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Oldham\n",
    "# oldham_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in oldham_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in oldham_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     oldham_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/oldham_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(oldham_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Oldham\n",
    "oldham_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in oldham_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in oldham_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    oldham_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/oldham_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_LSOA_borders_2011, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Oldham\n",
    "oldham_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in oldham_2011['LSOACD'].unique():\n",
    "    lsoa_df = oldham_2011[oldham_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    oldham_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/oldham_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Oldham\n",
    "oldham_LSOA_OA_moran = {}\n",
    "for lsoa in oldham_2011['LSOACD'].unique():\n",
    "    lsoa_df = oldham_2011[oldham_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),oldham_LSOA_OA_borders_2011[lsoa])\n",
    "    oldham_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in oldham_LSOA_OA_moran.items()]\n",
    "\n",
    "oldham_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_LSOA_2011 = oldham_LSOA_2011.merge(oldham_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "oldham_LSOA_2011=oldham_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Oldham\n",
    "oldham_MSOA_OA_borders_2011 = {}\n",
    "for msoa in oldham_2011['MSOACD'].unique():\n",
    "    msoa_df = oldham_2011[oldham_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    oldham_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/oldham_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Oldham\n",
    "oldham_MSOA_LSOA = pd.merge(oldham_LSOA_2011,oldham_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "oldham_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in oldham_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = oldham_MSOA_LSOA[oldham_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    oldham_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/oldham_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_MSOA_LSOA_borders_2011, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Oldham\n",
    "oldham_MSOA_OA_moran = {}\n",
    "for msoa in oldham_2011['MSOACD'].unique():\n",
    "    msoa_df = oldham_2011[oldham_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),oldham_MSOA_OA_borders_2011[msoa])\n",
    "    oldham_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in oldham_MSOA_OA_moran.items()]\n",
    "\n",
    "oldham_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_MSOA_2011 = oldham_MSOA_2011.merge(oldham_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- Oldham\n",
    "oldham_MSOA_LSOA_moran = {}\n",
    "for msoa in oldham_2011['MSOACD'].unique():\n",
    "    msoa_df = oldham_2011[oldham_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,oldham_MSOA_LSOA_borders_2011[msoa])\n",
    "    oldham_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in oldham_MSOA_LSOA_moran.items()]\n",
    "\n",
    "oldham_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_MSOA_2011 = oldham_MSOA_2011.merge(oldham_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "oldham_MSOA_2011=oldham_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Pendle\n",
    "# pendle_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in pendle_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in pendle_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     pendle_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/pendle_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(pendle_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Pendle\n",
    "pendle_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in pendle_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in pendle_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    pendle_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/pendle_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Pendle\n",
    "pendle_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in pendle_2011['LSOACD'].unique():\n",
    "    lsoa_df = pendle_2011[pendle_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    pendle_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/pendle_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_11860\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Pendle\n",
    "pendle_LSOA_OA_moran = {}\n",
    "for lsoa in pendle_2011['LSOACD'].unique():\n",
    "    lsoa_df = pendle_2011[pendle_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),pendle_LSOA_OA_borders_2011[lsoa])\n",
    "    pendle_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in pendle_LSOA_OA_moran.items()]\n",
    "\n",
    "pendle_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_LSOA_2011 = pendle_LSOA_2011.merge(pendle_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "pendle_LSOA_2011=pendle_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Pendle\n",
    "pendle_MSOA_OA_borders_2011 = {}\n",
    "for msoa in pendle_2011['MSOACD'].unique():\n",
    "    msoa_df = pendle_2011[pendle_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    pendle_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/pendle_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Pendle\n",
    "pendle_MSOA_LSOA = pd.merge(pendle_LSOA_2011,pendle_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "pendle_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in pendle_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = pendle_MSOA_LSOA[pendle_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    pendle_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/pendle_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Pendle\n",
    "pendle_MSOA_OA_moran = {}\n",
    "for msoa in pendle_2011['MSOACD'].unique():\n",
    "    msoa_df = pendle_2011[pendle_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),pendle_MSOA_OA_borders_2011[msoa])\n",
    "    pendle_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in pendle_MSOA_OA_moran.items()]\n",
    "\n",
    "pendle_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_MSOA_2011 = pendle_MSOA_2011.merge(pendle_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- Pendle\n",
    "pendle_MSOA_LSOA_moran = {}\n",
    "for msoa in pendle_2011['MSOACD'].unique():\n",
    "    msoa_df = pendle_2011[pendle_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,pendle_MSOA_LSOA_borders_2011[msoa])\n",
    "    pendle_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in pendle_MSOA_LSOA_moran.items()]\n",
    "\n",
    "pendle_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_MSOA_2011 = pendle_MSOA_2011.merge(pendle_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "pendle_MSOA_2011=pendle_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- London\n",
    "# london_OA_borders_2011 = {}\n",
    "\n",
    "# for idx1, row1 in london_2011.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in london_2011.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     london_OA_borders_2011[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2011/london_OA_borders_2011.pkl', 'wb') as f:\n",
    "#     pickle.dump(london_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- London\n",
    "london_LSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in london_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in london_LSOA_2011.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    london_LSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/london_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(london_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- London\n",
    "london_LSOA_OA_borders_2011 = {}\n",
    "for lsoa in london_2011['LSOACD'].unique():\n",
    "    lsoa_df = london_2011[london_2011['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    london_LSOA_OA_borders_2011[lsoa] = oa_borders\n",
    "with open('preprocessed files/2011/london_LSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(london_LSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding moran index to the city LSOA dataset- London\n",
    "london_LSOA_OA_moran = {}\n",
    "for lsoa in london_2011['LSOACD'].unique():\n",
    "    lsoa_df = london_2011[london_2011['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),london_LSOA_OA_borders_2011[lsoa])\n",
    "    london_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in london_LSOA_OA_moran.items()]\n",
    "\n",
    "london_LSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_LSOA_2011 = london_LSOA_2011.merge(london_LSOA_OA_moran_2011[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "london_LSOA_2011=london_LSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA level- London\n",
    "london_MSOA_borders_2011 = {}\n",
    "\n",
    "for idx1, row1 in london_MSOA_2011.set_index('MSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in london_MSOA_2011.set_index('MSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    london_MSOA_borders_2011[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2011/london_MSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- London\n",
    "london_MSOA_OA_borders_2011 = {}\n",
    "for msoa in london_2011['MSOACD'].unique():\n",
    "    msoa_df = london_2011[london_2011['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    london_MSOA_OA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/london_MSOA_OA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_OA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- London\n",
    "london_MSOA_LSOA = pd.merge(london_LSOA_2011,london_2011.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "london_MSOA_LSOA_borders_2011 = {}\n",
    "for msoa in london_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = london_MSOA_LSOA[london_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    london_MSOA_LSOA_borders_2011[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2011/london_MSOA_LSOA_borders_2011.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_LSOA_borders_2011, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- London\n",
    "london_MSOA_OA_moran = {}\n",
    "for msoa in london_2011['MSOACD'].unique():\n",
    "    msoa_df = london_2011[london_2011['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),london_MSOA_OA_borders_2011[msoa])\n",
    "    london_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in london_MSOA_OA_moran.items()]\n",
    "\n",
    "london_MSOA_OA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_MSOA_2011 = london_MSOA_2011.merge(london_MSOA_OA_moran_2011[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- London\n",
    "london_MSOA_LSOA_moran = {}\n",
    "for msoa in london_2011['MSOACD'].unique():\n",
    "    msoa_df = london_2011[london_2011['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,london_MSOA_LSOA_borders_2011[msoa])\n",
    "    london_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in london_MSOA_LSOA_moran.items()]\n",
    "\n",
    "london_MSOA_LSOA_moran_2011 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_MSOA_2011 = london_MSOA_2011.merge(london_MSOA_LSOA_moran_2011[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "london_MSOA_2011=london_MSOA_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white_frac</th>\n",
       "      <th>asian_frac</th>\n",
       "      <th>black_frac</th>\n",
       "      <th>other_frac</th>\n",
       "      <th>OA_simpson</th>\n",
       "      <th>LSOA_simpson</th>\n",
       "      <th>MSOA_simpson</th>\n",
       "      <th>LAD_simpson</th>\n",
       "      <th>London_simpson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>8173941</td>\n",
       "      <td>4887435</td>\n",
       "      <td>1511546</td>\n",
       "      <td>1088640</td>\n",
       "      <td>686320</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  total_population    white    asian    black   other  white_frac  \\\n",
       "0  2011           8173941  4887435  1511546  1088640  686320       0.598   \n",
       "\n",
       "   asian_frac  black_frac  other_frac  OA_simpson  LSOA_simpson  MSOA_simpson  \\\n",
       "0       0.185       0.133       0.084       0.502         0.491         0.483   \n",
       "\n",
       "   LAD_simpson  London_simpson  \n",
       "0        0.449           0.409  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating london simpson index dataset for year 2011.\n",
    "# Calculating OA, LSOA, MSOA and LAD level simpson index inside London\n",
    "OA_simp_london_2011 = simpson(london_2011[['white','asian','black','other']])\n",
    "LSOA_simp_london_2011 = simpson(london_2011.groupby(['LSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_simp_london_2011 = simpson(london_2011.groupby(['MSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_simp_london_2011 = simpson(london_2011.groupby(['LADCD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "\n",
    "country_dic_sim_2011 = {'OA_simpson':OA_simp_london_2011[0], 'LSOA_simpson':LSOA_simp_london_2011[0],\n",
    "                        'MSOA_simpson':MSOA_simp_london_2011[0], 'LAD_simpson':LAD_simp_london_2011[0], 'london':LAD_simp_london_2011[1]}\n",
    "\n",
    "flat_dict = [{'year': 2011, 'total_population': london_2011['total_pop'].sum(),\n",
    "              'white': london_2011['white'].sum(),\n",
    "              'asian': london_2011['asian'].sum(),\n",
    "              'black': london_2011['black'].sum(),\n",
    "              'other': london_2011['other'].sum(),              \n",
    "              'white_frac': round(london_2011['white'].sum()/london_2011['total_pop'].sum(),3),\n",
    "              'asian_frac': round(london_2011['asian'].sum()/london_2011['total_pop'].sum(),3),\n",
    "              'black_frac': round(london_2011['black'].sum()/london_2011['total_pop'].sum(),3),\n",
    "              'other_frac': round(london_2011['other'].sum()/london_2011['total_pop'].sum(),3),\n",
    "              'OA_simpson':OA_simp_london_2011[0], 'LSOA_simpson':LSOA_simp_london_2011[0],'MSOA_simpson':MSOA_simp_london_2011[0], \n",
    "              'LAD_simpson':LAD_simp_london_2011[0], 'London_simpson':LAD_simp_london_2011[1]}]\n",
    "\n",
    "london_simpson_2011 = pd.DataFrame(flat_dict)\n",
    "london_simpson_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>OA_white_diss</th>\n",
       "      <th>LSOA_white_diss</th>\n",
       "      <th>MSOA_white_diss</th>\n",
       "      <th>LAD_white_diss</th>\n",
       "      <th>OA_asian_diss</th>\n",
       "      <th>LSOA_asian_diss</th>\n",
       "      <th>MSOA_asian_diss</th>\n",
       "      <th>LAD_asian_diss</th>\n",
       "      <th>OA_black_diss</th>\n",
       "      <th>LSOA_black_diss</th>\n",
       "      <th>MSOA_black_diss</th>\n",
       "      <th>LAD_black_diss</th>\n",
       "      <th>OA_other_diss</th>\n",
       "      <th>LSOA_other_diss</th>\n",
       "      <th>MSOA_other_diss</th>\n",
       "      <th>LAD_other_diss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  OA_white_diss  LSOA_white_diss  MSOA_white_diss  LAD_white_diss  \\\n",
       "0  2011          0.382            0.356            0.335           0.227   \n",
       "\n",
       "   OA_asian_diss  LSOA_asian_diss  MSOA_asian_diss  LAD_asian_diss  \\\n",
       "0           0.43            0.409            0.395           0.332   \n",
       "\n",
       "   OA_black_diss  LSOA_black_diss  MSOA_black_diss  LAD_black_diss  \\\n",
       "0           0.42            0.386            0.363            0.28   \n",
       "\n",
       "   OA_other_diss  LSOA_other_diss  MSOA_other_diss  LAD_other_diss  \n",
       "0          0.228            0.186             0.17           0.145  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating London dissimilarity index dataset for year 2011.\n",
    "# Calculating OA, LSOA, MSOA and LAD level dissimilarity index inside London\n",
    "\n",
    "OA_diss_london_2011 = dissimilarity(london_2011[['white','asian','black','other']])\n",
    "LSOA_diss_london_2011 = dissimilarity(london_2011.groupby(['LSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_diss_london_2011 = dissimilarity(london_2011.groupby(['MSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_diss_london_2011 = dissimilarity(london_2011.groupby(['LADCD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "london_dic_diss_2011 = {'OA_level':OA_diss_london_2011, 'LSOA_level':LSOA_diss_london_2011,\n",
    "                        'MSOA_level':MSOA_diss_london_2011, 'LAD_level':LAD_diss_london_2011}\n",
    "\n",
    "flat_dict = [{'year': 2011,\n",
    "              'OA_white_diss': london_dic_diss_2011['OA_level']['white'], 'LSOA_white_diss': london_dic_diss_2011['LSOA_level']['white'],\n",
    "              'MSOA_white_diss': london_dic_diss_2011['MSOA_level']['white'], 'LAD_white_diss': london_dic_diss_2011['LAD_level']['white'],\n",
    "              'OA_asian_diss': london_dic_diss_2011['OA_level']['asian'], 'LSOA_asian_diss': london_dic_diss_2011['LSOA_level']['asian'],\n",
    "              'MSOA_asian_diss': london_dic_diss_2011['MSOA_level']['asian'], 'LAD_asian_diss': london_dic_diss_2011['LAD_level']['asian'],\n",
    "              'OA_black_diss': london_dic_diss_2011['OA_level']['black'], 'LSOA_black_diss': london_dic_diss_2011['LSOA_level']['black'],\n",
    "              'MSOA_black_diss': london_dic_diss_2011['MSOA_level']['black'], 'LAD_black_diss': london_dic_diss_2011['LAD_level']['black'],\n",
    "              'OA_other_diss': london_dic_diss_2011['OA_level']['other'], 'LSOA_other_diss': london_dic_diss_2011['LSOA_level']['other'],\n",
    "              'MSOA_other_diss': london_dic_diss_2011['MSOA_level']['other'], 'LAD_other_diss': london_dic_diss_2011['LAD_level']['other']}]\n",
    "\n",
    "\n",
    "london_dissimilarity_2011 = pd.DataFrame(flat_dict)\n",
    "london_dissimilarity_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2011/london_OA_borders_2011.pkl', 'rb') as f:\n",
    "    london_OA_borders_2011 = pickle.load(f)\n",
    "with open('preprocessed files/2011/london_LSOA_borders_2011.pkl', 'rb') as f:\n",
    "    london_LSOA_borders_2011 = pickle.load(f)\n",
    "with open('preprocessed files/2011/london_MSOA_borders_2011.pkl', 'rb') as f:\n",
    "    london_MSOA_borders_2011 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA_white_mor</th>\n",
       "      <th>OA_asian_mor</th>\n",
       "      <th>OA_black_mor</th>\n",
       "      <th>OA_other_mor</th>\n",
       "      <th>LSOA_white_mor</th>\n",
       "      <th>LSOA_asian_mor</th>\n",
       "      <th>LSOA_black_mor</th>\n",
       "      <th>LSOA_other_mor</th>\n",
       "      <th>MSOA_white_mor</th>\n",
       "      <th>MSOA_asian_mor</th>\n",
       "      <th>MSOA_black_mor</th>\n",
       "      <th>MSOA_other_mor</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OA_white_mor  OA_asian_mor  OA_black_mor  OA_other_mor  LSOA_white_mor  \\\n",
       "0         0.816         0.854         0.732         0.561           0.846   \n",
       "\n",
       "   LSOA_asian_mor  LSOA_black_mor  LSOA_other_mor  MSOA_white_mor  \\\n",
       "0           0.889           0.768           0.737           0.802   \n",
       "\n",
       "   MSOA_asian_mor  MSOA_black_mor  MSOA_other_mor  year  \n",
       "0           0.848           0.728           0.786  2011  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_mor_london_2011= {}\n",
    "\n",
    "OA_mor_london_2011 = moran(london_2011[['OACD','white','asian','black','other']].set_index('OACD'),london_OA_borders_2011)\n",
    "LSOA_mor_london_2011 = moran(london_2011.groupby(['LSOACD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],london_LSOA_borders_2011)\n",
    "MSOA_mor_london_2011 = moran(london_2011.groupby(['MSOACD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],london_MSOA_borders_2011)\n",
    "dic_mor_london_2011 = {'OA':OA_mor_london_2011, 'LSOA':LSOA_mor_london_2011, 'MSOA':MSOA_mor_london_2011}\n",
    "\n",
    "flat_dict = {}\n",
    "for level, values in dic_mor_london_2011.items():\n",
    "    for ethnicity, value in values.items():\n",
    "        flat_dict[f\"{level}_{ethnicity}_mor\"] = value\n",
    "\n",
    "london_moran_2011 = pd.DataFrame([flat_dict])\n",
    "london_moran_2011['year']= 2011\n",
    "london_moran_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white_frac</th>\n",
       "      <th>asian_frac</th>\n",
       "      <th>black_frac</th>\n",
       "      <th>other_frac</th>\n",
       "      <th>...</th>\n",
       "      <th>OA_black_mor</th>\n",
       "      <th>OA_other_mor</th>\n",
       "      <th>LSOA_white_mor</th>\n",
       "      <th>LSOA_asian_mor</th>\n",
       "      <th>LSOA_black_mor</th>\n",
       "      <th>LSOA_other_mor</th>\n",
       "      <th>MSOA_white_mor</th>\n",
       "      <th>MSOA_asian_mor</th>\n",
       "      <th>MSOA_black_mor</th>\n",
       "      <th>MSOA_other_mor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>8173941</td>\n",
       "      <td>4887435</td>\n",
       "      <td>1511546</td>\n",
       "      <td>1088640</td>\n",
       "      <td>686320</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  total_population    white    asian    black   other  white_frac  \\\n",
       "0  2011           8173941  4887435  1511546  1088640  686320       0.598   \n",
       "\n",
       "   asian_frac  black_frac  other_frac  ...  OA_black_mor  OA_other_mor  \\\n",
       "0       0.185       0.133       0.084  ...         0.732         0.561   \n",
       "\n",
       "   LSOA_white_mor  LSOA_asian_mor  LSOA_black_mor  LSOA_other_mor  \\\n",
       "0           0.846           0.889           0.768           0.737   \n",
       "\n",
       "   MSOA_white_mor  MSOA_asian_mor  MSOA_black_mor  MSOA_other_mor  \n",
       "0           0.802           0.848           0.728           0.786  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_indexes_2011 = pd.merge(london_simpson_2011,london_dissimilarity_2011, how='left')\n",
    "london_indexes_2011 = london_indexes_2011.merge(london_moran_2011, how='left')\n",
    "london_indexes_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_indexes_2011['LADCD'] = 'E00000000'\n",
    "london_indexes_2011['LADNM'] = 'London'\n",
    "col_order = ['year', 'LADCD', 'LADNM', 'white', 'asian', 'black', 'other', 'total_population', \n",
    "             'white_frac', 'asian_frac', 'black_frac', 'other_frac', \n",
    "             'OA_simpson', 'LSOA_simpson', 'MSOA_simpson', 'LAD_simpson', 'London_simpson',\n",
    "             'OA_white_diss', 'LSOA_white_diss', 'MSOA_white_diss',\n",
    "             'OA_asian_diss', 'LSOA_asian_diss', 'MSOA_asian_diss', \n",
    "             'OA_black_diss', 'LSOA_black_diss', 'MSOA_black_diss', \n",
    "             'OA_other_diss', 'LSOA_other_diss', 'MSOA_other_diss',\n",
    "             'OA_white_mor', 'LSOA_white_mor','MSOA_white_mor', \n",
    "             'OA_asian_mor', 'LSOA_asian_mor', 'MSOA_asian_mor',\n",
    "             'OA_black_mor', 'LSOA_black_mor', 'MSOA_black_mor', \n",
    "             'OA_other_mor', 'LSOA_other_mor', 'MSOA_other_mor']\n",
    "london_indexes_2011 = london_indexes_2011[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_LSOA_2011.to_csv('preprocessed files/2011/birmingham_LSOA_2011.csv', index= False)\n",
    "leicester_LSOA_2011.to_csv('preprocessed files/2011/leicester_LSOA_2011.csv', index= False)\n",
    "bradford_LSOA_2011.to_csv('preprocessed files/2011/bradford_LSOA_2011.csv', index= False)\n",
    "blackburn_LSOA_2011.to_csv('preprocessed files/2011/blackburn_LSOA_2011.csv', index= False)\n",
    "oldham_LSOA_2011.to_csv('preprocessed files/2011/oldham_LSOA_2011.csv', index= False)\n",
    "pendle_LSOA_2011.to_csv('preprocessed files/2011/pendle_LSOA_2011.csv', index= False)\n",
    "london_LSOA_2011.to_csv('preprocessed files/2011/london_LSOA_2011.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_MSOA_2011.to_csv('preprocessed files/2011/birmingham_MSOA_2011.csv', index= False)\n",
    "leicester_MSOA_2011.to_csv('preprocessed files/2011/leicester_MSOA_2011.csv', index= False)\n",
    "bradford_MSOA_2011.to_csv('preprocessed files/2011/bradford_MSOA_2011.csv', index= False)\n",
    "blackburn_MSOA_2011.to_csv('preprocessed files/2011/blackburn_MSOA_2011.csv', index= False)\n",
    "oldham_MSOA_2011.to_csv('preprocessed files/2011/oldham_MSOA_2011.csv', index= False)\n",
    "pendle_MSOA_2011.to_csv('preprocessed files/2011/pendle_MSOA_2011.csv', index= False)\n",
    "london_MSOA_2011.to_csv('preprocessed files/2011/london_MSOA_2011.csv', index= False)\n",
    "london_LAD_2011.to_csv('preprocessed files/2011/london_LAD_2011.csv', index= False)\n",
    "london_indexes_2011.to_csv('preprocessed files/2011/london_indexes_2011.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
