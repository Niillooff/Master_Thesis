{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots \n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium.plugins import DualMap, HeatMap\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from dbfread import DBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dissimilarity function\n",
    "def dissimilarity(df):\n",
    "    dissimilarity_results = {}\n",
    "    for col in df.columns:\n",
    "        col_numerator = []\n",
    "        for i in range(df.shape[0]):\n",
    "            col_numerator.append((df.iloc[i,:].sum() / df.sum().sum()) *\n",
    "                                 np.abs((df.loc[i, col] / df.iloc[i,:].sum() - (df[col].sum() / df.sum().sum()))))\n",
    "        col_numerator = sum(col_numerator)\n",
    "        col_denominator = 2 * (df[col].sum() / df.sum().sum()) * (1 - (df[col].sum() / df.sum().sum()))\n",
    "        dissimilarity_results[col] = round(col_numerator / col_denominator, 3)\n",
    "\n",
    "        # print(f'dissimilarity {col} = {col_numerator/col_denominator}')\n",
    "    return dissimilarity_results              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "# defining simpson function\n",
    "\n",
    "def simpson(df):\n",
    "    simpson_series = []\n",
    "    for i in range(df.shape[0]):\n",
    "        area_ethnic_fraction_2 = []\n",
    "        for col in df.columns:\n",
    "            if col != 'other':\n",
    "                area_ethnic_fraction_2.append((df.loc[i,col]/(df.iloc[i,:].sum()))**2)\n",
    "        sum_area_ethnic_fraction_2 = sum(area_ethnic_fraction_2)\n",
    "        simpson_series.append(sum_area_ethnic_fraction_2)\n",
    "        \n",
    "    simpson_series = pd.Series(simpson_series)\n",
    "    simpson_index = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        simpson_index += (simpson_series.iloc[i] * df.iloc[i, :].sum() / df.sum().sum())\n",
    "    \n",
    "    area_simpson = []\n",
    "    for col in df.columns:\n",
    "        if col != 'other':\n",
    "            area_simpson.append((df[col].sum()/df.sum().sum())**2)\n",
    "    area_simpson_index = sum(area_simpson)\n",
    "    simpson_index = round(simpson_index, 3)\n",
    "    area_simpson_index = round(area_simpson_index, 3)\n",
    "    return [simpson_index, area_simpson_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining moran I function\n",
    "\n",
    "def moran(df,border):\n",
    "    positive_weights = []\n",
    "    for key in border.keys():\n",
    "        positive_weights.append(len(border[key]))\n",
    "       \n",
    "    fraction = {}\n",
    "    for col in df.columns:\n",
    "        # df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        fraction[col] = []\n",
    "        for i in df.index:\n",
    "            fraction[col].append(df.loc[i, col] / df.loc[i, :].sum())\n",
    "    \n",
    "    col_moran = {} \n",
    "    for col in df.columns:\n",
    "        col_moran_list = []\n",
    "        for i in df.index:\n",
    "            morani = []\n",
    "            for common in border[i]:    \n",
    "                morani.append(((df.loc[i, col] / df.loc[i, :].sum()) - np.mean(fraction[col])) * ((df.loc[common, col] / df.loc[common, :].sum()) - np.mean(fraction[col])))\n",
    "            row_moran = sum(morani)\n",
    "            col_moran_list.append(row_moran)\n",
    "        col_moran[col] = col_moran_list\n",
    "    moran_results= {}\n",
    "    for col in df.columns:\n",
    "        moran_numerator = sum(col_moran[col])*df.shape[0]\n",
    "        moran_denominator = sum((fraction[col] - np.mean(fraction[col]))**2)*sum(positive_weights)\n",
    "        # moran_index = moran_numerator/moran_denominator\n",
    "        moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
    "    return moran_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2001 = pd.read_csv('Census2001\\\\census2001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175434 entries, 0 to 175433\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                Non-Null Count   Dtype \n",
      "---  ------                                --------------   ----- \n",
      " 0   2001 output area                      175434 non-null  object\n",
      " 1   mnemonic                              175434 non-null  object\n",
      " 2   White: British                        175434 non-null  int64 \n",
      " 3   White: Irish                          175434 non-null  int64 \n",
      " 4   White: Other                          175434 non-null  int64 \n",
      " 5   Mixed: White and Black Caribbean      175434 non-null  int64 \n",
      " 6   Mixed: White and Black African        175434 non-null  int64 \n",
      " 7   Mixed: White and Asian                175434 non-null  int64 \n",
      " 8   Mixed: Other                          175434 non-null  int64 \n",
      " 9   Asian/Asian British: Indian           175434 non-null  int64 \n",
      " 10  Asian/Asian British: Pakistani        175434 non-null  int64 \n",
      " 11  Asian/Asian British: Bangladeshi      175434 non-null  int64 \n",
      " 12  Asian/Asian British: Other            175434 non-null  int64 \n",
      " 13  Black/Black British: Black Caribbean  175434 non-null  int64 \n",
      " 14  Black/Black British: Black African    175434 non-null  int64 \n",
      " 15  Black/Black British: Other            175434 non-null  int64 \n",
      " 16  Chinese/Other: Chinese                175434 non-null  int64 \n",
      " 17  Chinese/Other: Other                  175434 non-null  int64 \n",
      "dtypes: int64(16), object(2)\n",
      "memory usage: 24.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_2001.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001 output area</th>\n",
       "      <th>mnemonic</th>\n",
       "      <th>White: British</th>\n",
       "      <th>White: Irish</th>\n",
       "      <th>White: Other</th>\n",
       "      <th>Mixed: White and Black Caribbean</th>\n",
       "      <th>Mixed: White and Black African</th>\n",
       "      <th>Mixed: White and Asian</th>\n",
       "      <th>Mixed: Other</th>\n",
       "      <th>Asian/Asian British: Indian</th>\n",
       "      <th>Asian/Asian British: Pakistani</th>\n",
       "      <th>Asian/Asian British: Bangladeshi</th>\n",
       "      <th>Asian/Asian British: Other</th>\n",
       "      <th>Black/Black British: Black Caribbean</th>\n",
       "      <th>Black/Black British: Black African</th>\n",
       "      <th>Black/Black British: Other</th>\n",
       "      <th>Chinese/Other: Chinese</th>\n",
       "      <th>Chinese/Other: Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45UBFQ0001</td>\n",
       "      <td>E00159790</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45UBFQ0002</td>\n",
       "      <td>E00159791</td>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45UBFQ0003</td>\n",
       "      <td>E00159792</td>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45UBFQ0004</td>\n",
       "      <td>E00159793</td>\n",
       "      <td>310</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45UBFQ0005</td>\n",
       "      <td>E00159794</td>\n",
       "      <td>289</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2001 output area   mnemonic  White: British  White: Irish  White: Other  \\\n",
       "0       45UBFQ0001  E00159790             271             0             5   \n",
       "1       45UBFQ0002  E00159791             318             3             6   \n",
       "2       45UBFQ0003  E00159792             298             3             3   \n",
       "3       45UBFQ0004  E00159793             310             3             4   \n",
       "4       45UBFQ0005  E00159794             289             3             0   \n",
       "\n",
       "   Mixed: White and Black Caribbean  Mixed: White and Black African  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               4   \n",
       "2                                 3                               3   \n",
       "3                                 0                               3   \n",
       "4                                 0                               0   \n",
       "\n",
       "   Mixed: White and Asian  Mixed: Other  Asian/Asian British: Indian  \\\n",
       "0                       3             0                            0   \n",
       "1                       3             0                            0   \n",
       "2                       3             0                            0   \n",
       "3                       0             0                            0   \n",
       "4                       0             0                            0   \n",
       "\n",
       "   Asian/Asian British: Pakistani  Asian/Asian British: Bangladeshi  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "2                               5                                 0   \n",
       "3                               0                                 0   \n",
       "4                               0                                 0   \n",
       "\n",
       "   Asian/Asian British: Other  Black/Black British: Black Caribbean  \\\n",
       "0                           0                                     0   \n",
       "1                           0                                     0   \n",
       "2                           0                                     0   \n",
       "3                           3                                     0   \n",
       "4                           0                                     0   \n",
       "\n",
       "   Black/Black British: Black African  Black/Black British: Other  \\\n",
       "0                                   0                           0   \n",
       "1                                   0                           0   \n",
       "2                                   0                           0   \n",
       "3                                   4                           0   \n",
       "4                                   0                           0   \n",
       "\n",
       "   Chinese/Other: Chinese  Chinese/Other: Other  \n",
       "0                       0                     0  \n",
       "1                       0                     3  \n",
       "2                       3                     0  \n",
       "3                       0                     0  \n",
       "4                       0                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001 output area</th>\n",
       "      <th>mnemonic</th>\n",
       "      <th>Ethnic group</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45UBFQ0001</td>\n",
       "      <td>E00159790</td>\n",
       "      <td>White: British</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45UBFQ0002</td>\n",
       "      <td>E00159791</td>\n",
       "      <td>White: British</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45UBFQ0003</td>\n",
       "      <td>E00159792</td>\n",
       "      <td>White: British</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45UBFQ0004</td>\n",
       "      <td>E00159793</td>\n",
       "      <td>White: British</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45UBFQ0005</td>\n",
       "      <td>E00159794</td>\n",
       "      <td>White: British</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2001 output area   mnemonic    Ethnic group  Observation\n",
       "0       45UBFQ0001  E00159790  White: British          271\n",
       "1       45UBFQ0002  E00159791  White: British          318\n",
       "2       45UBFQ0003  E00159792  White: British          298\n",
       "3       45UBFQ0004  E00159793  White: British          310\n",
       "4       45UBFQ0005  E00159794  White: British          289"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001 = data_2001.melt(id_vars=['2001 output area','mnemonic'], value_vars= data_2001.columns[2:], \n",
    "                           var_name='Ethnic group', value_name='Observation')\n",
    "melt_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White: British', 'White: Irish', 'White: Other',\n",
       "       'Mixed: White and Black Caribbean',\n",
       "       'Mixed: White and Black African', 'Mixed: White and Asian',\n",
       "       'Mixed: Other', 'Asian/Asian British: Indian',\n",
       "       'Asian/Asian British: Pakistani',\n",
       "       'Asian/Asian British: Bangladeshi', 'Asian/Asian British: Other',\n",
       "       'Black/Black British: Black Caribbean',\n",
       "       'Black/Black British: Black African', 'Black/Black British: Other',\n",
       "       'Chinese/Other: Chinese', 'Chinese/Other: Other'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001['Ethnic group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001 output area</th>\n",
       "      <th>mnemonic</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45UBFQ0001</td>\n",
       "      <td>E00159790</td>\n",
       "      <td>271</td>\n",
       "      <td>White</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45UBFQ0002</td>\n",
       "      <td>E00159791</td>\n",
       "      <td>318</td>\n",
       "      <td>White</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45UBFQ0003</td>\n",
       "      <td>E00159792</td>\n",
       "      <td>298</td>\n",
       "      <td>White</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45UBFQ0004</td>\n",
       "      <td>E00159793</td>\n",
       "      <td>310</td>\n",
       "      <td>White</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45UBFQ0005</td>\n",
       "      <td>E00159794</td>\n",
       "      <td>289</td>\n",
       "      <td>White</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2001 output area   mnemonic  Observation ethnicity sub_ethnicity\n",
       "0       45UBFQ0001  E00159790          271     White       British\n",
       "1       45UBFQ0002  E00159791          318     White       British\n",
       "2       45UBFQ0003  E00159792          298     White       British\n",
       "3       45UBFQ0004  E00159793          310     White       British\n",
       "4       45UBFQ0005  E00159794          289     White       British"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001['ethnicity'] = melt_2001['Ethnic group'].apply( lambda x: x.split(':')[0])\n",
    "melt_2001['sub_ethnicity'] = melt_2001['Ethnic group'].apply( lambda x: x.split(':')[1])\n",
    "melt_2001.drop('Ethnic group', axis= 1, inplace= True)\n",
    "melt_2001['sub_ethnicity'] = melt_2001['sub_ethnicity'].apply(str.lstrip)\n",
    "melt_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Mixed', 'Asian/Asian British', 'Black/Black British',\n",
       "       'Chinese/Other'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001.ethnicity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_2001['ethnicity'] = melt_2001['ethnicity'].apply(lambda x: 'white' if 'White' in x else\n",
    "                                                                'asian' if 'Asian' in x else \n",
    "                                                                'asian' if 'Chinese' in x else\n",
    "                                                                'black' if 'Black' in x else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001 output area</th>\n",
       "      <th>mnemonic</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45UBFQ0001</td>\n",
       "      <td>E00159790</td>\n",
       "      <td>271</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45UBFQ0002</td>\n",
       "      <td>E00159791</td>\n",
       "      <td>318</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45UBFQ0003</td>\n",
       "      <td>E00159792</td>\n",
       "      <td>298</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45UBFQ0004</td>\n",
       "      <td>E00159793</td>\n",
       "      <td>310</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45UBFQ0005</td>\n",
       "      <td>E00159794</td>\n",
       "      <td>289</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806939</th>\n",
       "      <td>36UCHT0004</td>\n",
       "      <td>E00140745</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806940</th>\n",
       "      <td>36UCHT0005</td>\n",
       "      <td>E00140746</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806941</th>\n",
       "      <td>36UCHT0006</td>\n",
       "      <td>E00140747</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806942</th>\n",
       "      <td>36UCHT0007</td>\n",
       "      <td>E00140748</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806943</th>\n",
       "      <td>36UCHT0008</td>\n",
       "      <td>E00140749</td>\n",
       "      <td>0</td>\n",
       "      <td>asian</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2806944 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2001 output area   mnemonic  Observation ethnicity sub_ethnicity\n",
       "0             45UBFQ0001  E00159790          271     white       British\n",
       "1             45UBFQ0002  E00159791          318     white       British\n",
       "2             45UBFQ0003  E00159792          298     white       British\n",
       "3             45UBFQ0004  E00159793          310     white       British\n",
       "4             45UBFQ0005  E00159794          289     white       British\n",
       "...                  ...        ...          ...       ...           ...\n",
       "2806939       36UCHT0004  E00140745            0     asian         Other\n",
       "2806940       36UCHT0005  E00140746            0     asian         Other\n",
       "2806941       36UCHT0006  E00140747            0     asian         Other\n",
       "2806942       36UCHT0007  E00140748            0     asian         Other\n",
       "2806943       36UCHT0008  E00140749            0     asian         Other\n",
       "\n",
       "[2806944 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['white', 'other', 'asian', 'black'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001.ethnicity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00ABGA0017</td>\n",
       "      <td>E01000031</td>\n",
       "      <td>Barking and Dagenham 002A</td>\n",
       "      <td>E02000003</td>\n",
       "      <td>Barking and Dagenham 002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0002</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AAFA0003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AAFA0004</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OA01CD   LSOA01CD                   LSOA01NM   MSOA01CD  \\\n",
       "0  00AAFA0001  E01000001        City of London 001A  E02000001   \n",
       "1  00ABGA0017  E01000031  Barking and Dagenham 002A  E02000003   \n",
       "2  00AAFA0002  E01000001        City of London 001A  E02000001   \n",
       "3  00AAFA0003  E01000001        City of London 001A  E02000001   \n",
       "4  00AAFA0004  E01000001        City of London 001A  E02000001   \n",
       "\n",
       "                   MSOA01NM  ObjectId  \n",
       "0        City of London 001         1  \n",
       "1  Barking and Dagenham 002         2  \n",
       "2        City of London 001         3  \n",
       "3        City of London 001         4  \n",
       "4        City of London 001         5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_2001= pd.read_csv('Census2001\\\\lookup2001.csv')\n",
    "lookup_2011= pd.read_csv('Census2011\\\\lookup2011.csv', low_memory= False)\n",
    "lookup_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>OA01CDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000051</td>\n",
       "      <td>00ABFX0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000002</td>\n",
       "      <td>00AAFA0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>00AAFA0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000004</td>\n",
       "      <td>00AAFA0004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CD     OA01CDO\n",
       "0  E00000001  00AAFA0001\n",
       "1  E00000051  00ABFX0015\n",
       "2  E00000002  00AAFA0002\n",
       "3  E00000003  00AAFA0003\n",
       "4  E00000004  00AAFA0004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OA01CD and mnemonic in 2001 census data are not the same, so I found a lookup file to connect these dataset\n",
    "# I only selected the columns that I need.\n",
    "connection = pd.read_csv('Census2001\\\\Output_Area_(2001)_to_Output_Area_(2011)_to_Local_Authority_District_(2011)_Lookup_in_England_and_Wales.csv', usecols=['OA01CD','OA01CDO'])\n",
    "connection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181979, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175434, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there were duplicated rows in the connection dataset so I drop them. Now number of rows in the connection file and \n",
    "# data_2001 are the same\n",
    "connection.drop_duplicates(subset= 'OA01CD', inplace= True)\n",
    "connection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>170</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>4</td>\n",
       "      <td>white</td>\n",
       "      <td>Irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>28</td>\n",
       "      <td>white</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black African</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CD     OA01CDO  Observation ethnicity              sub_ethnicity\n",
       "0  E00000001  00AAFA0001          170     white                    British\n",
       "1  E00000001  00AAFA0001            4     white                      Irish\n",
       "2  E00000001  00AAFA0001           28     white                      Other\n",
       "3  E00000001  00AAFA0001            0     other  White and Black Caribbean\n",
       "4  E00000001  00AAFA0001            0     other    White and Black African"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2001 = pd.merge(connection, melt_2001, left_on= 'OA01CD', right_on= 'mnemonic', how= 'left')\n",
    "melt_2001.drop(['mnemonic','2001 output area'], axis= 1, inplace= True)\n",
    "melt_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00ABGA0017</td>\n",
       "      <td>E01000031</td>\n",
       "      <td>Barking and Dagenham 002A</td>\n",
       "      <td>E02000003</td>\n",
       "      <td>Barking and Dagenham 002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0002</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AAFA0003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AAFA0004</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175429</th>\n",
       "      <td>47UGGM0012</td>\n",
       "      <td>E01032482</td>\n",
       "      <td>Wyre Forest 005D</td>\n",
       "      <td>E02006771</td>\n",
       "      <td>Wyre Forest 005</td>\n",
       "      <td>175430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175430</th>\n",
       "      <td>47UGGM0013</td>\n",
       "      <td>E01032482</td>\n",
       "      <td>Wyre Forest 005D</td>\n",
       "      <td>E02006771</td>\n",
       "      <td>Wyre Forest 005</td>\n",
       "      <td>175431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175431</th>\n",
       "      <td>47UGGM0014</td>\n",
       "      <td>E01032481</td>\n",
       "      <td>Wyre Forest 005C</td>\n",
       "      <td>E02006771</td>\n",
       "      <td>Wyre Forest 005</td>\n",
       "      <td>175432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175432</th>\n",
       "      <td>47UGGM0015</td>\n",
       "      <td>E01032481</td>\n",
       "      <td>Wyre Forest 005C</td>\n",
       "      <td>E02006771</td>\n",
       "      <td>Wyre Forest 005</td>\n",
       "      <td>175433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175433</th>\n",
       "      <td>47UGGM0016</td>\n",
       "      <td>E01032481</td>\n",
       "      <td>Wyre Forest 005C</td>\n",
       "      <td>E02006771</td>\n",
       "      <td>Wyre Forest 005</td>\n",
       "      <td>175434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175434 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OA01CD   LSOA01CD                   LSOA01NM   MSOA01CD  \\\n",
       "0       00AAFA0001  E01000001        City of London 001A  E02000001   \n",
       "1       00ABGA0017  E01000031  Barking and Dagenham 002A  E02000003   \n",
       "2       00AAFA0002  E01000001        City of London 001A  E02000001   \n",
       "3       00AAFA0003  E01000001        City of London 001A  E02000001   \n",
       "4       00AAFA0004  E01000001        City of London 001A  E02000001   \n",
       "...            ...        ...                        ...        ...   \n",
       "175429  47UGGM0012  E01032482           Wyre Forest 005D  E02006771   \n",
       "175430  47UGGM0013  E01032482           Wyre Forest 005D  E02006771   \n",
       "175431  47UGGM0014  E01032481           Wyre Forest 005C  E02006771   \n",
       "175432  47UGGM0015  E01032481           Wyre Forest 005C  E02006771   \n",
       "175433  47UGGM0016  E01032481           Wyre Forest 005C  E02006771   \n",
       "\n",
       "                        MSOA01NM  ObjectId  \n",
       "0             City of London 001         1  \n",
       "1       Barking and Dagenham 002         2  \n",
       "2             City of London 001         3  \n",
       "3             City of London 001         4  \n",
       "4             City of London 001         5  \n",
       "...                          ...       ...  \n",
       "175429           Wyre Forest 005    175430  \n",
       "175430           Wyre Forest 005    175431  \n",
       "175431           Wyre Forest 005    175432  \n",
       "175432           Wyre Forest 005    175433  \n",
       "175433           Wyre Forest 005    175434  \n",
       "\n",
       "[175434 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD_x</th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>Observation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "      <th>OA01CD_y</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>170</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>4</td>\n",
       "      <td>white</td>\n",
       "      <td>Irish</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>28</td>\n",
       "      <td>white</td>\n",
       "      <td>Other</td>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OA01CD_x     OA01CDO  Observation ethnicity sub_ethnicity    OA01CD_y  \\\n",
       "0  E00000001  00AAFA0001          170     white       British  00AAFA0001   \n",
       "1  E00000001  00AAFA0001            4     white         Irish  00AAFA0001   \n",
       "2  E00000001  00AAFA0001           28     white         Other  00AAFA0001   \n",
       "\n",
       "    LSOA01CD             LSOA01NM   MSOA01CD            MSOA01NM  ObjectId  \n",
       "0  E01000001  City of London 001A  E02000001  City of London 001         1  \n",
       "1  E01000001  City of London 001A  E02000001  City of London 001         1  \n",
       "2  E01000001  City of London 001A  E02000001  City of London 001         1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2001 = pd.merge(melt_2001, lookup_2001, left_on='OA01CDO', right_on='OA01CD', how= 'left')\n",
    "merged_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>Irish</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>Other</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black Caribbean</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black African</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CDO     OA01CD   LSOA01CD   MSOA01CD             LSOA01NM  \\\n",
       "0  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "1  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "2  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "3  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "4  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "\n",
       "             MSOA01NM ethnicity              sub_ethnicity  Observation  \n",
       "0  City of London 001     white                    British          170  \n",
       "1  City of London 001     white                      Irish            4  \n",
       "2  City of London 001     white                      Other           28  \n",
       "3  City of London 001     other  White and Black Caribbean            0  \n",
       "4  City of London 001     other    White and Black African            0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_order = ['OA01CDO', 'OA01CD_x', 'LSOA01CD', 'MSOA01CD', 'LSOA01NM',  \n",
    "                'MSOA01NM', 'ethnicity', 'sub_ethnicity', 'Observation']\n",
    "merged_2001 = merged_2001[column_order]\n",
    "merged_2001.rename(columns={'OA01CD_x':'OA01CD'}, inplace= True)\n",
    "merged_2001.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column for LAD names in 2001\n",
    "merged_2001['LAD01NM'] = merged_2001['MSOA01NM'].apply(lambda x: re.sub(r'\\d+', '', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying LAD names based on the LAD names in 2011\n",
    "merged_2001['LAD01NM'] = merged_2001['LAD01NM'].apply(lambda x: 'Northumberland' if x == 'Alnwick' else\n",
    "                                                                    'Northumberland' if x == 'Berwick-upon-Tweed' else\n",
    "                                                                    'Northumberland'  if x == 'Blyth Valley' else \n",
    "                                                                    'Shropshire'  if x == 'Bridgnorth' else\n",
    "                                                                    'Bristol, City of'  if x == 'Bristol' else\n",
    "                                                                    'Cornwall' if x == 'Caradon' else\n",
    "                                                                    'Cornwall' if x == 'Carrick' else\n",
    "                                                                    'Northumberland' if x == 'Castle Morpeth' else \n",
    "                                                                    'Cheshire West and Chester' if x == 'Chester' else \n",
    "                                                                    'County Durham' if x == 'Chester-le-Street' else\n",
    "                                                                    'Cheshire West and Chester' if x == 'Congleton' else\n",
    "                                                                    'Cheshire West and Chester' if x == 'Crewe and Nantwich' else\n",
    "                                                                    'County Durham' if x == 'Derwentside' else\n",
    "                                                                    'County Durham' if x == 'Durham' else\n",
    "                                                                    'County Durham' if x == 'Easington' else\n",
    "                                                                    'Cheshire West and Chester' if x == 'Ellesmere Port & Neston' else \n",
    "                                                                    'Herefordshire, County of' if x == 'Herefordshire' else \n",
    "                                                                    'Cornwall' if x == 'Kerrier' else\n",
    "                                                                    'Kingston upon Hull, City of' if x == 'Kingston upon Hull' else\n",
    "                                                                    'Cheshire East' if x == 'Macclesfield' else\n",
    "                                                                    'Rhondda Cynon Taf' if x == 'Rhondda, Cynon, Taff' else\n",
    "                                                                    'Central Bedfordshire' if x == 'Mid Bedfordshire' else\n",
    "                                                                    'Cornwall' if x == 'North Cornwall' else\n",
    "                                                                    'Shropshire' if x == 'North Shropshire' else\n",
    "                                                                    'Wiltshire' if x == 'North Wiltshire' else\n",
    "                                                                    'Shropshire' if x == 'Oswestry' else\n",
    "                                                                    'Cornwall' if x == 'Penwith' else\n",
    "                                                                    'Cornwall' if x == 'Restormel' else\n",
    "                                                                    'Wiltshire' if x == 'Salisbury' else\n",
    "                                                                    'County Durham' if x == 'Sedgefield' else\n",
    "                                                                    'Shropshire' if x == 'Shrewsbury and Atcham' else\n",
    "                                                                    'Central Bedfordshire' if x == 'South Bedfordshire' else\n",
    "                                                                    'Central Bedfordshire' if x == 'Bedfordshire' else\n",
    "                                                                    'Shropshire' if x == 'South Shropshire' else\n",
    "                                                                    'County Durham' if x == 'Teesdale' else\n",
    "                                                                    'Northumberland' if x == 'Tynedale' else\n",
    "                                                                    'Northumberland' if x == 'Wansbeck' else\n",
    "                                                                    'County Durham' if x == 'Wear Valley' else\n",
    "                                                                    'Cheshire West and Chester' if x == 'Vale Royal' else\n",
    "                                                                    'Wiltshire' if x == 'Kennet' else\n",
    "                                                                    'Wiltshire' if x == 'West Wiltshire' else  x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>sub_ethnicity</th>\n",
       "      <th>Observation</th>\n",
       "      <th>LAD01NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>British</td>\n",
       "      <td>170</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>Irish</td>\n",
       "      <td>4</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>white</td>\n",
       "      <td>Other</td>\n",
       "      <td>28</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black Caribbean</td>\n",
       "      <td>0</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>other</td>\n",
       "      <td>White and Black African</td>\n",
       "      <td>0</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CDO     OA01CD   LSOA01CD   MSOA01CD             LSOA01NM  \\\n",
       "0  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "1  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "2  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "3  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "4  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "\n",
       "             MSOA01NM ethnicity              sub_ethnicity  Observation  \\\n",
       "0  City of London 001     white                    British          170   \n",
       "1  City of London 001     white                      Irish            4   \n",
       "2  City of London 001     white                      Other           28   \n",
       "3  City of London 001     other  White and Black Caribbean            0   \n",
       "4  City of London 001     other    White and Black African            0   \n",
       "\n",
       "          LAD01NM  \n",
       "0  City of London  \n",
       "1  City of London  \n",
       "2  City of London  \n",
       "3  City of London  \n",
       "4  City of London  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA11CD</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>LAD11NMW</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E00000005</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E00000007</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E00000010</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA11CD   LSOA11CD             LSOA11NM   MSOA11CD            MSOA11NM  \\\n",
       "0  E00000001  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "1  E00000003  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "2  E00000005  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "3  E00000007  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "4  E00000010  E01000003  City of London 001C  E02000001  City of London 001   \n",
       "\n",
       "     LAD11CD         LAD11NM LAD11NMW  ObjectId  \n",
       "0  E09000001  City of London      NaN         1  \n",
       "1  E09000001  City of London      NaN         2  \n",
       "2  E09000001  City of London      NaN         3  \n",
       "3  E09000001  City of London      NaN         4  \n",
       "4  E09000001  City of London      NaN         5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['British', 'Irish', 'Other', 'White and Black Caribbean',\n",
       "       'White and Black African', 'White and Asian', 'Indian',\n",
       "       'Pakistani', 'Bangladeshi', 'Black Caribbean', 'Black African',\n",
       "       'Chinese'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2001['sub_ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175434"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2001['OA01CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34378"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2001['LSOA01CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7194"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2001['MSOA01CD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_2001['LAD01NM'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>LAD01NM</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>asian</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CDO     OA01CD   LSOA01CD   MSOA01CD             LSOA01NM  \\\n",
       "0  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "1  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "2  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "\n",
       "             MSOA01NM         LAD01NM ethnicity  Observation  \n",
       "0  City of London 001  City of London     asian           10  \n",
       "1  City of London 001  City of London     black            0  \n",
       "2  City of London 001  City of London     other            3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001 = merged_2001.groupby(['OA01CDO','OA01CD', 'LSOA01CD', 'MSOA01CD', 'LSOA01NM',\n",
    "                                      'MSOA01NM', 'LAD01NM','ethnicity'])['Observation'].sum().reset_index()\n",
    "ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian', 'black', 'other', 'white'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001.ethnicity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>LAD01NM</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AAFA0002</td>\n",
       "      <td>E00000002</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0003</td>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CDO     OA01CD   LSOA01CD   MSOA01CD             LSOA01NM  \\\n",
       "0  00AAFA0001  E00000001  E01000001  E02000001  City of London 001A   \n",
       "1  00AAFA0002  E00000002  E01000001  E02000001  City of London 001A   \n",
       "2  00AAFA0003  E00000003  E01000001  E02000001  City of London 001A   \n",
       "\n",
       "             MSOA01NM         LAD01NM  asian  black  other  white  \n",
       "0  City of London 001  City of London     10      0      3    202  \n",
       "1  City of London 001  City of London      6      0      3     92  \n",
       "2  City of London 001  City of London     14      0      4    189  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001 = ethnicity_2001.pivot(index = ['OA01CDO','OA01CD', 'LSOA01CD', 'MSOA01CD', 'LSOA01NM',\n",
    "                                      'MSOA01NM','LAD01NM'], columns = 'ethnicity', values = 'Observation').reset_index().rename_axis(None, axis=1)\n",
    "ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CDO</th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LAD01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>LAD01NM</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00AAFA0001</td>\n",
       "      <td>E00000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AAFA0002</td>\n",
       "      <td>E00000002</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AAFA0003</td>\n",
       "      <td>E00000003</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OA01CDO     OA01CD   LSOA01CD   MSOA01CD    LAD01CD  \\\n",
       "0  00AAFA0001  E00000001  E01000001  E02000001  E09000001   \n",
       "1  00AAFA0002  E00000002  E01000001  E02000001  E09000001   \n",
       "2  00AAFA0003  E00000003  E01000001  E02000001  E09000001   \n",
       "\n",
       "              LSOA01NM            MSOA01NM         LAD01NM  asian  black  \\\n",
       "0  City of London 001A  City of London 001  City of London     10      0   \n",
       "1  City of London 001A  City of London 001  City of London      6      0   \n",
       "2  City of London 001A  City of London 001  City of London     14      0   \n",
       "\n",
       "   other  white  total_pop  \n",
       "0      3    202        215  \n",
       "1      3     92        101  \n",
       "2      4    189        207  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001 = pd.merge(ethnicity_2001, lookup_2011[['LAD11CD', 'LAD11NM']].drop_duplicates(), \n",
    "                          left_on= 'LAD01NM', right_on= 'LAD11NM', how= 'left')\n",
    "\n",
    "ethnicity_2001['total_pop']= ethnicity_2001['white']+ethnicity_2001['asian']+ethnicity_2001['black']+ethnicity_2001['other']\n",
    "ethnicity_2001.rename(columns={'LAD11CD':'LAD01CD'}, inplace= True)\n",
    "\n",
    "column_order = ['OA01CDO', 'OA01CD', 'LSOA01CD', 'MSOA01CD', 'LAD01CD', \n",
    "                'LSOA01NM', 'MSOA01NM', 'LAD01NM', 'asian', 'black', 'other', 'white', 'total_pop'] \n",
    "\n",
    "ethnicity_2001 = ethnicity_2001[column_order]\n",
    "\n",
    "ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52041655"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001[['asian', 'black', 'other','white']].sum(axis= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.drop(columns=['OA01CDO'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\2612407318.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ethnicity_2001['LAD01CD'].fillna('E06000010', inplace= True)\n"
     ]
    }
   ],
   "source": [
    "ethnicity_2001['LAD01CD'].fillna('E06000010', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA01CD</th>\n",
       "      <th>LSOA01CD</th>\n",
       "      <th>MSOA01CD</th>\n",
       "      <th>LAD01CD</th>\n",
       "      <th>LSOA01NM</th>\n",
       "      <th>MSOA01NM</th>\n",
       "      <th>LAD01NM</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64332</th>\n",
       "      <td>E00064333</td>\n",
       "      <td>E01012763</td>\n",
       "      <td>E02002669</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 018C</td>\n",
       "      <td>Kingston upon Hull 018</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>284</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64333</th>\n",
       "      <td>E00064334</td>\n",
       "      <td>E01012761</td>\n",
       "      <td>E02002666</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 015A</td>\n",
       "      <td>Kingston upon Hull 015</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>263</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64334</th>\n",
       "      <td>E00064335</td>\n",
       "      <td>E01012760</td>\n",
       "      <td>E02002676</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 025D</td>\n",
       "      <td>Kingston upon Hull 025</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>274</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64335</th>\n",
       "      <td>E00064336</td>\n",
       "      <td>E01012756</td>\n",
       "      <td>E02002676</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 025A</td>\n",
       "      <td>Kingston upon Hull 025</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>271</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64336</th>\n",
       "      <td>E00064337</td>\n",
       "      <td>E01012763</td>\n",
       "      <td>E02002669</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 018C</td>\n",
       "      <td>Kingston upon Hull 018</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>244</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65161</th>\n",
       "      <td>E00065162</td>\n",
       "      <td>E01012914</td>\n",
       "      <td>E02002663</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 012C</td>\n",
       "      <td>Kingston upon Hull 012</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65162</th>\n",
       "      <td>E00065163</td>\n",
       "      <td>E01012914</td>\n",
       "      <td>E02002663</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 012C</td>\n",
       "      <td>Kingston upon Hull 012</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>457</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65163</th>\n",
       "      <td>E00065164</td>\n",
       "      <td>E01012917</td>\n",
       "      <td>E02002659</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 008F</td>\n",
       "      <td>Kingston upon Hull 008</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>276</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65164</th>\n",
       "      <td>E00065165</td>\n",
       "      <td>E01012915</td>\n",
       "      <td>E02002659</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 008E</td>\n",
       "      <td>Kingston upon Hull 008</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>254</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65165</th>\n",
       "      <td>E00065166</td>\n",
       "      <td>E01012915</td>\n",
       "      <td>E02002659</td>\n",
       "      <td>E06000010</td>\n",
       "      <td>Kingston upon Hull 008E</td>\n",
       "      <td>Kingston upon Hull 008</td>\n",
       "      <td>Kingston upon Hull, City of</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>309</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          OA01CD   LSOA01CD   MSOA01CD    LAD01CD                 LSOA01NM  \\\n",
       "64332  E00064333  E01012763  E02002669  E06000010  Kingston upon Hull 018C   \n",
       "64333  E00064334  E01012761  E02002666  E06000010  Kingston upon Hull 015A   \n",
       "64334  E00064335  E01012760  E02002676  E06000010  Kingston upon Hull 025D   \n",
       "64335  E00064336  E01012756  E02002676  E06000010  Kingston upon Hull 025A   \n",
       "64336  E00064337  E01012763  E02002669  E06000010  Kingston upon Hull 018C   \n",
       "...          ...        ...        ...        ...                      ...   \n",
       "65161  E00065162  E01012914  E02002663  E06000010  Kingston upon Hull 012C   \n",
       "65162  E00065163  E01012914  E02002663  E06000010  Kingston upon Hull 012C   \n",
       "65163  E00065164  E01012917  E02002659  E06000010  Kingston upon Hull 008F   \n",
       "65164  E00065165  E01012915  E02002659  E06000010  Kingston upon Hull 008E   \n",
       "65165  E00065166  E01012915  E02002659  E06000010  Kingston upon Hull 008E   \n",
       "\n",
       "                     MSOA01NM                      LAD01NM  asian  black  \\\n",
       "64332  Kingston upon Hull 018  Kingston upon Hull, City of     16      7   \n",
       "64333  Kingston upon Hull 015  Kingston upon Hull, City of     48      3   \n",
       "64334  Kingston upon Hull 025  Kingston upon Hull, City of     16      0   \n",
       "64335  Kingston upon Hull 025  Kingston upon Hull, City of      0      4   \n",
       "64336  Kingston upon Hull 018  Kingston upon Hull, City of     29      4   \n",
       "...                       ...                          ...    ...    ...   \n",
       "65161  Kingston upon Hull 012  Kingston upon Hull, City of     24      9   \n",
       "65162  Kingston upon Hull 012  Kingston upon Hull, City of     81     20   \n",
       "65163  Kingston upon Hull 008  Kingston upon Hull, City of      3      0   \n",
       "65164  Kingston upon Hull 008  Kingston upon Hull, City of      3      0   \n",
       "65165  Kingston upon Hull 008  Kingston upon Hull, City of      9      0   \n",
       "\n",
       "       other  white  total_pop  \n",
       "64332      6    284        313  \n",
       "64333     14    263        328  \n",
       "64334      3    274        293  \n",
       "64335      6    271        281  \n",
       "64336     17    244        294  \n",
       "...      ...    ...        ...  \n",
       "65161      3    300        336  \n",
       "65162     10    457        568  \n",
       "65163      6    276        285  \n",
       "65164      6    254        263  \n",
       "65165      6    309        324  \n",
       "\n",
       "[834 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Hull')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.to_csv('preprocessed files/2001/ethnicity_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-Ethnicity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2001 = merged_2001.groupby(['OA01CDO','OA01CD', 'LSOA01CD', 'MSOA01CD', 'LSOA01NM',\n",
    "                                      'MSOA01NM','LAD01NM','sub_ethnicity'])['Observation'].sum().reset_index()\n",
    "sub_ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2001 = sub_ethnicity_2001.pivot(index = ['OA01CDO','OA01CD', 'LSOA01CD', 'MSOA01CD', 'LSOA01NM', 'MSOA01NM','LAD01NM'],\n",
    "                                              columns = 'sub_ethnicity', values = 'Observation').reset_index().rename_axis(None, axis=1)\n",
    "sub_ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2001 = pd.merge(sub_ethnicity_2001, lookup_2011[['LAD11CD', 'LAD11NM']].drop_duplicates(), \n",
    "                          left_on= 'LAD01NM', right_on= 'LAD11NM', how= 'left')\n",
    "\n",
    "sub_ethnicity_2001.rename(columns={'LAD11CD':'LAD01CD'}, inplace= True)\n",
    "sub_ethnicity_2001.drop(columns= ['LAD11NM'], axis= 1, inplace= True)\n",
    "column_order = ['OA01CDO', 'OA01CD', 'LSOA01CD', 'MSOA01CD', 'LAD01CD', \n",
    "                'LSOA01NM', 'MSOA01NM', 'LAD01NM'] \n",
    "\n",
    "sub_ethnicity_2001 = sub_ethnicity_2001[column_order + [col for col in sub_ethnicity_2001.columns if col not in column_order]]\n",
    "\n",
    "sub_ethnicity_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2001[['Bangladeshi', 'Black African',\n",
    "       'Black Caribbean', 'British', 'Chinese', 'Indian', 'Irish', 'Other',\n",
    "       'Pakistani', 'White and Asian', 'White and Black African',\n",
    "       'White and Black Caribbean']].sum(axis= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ethnicity_2001.to_csv('preprocessed files/2001/sub_ethnicity_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2001 = gpd.read_file('Census2001\\\\shape_2001\\\\OA_2001_EW_BGC.shp')\n",
    "# shape_2001.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2001 = shape_2001.rename(columns={'geometry': 'OA_geometry'})\n",
    "shape_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2001 = shape_2001.merge(ethnicity_2001[['OA01CD', 'LSOA01CD', 'MSOA01CD', 'LAD01CD']], on = 'OA01CD', how= 'left')\n",
    "shape_column_order = [ 'OA01CD', 'LSOA01CD', 'MSOA01CD', 'LAD01CD', 'GlobalID', 'OA_geometry']\n",
    "shape_2001 = shape_2001[shape_column_order]\n",
    "shape_2001 = gpd.GeoDataFrame(shape_2001, geometry='OA_geometry')\n",
    "shape_2001.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving OA_2001 into a shape file\n",
    "shape_2001.to_file('preprocessed files/2001/OA_2001.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_2001 = gpd.read_file('preprocessed files/2001/OA_2001.shp').set_geometry('geometry')\n",
    "OA_2001.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for LSOA geometry\n",
    "lsoa_geom_2001 = shape_2001.groupby('LSOA01CD')['OA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2001['LSOA_geometry'] = shape_2001['LSOA01CD'].map(lsoa_geom_2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving LSOA_2001 into a shape file\n",
    "LSOA_2001 = shape_2001.groupby('LSOA01CD').agg({'LSOA_geometry': 'first'}).reset_index()\n",
    "LSOA_2001 = LSOA_2001.merge(ethnicity_2001.groupby('LSOA01CD')[['asian', 'black', 'other', 'white']].sum().reset_index(), on='LSOA01CD' ,how= 'left')\n",
    "\n",
    "LSOA_2001['total'] = LSOA_2001['white'] + LSOA_2001['asian']+ LSOA_2001['black']+ LSOA_2001['other']\n",
    "\n",
    "for col in LSOA_2001[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    LSOA_2001[new_name] = round(LSOA_2001[col]/LSOA_2001['total'], 3)\n",
    "\n",
    "LSOA_2001['year'] = 2001\n",
    "LSOA_2001.rename(columns={'LSOA01CD':'LSOACD'}, inplace = True)\n",
    "column_order = ['year', 'LSOACD', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'total', 'LSOA_geometry',]\n",
    "LSOA_2001 = LSOA_2001[column_order]\n",
    "\n",
    "LSOA_2001 = gpd.GeoDataFrame(LSOA_2001, geometry='LSOA_geometry')\n",
    "LSOA_2001.to_file('preprocessed files/2001/LSOA_2001.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_2001 = gpd.read_file('preprocessed files/2001/LSOA_2001.shp').set_geometry('geometry')\n",
    "LSOA_2001.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for MSOA geometry\n",
    "msoa_geom_2001 = shape_2001.groupby('MSOA01CD')['LSOA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2001['MSOA_geometry'] = shape_2001['MSOA01CD'].map(msoa_geom_2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving MSOA_2001 into a shape file\n",
    "MSOA_2001 = shape_2001.groupby('MSOA01CD').agg({'MSOA_geometry': 'first'}).reset_index()\n",
    "MSOA_2001 = MSOA_2001.merge(ethnicity_2001.groupby('MSOA01CD')[['asian', 'black', 'other', 'white']].sum().reset_index(), on='MSOA01CD' ,how= 'left')\n",
    "\n",
    "MSOA_2001['total'] = MSOA_2001['white'] + MSOA_2001['asian']+ MSOA_2001['black']+ MSOA_2001['other']\n",
    "\n",
    "for col in MSOA_2001[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    MSOA_2001[new_name] = round(MSOA_2001[col]/MSOA_2001['total'], 3)\n",
    "\n",
    "MSOA_2001['year'] = 2001\n",
    "MSOA_2001.rename(columns={'MSOA01CD':'MSOACD'}, inplace = True)\n",
    "column_order = ['year', 'MSOACD', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'total', 'MSOA_geometry',]\n",
    "MSOA_2001 = MSOA_2001[column_order]\n",
    "\n",
    "MSOA_2001 = gpd.GeoDataFrame(MSOA_2001, geometry='MSOA_geometry')\n",
    "MSOA_2001.to_file('preprocessed files/2001/MSOA_2001.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_2001 = gpd.read_file('preprocessed files/2001/MSOA_2001.shp').set_geometry('geometry')\n",
    "MSOA_2001.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new culumns in shape file for LAD geometry\n",
    "lad_geom_2001 = shape_2001.groupby('LAD01CD')['MSOA_geometry'].agg(lambda x: x.unary_union)\n",
    "shape_2001['LAD_geometry'] = shape_2001['LAD01CD'].map(lad_geom_2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order t have better and clearer borders of LAD, I took border info from another files and mixed it with LAD borders of 2021\n",
    "# For the LADs that geometry was unavailable in new_borders, I took LAD geopmetry from year 2011\n",
    "new_borders = gpd.read_file('May_2020_Boundaries/LAD_May_2020_Boundaries_UK_BFE_2022_4839426458879395509.geojson')\n",
    "LAD_2011 = gpd.read_file('preprocessed files/2011/LAD_2011.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving LAD_2001 into a shape file\n",
    "LAD_2001 = shape_2001.groupby('LAD01CD').agg({'LAD_geometry': 'first'}).reset_index()\n",
    "LAD_2001 = LAD_2001.merge(ethnicity_2001.groupby(['LAD01CD', 'LAD01NM'])[['asian', 'black', 'other', 'white']].sum().reset_index(), on='LAD01CD' ,how= 'left')\n",
    "LAD_2001['LAD_pop'] = LAD_2001['white'] + LAD_2001['asian']+ LAD_2001['black']+ LAD_2001['other']\n",
    "\n",
    "for col in LAD_2001[['asian', 'black', 'other', 'white']]:\n",
    "    new_name = col + '_fraction'\n",
    "    LAD_2001[new_name] = round(LAD_2001[col]/LAD_2001['LAD_pop'], 3)\n",
    "\n",
    "LAD_2001['year'] = 2001\n",
    "LAD_2001.rename(columns={'LAD01CD':'LADCD', 'LAD01NM':'LADNM'}, inplace = True)\n",
    "column_order = ['year', 'LADCD', 'LADNM', 'white', 'asian', 'black', 'other',\n",
    "                'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'LAD_pop', 'LAD_geometry']\n",
    "LAD_2001 = LAD_2001[column_order]\n",
    "\n",
    "LAD_2001 =  pd.merge(LAD_2001, new_borders[['lad20nm', 'geometry']], left_on= 'LADNM',right_on='lad20nm', how= 'left')\n",
    "LAD_2001 =  LAD_2001.merge(LAD_2011[['LADNM','LADCD', 'geometry']], on= 'LADNM', how= 'left')\n",
    "\n",
    "LAD_2001['geometry']= LAD_2001['geometry_x'].fillna(LAD_2001['geometry_y'])\n",
    "LAD_2001.drop(columns=['LAD_geometry','lad20nm','geometry_x', 'LADCD_y', 'geometry_y'], axis= 1,inplace= True)\n",
    "LAD_2001.rename(columns={'LADCD_x':'LADCD','geometry':'LAD_geometry'}, inplace= True)\n",
    "\n",
    "LAD_2001 = gpd.GeoDataFrame(LAD_2001, geometry='LAD_geometry')\n",
    "LAD_2001.to_file('preprocessed files/2001/LAD_2001.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2001 = gpd.read_file('preprocessed files/2001/LAD_2001.shp').set_geometry('geometry')\n",
    "LAD_2001.set_geometry('geometry')\n",
    "LAD_2001.plot(alpha=0.5, edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpson Index at coutry level in 2001\n",
    "OA_simp_2001 = simpson(ethnicity_2001[['white','asian','black','other']])\n",
    "LSOA_simp_2001 = simpson(ethnicity_2001.groupby(['LSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_simp_2001 = simpson(ethnicity_2001.groupby(['MSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_simp_2001 = simpson(ethnicity_2001.groupby(['LAD01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "\n",
    "country_dic_sim_2001 = {'OA':OA_simp_2001[0], 'LSOA':LSOA_simp_2001[0],\n",
    "                        'MSOA':MSOA_simp_2001[0], 'LAD':LAD_simp_2001[0], 'country':LAD_simp_2001[1]}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'total_population': ethnicity_2001['total_pop'].sum(),\n",
    "              'white_frac': round(ethnicity_2001['white'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'asian_frac': round(ethnicity_2001['asian'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'black_frac': round(ethnicity_2001['black'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'other_frac': round(ethnicity_2001['other'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'OA':OA_simp_2001[0], 'LSOA':LSOA_simp_2001[0],'MSOA':MSOA_simp_2001[0], 'LAD':LAD_simp_2001[0], 'country':LAD_simp_2001[1]}]\n",
    "\n",
    "country_simpson_2001 = pd.DataFrame(flat_dict)\n",
    "country_simpson_2001.to_csv('preprocessed files/2001/country_simpson_2001.csv', index= False)\n",
    "country_simpson_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# Creating LAD level simpson index dataset for year 2001.\n",
    "# Calculating OA, LSOA and MSOA level simpson index inside each LAD\n",
    "LAD_list_2001= ethnicity_2001['LAD01CD'].unique()\n",
    "LAD_dic = {}\n",
    "for LAD in LAD_list_2001:\n",
    "    df = ethnicity_2001[ethnicity_2001['LAD01CD'] == LAD].reset_index(drop= True)\n",
    "    OA_LADsimp_2001 = simpson(df[['white','asian','black','other']])\n",
    "    LSOA_LADsimp_2001 = simpson(df.groupby(['LSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    MSOA_LADsimp_2001 = simpson(df.groupby(['MSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    LAD_dic[LAD] = {'OA':OA_LADsimp_2001, 'LSOA':LSOA_LADsimp_2001,'MSOA':MSOA_LADsimp_2001}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'LADCD': key, \n",
    "              'OA': value['OA'][0], 'LSOA': value['LSOA'][0],\n",
    "              'MSOA': value['MSOA'][0], 'LAD': value['MSOA'][1]} for key, value in LAD_dic.items()]\n",
    "\n",
    "LAD_simpson_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_simpson_2001 = LAD_simpson_2001.merge(\n",
    "                         LAD_2001.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "\n",
    "LAD_simpson_2001.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population',\n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac', \n",
    "                'OA', 'LSOA', 'MSOA', 'LAD']\n",
    "\n",
    "LAD_simpson_2001 = LAD_simpson_2001[column_order]\n",
    "LAD_simpson_2001.to_csv('preprocessed files/2001/LAD_simpson_2001.csv', index= False)\n",
    "LAD_simpson_2001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_borders_2001 = {}\n",
    "\n",
    "for idx, row in shape_2001.groupby('LAD01CD').agg({'LAD_geometry': 'first'}).iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in shape_2001.groupby('LAD01CD').agg({'LAD_geometry': 'first'}).iterrows():\n",
    "        if idx != idx2:\n",
    "            if row.LAD_geometry.intersects(row2.LAD_geometry):\n",
    "                borders.append(idx2)\n",
    "    LAD_borders_2001[idx] = borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/LAD_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(LAD_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_borders_2001 = {}\n",
    "for lad_code in shape_2001['LAD01CD'].unique():\n",
    "    df_lad = shape_2001[shape_2001['LAD01CD'] == lad_code]\n",
    "    MSOA_borders_2001[lad_code] = {}\n",
    "    df_msoa =df_lad.groupby('MSOA01CD').agg({'MSOA_geometry': 'first'})\n",
    "    for idx, row in df_msoa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_msoa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['MSOA_geometry'].intersects(row2['MSOA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        MSOA_borders_2001[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/MSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(MSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_borders_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_borders_2001 = {}\n",
    "for lad_code in shape_2001['LAD01CD'].unique():\n",
    "    df_lad = shape_2001[shape_2001['LAD01CD'] == lad_code]\n",
    "    LSOA_borders_2001[lad_code] = {}\n",
    "    df_lsoa =df_lad.groupby('LSOA01CD').agg({'LSOA_geometry': 'first'})\n",
    "    for idx, row in df_lsoa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_lsoa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['LSOA_geometry'].intersects(row2['LSOA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        LSOA_borders_2001[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_borders_2001 = {}\n",
    "for lad_code in shape_2001['LAD01CD'].unique():\n",
    "    df_lad = shape_2001[shape_2001['LAD01CD'] == lad_code]\n",
    "    OA_borders_2001[lad_code] = {}\n",
    "    df_oa = df_lad.set_index('OA01CD')\n",
    "    for idx, row in df_oa.iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in df_oa.iterrows():\n",
    "            if idx != idx2:\n",
    "                if row['OA_geometry'].intersects(row2['OA_geometry']):\n",
    "                    borders.append(idx2)\n",
    "        OA_borders_2001[lad_code][idx] = borders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating country level dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA, MSOA and LAD level dissimilarity index inside england\n",
    "\n",
    "OA_diss_2001 = dissimilarity(ethnicity_2001[['white','asian','black','other']])\n",
    "LSOA_diss_2001 = dissimilarity(ethnicity_2001.groupby(['LSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_diss_2001 = dissimilarity(ethnicity_2001.groupby(['MSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_diss_2001 = dissimilarity(ethnicity_2001.groupby(['LAD01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "country_dic_diss_2001 = {'OA_level':OA_diss_2001, 'LSOA_level':LSOA_diss_2001,\n",
    "                        'MSOA_level':MSOA_diss_2001, 'LAD_level':LAD_diss_2001}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'total_population': ethnicity_2001['total_pop'].sum(),\n",
    "              'white_frac': round(ethnicity_2001['white'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'asian_frac': round(ethnicity_2001['asian'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'black_frac': round(ethnicity_2001['black'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'other_frac': round(ethnicity_2001['other'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'OA_white': country_dic_diss_2001['OA_level']['white'], 'LSOA_white': country_dic_diss_2001['LSOA_level']['white'],\n",
    "              'MSOA_white': country_dic_diss_2001['MSOA_level']['white'], 'LAD_white': country_dic_diss_2001['LAD_level']['white'],\n",
    "              'OA_asian': country_dic_diss_2001['OA_level']['asian'], 'LSOA_asian': country_dic_diss_2001['LSOA_level']['asian'],\n",
    "              'MSOA_asian': country_dic_diss_2001['MSOA_level']['asian'], 'LAD_asian': country_dic_diss_2001['LAD_level']['asian'],\n",
    "              'OA_black': country_dic_diss_2001['OA_level']['black'], 'LSOA_black': country_dic_diss_2001['LSOA_level']['black'],\n",
    "              'MSOA_black': country_dic_diss_2001['MSOA_level']['black'], 'LAD_black': country_dic_diss_2001['LAD_level']['black'],\n",
    "              'OA_other': country_dic_diss_2001['OA_level']['other'], 'LSOA_other': country_dic_diss_2001['LSOA_level']['other'],\n",
    "              'MSOA_other': country_dic_diss_2001['MSOA_level']['other'], 'LAD_other': country_dic_diss_2001['LAD_level']['other']}]\n",
    "\n",
    "\n",
    "country_dissimilarity_2001 = pd.DataFrame(flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating london level dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA, MSOA and LAD level dissimilarity index inside london\n",
    "df = ethnicity_2001[ethnicity_2001['']]\n",
    "\n",
    "OA_diss_london_2001 = dissimilarity(ethnicity_2001[['white','asian','black','other']])\n",
    "LSOA_diss_london_2001 = dissimilarity(ethnicity_2001.groupby(['LSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_diss_london_2001 = dissimilarity(ethnicity_2001.groupby(['MSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_diss_london_2001 = dissimilarity(ethnicity_2001.groupby(['LAD01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "country_dic_diss_2001 = {'OA_level':OA_diss_2001, 'LSOA_level':LSOA_diss_2001,\n",
    "                        'MSOA_level':MSOA_diss_2001, 'LAD_level':LAD_diss_2001}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'total_population': ethnicity_2001['total_pop'].sum(),\n",
    "              'white_frac': round(ethnicity_2001['white'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'asian_frac': round(ethnicity_2001['asian'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'black_frac': round(ethnicity_2001['black'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'other_frac': round(ethnicity_2001['other'].sum()/ethnicity_2001['total_pop'].sum(),3),\n",
    "              'OA_white': country_dic_diss_2001['OA_level']['white'], 'LSOA_white': country_dic_diss_2001['LSOA_level']['white'],\n",
    "              'MSOA_white': country_dic_diss_2001['MSOA_level']['white'], 'LAD_white': country_dic_diss_2001['LAD_level']['white'],\n",
    "              'OA_asian': country_dic_diss_2001['OA_level']['asian'], 'LSOA_asian': country_dic_diss_2001['LSOA_level']['asian'],\n",
    "              'MSOA_asian': country_dic_diss_2001['MSOA_level']['asian'], 'LAD_asian': country_dic_diss_2001['LAD_level']['asian'],\n",
    "              'OA_black': country_dic_diss_2001['OA_level']['black'], 'LSOA_black': country_dic_diss_2001['LSOA_level']['black'],\n",
    "              'MSOA_black': country_dic_diss_2001['MSOA_level']['black'], 'LAD_black': country_dic_diss_2001['LAD_level']['black'],\n",
    "              'OA_other': country_dic_diss_2001['OA_level']['other'], 'LSOA_other': country_dic_diss_2001['LSOA_level']['other'],\n",
    "              'MSOA_other': country_dic_diss_2001['MSOA_level']['other'], 'LAD_other': country_dic_diss_2001['LAD_level']['other']}]\n",
    "\n",
    "\n",
    "country_dissimilarity_2001 = pd.DataFrame(flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dissimilarity_2001.to_csv('preprocessed files/2001/country_dissimilarity_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LAD level dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA and MSOA level dissimilarity index inside each LAD\n",
    "LAD_list_2001= ethnicity_2001['LAD01CD'].unique()\n",
    "LAD_dic_diss_2001 = {}\n",
    "for LAD in LAD_list_2001:\n",
    "    df = ethnicity_2001[ethnicity_2001['LAD01CD'] == LAD].reset_index(drop= True)\n",
    "    OA_diss_2001 = dissimilarity(df[['white','asian','black','other']])\n",
    "    LSOA_diss_2001 = dissimilarity(df.groupby(['LSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    MSOA_diss_2001 = dissimilarity(df.groupby(['MSOA01CD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "    LAD_dic_diss_2001[LAD] = {'OA_level':OA_diss_2001, 'LSOA_level':LSOA_diss_2001, 'MSOA_level':MSOA_diss_2001,}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'LADCD': key,\n",
    "              'OA_white': value['OA_level']['white'], 'LSOA_white': value['LSOA_level']['white'], 'MSOA_white': value['MSOA_level']['white'],\n",
    "              'OA_asian': value['OA_level']['asian'], 'LSOA_asian': value['LSOA_level']['asian'], 'MSOA_asian': value['MSOA_level']['asian'],\n",
    "              'OA_black': value['OA_level']['black'], 'LSOA_black': value['LSOA_level']['black'], 'MSOA_black': value['MSOA_level']['black'],\n",
    "              'OA_other': value['OA_level']['other'], 'LSOA_other': value['LSOA_level']['other'], 'MSOA_other': value['MSOA_level']['other'],\n",
    "              } for key, value in LAD_dic_diss_2001.items()]\n",
    "\n",
    "LAD_dissimilarity_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_dissimilarity_2001 = LAD_dissimilarity_2001.merge(\n",
    "                         LAD_2001.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "LAD_dissimilarity_2001.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "# LAD_dissimilarity_2001.drop(['LAD'], axis= 1, inplace= True)\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population',\n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac',\n",
    "                'OA_white', 'LSOA_white', 'MSOA_white',\n",
    "                'OA_asian', 'LSOA_asian', 'MSOA_asian',\n",
    "                'OA_black', 'LSOA_black', 'MSOA_black',\n",
    "                'OA_other', 'LSOA_other', 'MSOA_other']\n",
    "\n",
    "LAD_dissimilarity_2001 = LAD_dissimilarity_2001[column_order]\n",
    "LAD_dissimilarity_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_dissimilarity_2001.to_csv('preprocessed files/2001/LAD_dissimilarity_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2001 = gpd.read_file('preprocessed files/2001/LAD_2001.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/OA_borders_2001.pkl', 'rb') as f:\n",
    "    OA_borders_2001 = pickle.load(f)\n",
    "with open('preprocessed files/2001/LSOA_borders_2001.pkl', 'rb') as f:\n",
    "    LSOA_borders_2001 = pickle.load(f)\n",
    "with open('preprocessed files/2001/MSOA_borders_2001.pkl', 'rb') as f:\n",
    "    MSOA_borders_2001 = pickle.load(f)\n",
    "with open('preprocessed files/2001/LAD_borders_2001.pkl', 'rb') as f:\n",
    "    LAD_borders_2001 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LAD level dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA and MSOA level dissimilarity index inside each LAD\n",
    "LAD_list_2001= ethnicity_2001['LAD01CD'].unique()\n",
    "LAD_dic_mor_2001 = {}\n",
    "for LAD in LAD_list_2001:\n",
    "    df = ethnicity_2001[ethnicity_2001['LAD01CD'] == LAD].reset_index(drop= True)\n",
    "    OA_mor_2001 = moran(df[['OA01CD','white','asian','black','other']].set_index('OA01CD'),OA_borders_2001[LAD])\n",
    "    LSOA_mor_2001 = moran(df.groupby(['LSOA01CD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],LSOA_borders_2001[LAD])\n",
    "    MSOA_mor_2001 = moran(df.groupby(['MSOA01CD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],MSOA_borders_2001[LAD])\n",
    "    LAD_dic_mor_2001[LAD] = {'OA_level':OA_mor_2001, 'LSOA_level':LSOA_mor_2001, 'MSOA_level':MSOA_mor_2001}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'LADCD': key,\n",
    "              'OA_white': value['OA_level']['white'], 'LSOA_white': value['LSOA_level']['white'], 'MSOA_white': value['MSOA_level']['white'],\n",
    "              'OA_asian': value['OA_level']['asian'], 'LSOA_asian': value['LSOA_level']['asian'], 'MSOA_asian': value['MSOA_level']['asian'],\n",
    "              'OA_black': value['OA_level']['black'], 'LSOA_black': value['LSOA_level']['black'], 'MSOA_black': value['MSOA_level']['black'],\n",
    "              'OA_other': value['OA_level']['other'], 'LSOA_other': value['LSOA_level']['other'], 'MSOA_other': value['MSOA_level']['other'],\n",
    "              } for key, value in LAD_dic_mor_2001.items()]\n",
    "\n",
    "LAD_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "LAD_moran_2001 = LAD_moran_2001.merge(\n",
    "                         LAD_2001.groupby(['LADCD','LADNM'])[['LAD_pop','white_frac','asian_frac','black_frac','other_frac']].sum().reset_index(),\n",
    "                         on= 'LADCD', how='left')\n",
    "LAD_moran_2001.rename(columns = {'LAD_pop': 'LAD_population'} ,inplace= True)\n",
    "\n",
    "column_order = ['year', 'LADNM', 'LADCD', 'LAD_population', \n",
    "                'white_frac', 'asian_frac', 'black_frac', 'other_frac',\n",
    "                'OA_white', 'LSOA_white', 'MSOA_white',\n",
    "                'OA_asian', 'LSOA_asian', 'MSOA_asian',\n",
    "                'OA_black', 'LSOA_black', 'MSOA_black',\n",
    "                'OA_other', 'LSOA_other', 'MSOA_other']\n",
    "\n",
    "LAD_moran_2001 = LAD_moran_2001[column_order]\n",
    "LAD_moran_2001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_moran_2001.to_csv('preprocessed files/2001/LAD_moran_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.groupby(['LSOA01CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.groupby(['MSOA01CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.groupby(['LAD01CD'])['total_pop'].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_2001.groupby(['MSOA01CD'])['LSOA01CD'].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_2001 = gpd.read_file('preprocessed files/2001/OA_2001.shp')\n",
    "OA_2011 = gpd.read_file('preprocessed files/2011/OA_2011.shp')\n",
    "OA_2021 = gpd.read_file('preprocessed files/2021/OA_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  birmingham_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  birmingham_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leicester_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leicester_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bradford_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bradford_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blackburn_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blackburn_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oldham_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oldham_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pendle_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pendle_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_2001['year']= '2001'\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_8172\\4214092546.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  london_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n"
     ]
    }
   ],
   "source": [
    "# Creating city datasets\n",
    "birmingham_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Birmingham')]\n",
    "birmingham_2001['year']= '2001'\n",
    "birmingham_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "birmingham_2001 = pd.merge(birmingham_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "birmingham_2001['geometry'] = birmingham_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(birmingham_2001['geometry'])\n",
    "birmingham_2001['geometry'] = birmingham_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(birmingham_2001['geometry'])\n",
    "\n",
    "cols = list(birmingham_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "birmingham_2001 = birmingham_2001[cols]\n",
    "# birmingham_2001 = birmingham_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "birmingham_2001 = birmingham_2001.set_geometry('geometry')\n",
    "\n",
    "leicester_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Leicester') &\n",
    "                                ~ethnicity_2001['LAD01NM'].str.contains('North West Leicestershire')]\n",
    "leicester_2001['year']= '2001'\n",
    "leicester_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "leicester_2001 = pd.merge(leicester_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "leicester_2001['geometry'] = leicester_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(leicester_2001['geometry'])\n",
    "leicester_2001['geometry'] = leicester_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(leicester_2001['geometry'])\n",
    "\n",
    "cols = list(leicester_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "leicester_2001 = leicester_2001[cols]\n",
    "# leicester_2001 = leicester_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "leicester_2001 = leicester_2001.set_geometry('geometry')\n",
    "\n",
    "bradford_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Bradford')]\n",
    "bradford_2001['year']= '2001'\n",
    "bradford_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "bradford_2001 = pd.merge(bradford_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "bradford_2001['geometry'] = bradford_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(bradford_2001['geometry'])\n",
    "bradford_2001['geometry'] = bradford_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(bradford_2001['geometry'])\n",
    "\n",
    "cols = list(bradford_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "bradford_2001 = bradford_2001[cols]\n",
    "# bradford_2001 = bradford_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "bradford_2001 = bradford_2001.set_geometry('geometry')\n",
    "\n",
    "blackburn_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Blackburn')]\n",
    "blackburn_2001['year']= '2001'\n",
    "blackburn_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "blackburn_2001 = pd.merge(blackburn_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "blackburn_2001['geometry'] = blackburn_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(blackburn_2001['geometry'])\n",
    "blackburn_2001['geometry'] = blackburn_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(blackburn_2001['geometry'])\n",
    "\n",
    "cols = list(blackburn_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "blackburn_2001 = blackburn_2001[cols]\n",
    "# blackburn_2001 = blackburn_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "blackburn_2001 = blackburn_2001.set_geometry('geometry')\n",
    "\n",
    "oldham_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Oldham')]\n",
    "oldham_2001['year']= '2001'\n",
    "oldham_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "oldham_2001 = pd.merge(oldham_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "oldham_2001['geometry'] = oldham_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(oldham_2001['geometry'])\n",
    "oldham_2001['geometry'] = oldham_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(oldham_2001['geometry'])\n",
    "\n",
    "cols = list(oldham_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "oldham_2001 = oldham_2001[cols]\n",
    "# oldham_2001 = oldham_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "oldham_2001 = oldham_2001.set_geometry('geometry')\n",
    "\n",
    "pendle_2001= ethnicity_2001[ethnicity_2001['LAD01NM'].str.contains('Pendle')]\n",
    "pendle_2001['year']= '2001'\n",
    "pendle_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "pendle_2001 = pd.merge(pendle_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "pendle_2001['geometry'] = pendle_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(pendle_2001['geometry'])\n",
    "pendle_2001['geometry'] = pendle_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(pendle_2001['geometry'])\n",
    "\n",
    "cols = list(pendle_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "pendle_2001 = pendle_2001[cols]\n",
    "# pendle_2001 = pendle_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "pendle_2001 = pendle_2001.set_geometry('geometry')\n",
    "\n",
    "london_2001= ethnicity_2001[ethnicity_2001.LAD01CD.str.extract('([a-zA-Z]+)([^a-zA-Z]+)', expand=True)[1].astype(int).between(9000001,9000034)]\n",
    "london_2001['year']= '2001'\n",
    "london_2001.rename(columns={'OA01CD':'OACD', 'LSOA01CD':'LSOACD', 'MSOA01CD':'MSOACD', 'LAD01CD':'LADCD',\n",
    "                        'LSOA01NM':'LSOANM', 'MSOA01NM':'MSOANM', 'LAD01NM':'LADNM'}, inplace=True)\n",
    "\n",
    "london_2001 = pd.merge(london_2001,OA_2021[['OA21CD','geometry']], left_on='OACD', right_on='OA21CD', how= 'left').drop(['OA21CD'], axis = 1)\n",
    "london_2001['geometry'] = london_2001['OACD'].map(OA_2011.set_index('OA11CD')['geometry']).fillna(london_2001['geometry'])\n",
    "london_2001['geometry'] = london_2001['OACD'].map(OA_2001.set_index('OA01CD')['geometry']).fillna(london_2001['geometry'])\n",
    "\n",
    "cols = list(london_2001.columns)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "london_2001 = london_2001[cols]\n",
    "# london_2001 = london_2001.drop(['LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM'], axis= 1)\n",
    "london_2001 = london_2001.set_geometry('geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Columns\n",
    "ethnicity_list = ['asian', 'black', 'other', 'white']\n",
    "col_order = ['year', 'OACD', 'LSOACD', 'MSOACD', 'LADCD', 'LSOANM', 'MSOANM', 'LADNM', 'OA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_2001[f'{ethnicity}_fraction'] = round(birmingham_2001[ethnicity]/birmingham_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in birmingham_2001['OACD']:\n",
    "    df = birmingham_2001[birmingham_2001['OACD']== OA]\n",
    "    birmingham_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(birmingham_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_2001['OA_simpson']= OA_simpson\n",
    "birmingham_2001 = birmingham_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_2001[f'{ethnicity}_fraction'] = round(leicester_2001[ethnicity]/leicester_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in leicester_2001['OACD']:\n",
    "    df = leicester_2001[leicester_2001['OACD']== OA]\n",
    "    leicester_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(leicester_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_2001['OA_simpson']= OA_simpson\n",
    "leicester_2001 = leicester_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_2001[f'{ethnicity}_fraction'] = round(bradford_2001[ethnicity]/bradford_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in bradford_2001['OACD']:\n",
    "    df = bradford_2001[bradford_2001['OACD']== OA]\n",
    "    bradford_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(bradford_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_2001['OA_simpson']= OA_simpson\n",
    "bradford_2001 = bradford_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_2001[f'{ethnicity}_fraction'] = round(blackburn_2001[ethnicity]/blackburn_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in blackburn_2001['OACD']:\n",
    "    df = blackburn_2001[blackburn_2001['OACD']== OA]\n",
    "    blackburn_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(blackburn_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_2001['OA_simpson']= OA_simpson\n",
    "blackburn_2001 = blackburn_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_2001[f'{ethnicity}_fraction'] = round(oldham_2001[ethnicity]/oldham_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in oldham_2001['OACD']:\n",
    "    df = oldham_2001[oldham_2001['OACD']== OA]\n",
    "    oldham_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(oldham_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_2001['OA_simpson']= OA_simpson\n",
    "oldham_2001 = oldham_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_2001[f'{ethnicity}_fraction'] = round(pendle_2001[ethnicity]/pendle_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in pendle_2001['OACD']:\n",
    "    df = pendle_2001[pendle_2001['OACD']== OA]\n",
    "    pendle_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(pendle_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_2001['OA_simpson']= OA_simpson\n",
    "pendle_2001 = pendle_2001[col_order]\n",
    "\n",
    "# Creating OA_simpson and fraction columns\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_2001[f'{ethnicity}_fraction'] = round(london_2001[ethnicity]/london_2001['total_pop'],3)\n",
    "OA_simpson = []\n",
    "for OA in london_2001['OACD']:\n",
    "    df = london_2001[london_2001['OACD']== OA]\n",
    "    london_OA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))[0]\n",
    "    OA_simpson.append(london_OA_simpson)\n",
    "\n",
    "# Reordering the columns\n",
    "london_2001['OA_simpson']= OA_simpson\n",
    "london_2001 = london_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_2001.to_csv('preprocessed files/2001/birmingham_2001.csv', index= False)\n",
    "leicester_2001.to_csv('preprocessed files/2001/leicester_2001.csv', in1.to_csv('preprocessed files/2001/bradford_2001.csv', index= False)dex= False)\n",
    "bradford_200\n",
    "blackburn_2001.to_csv('preprocessed files/2001/blackburn_2001.csv', index= False)\n",
    "oldham_2001.to_csv('preprocessed files/2001/oldham_2001.csv', index= False)\n",
    "pendle_2001.to_csv('preprocessed files/2001/pendle_2001.csv', index= False)\n",
    "london_2001.to_csv('preprocessed files/2001/london_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSOA_2001 = gpd.read_file('preprocessed files/2001/LSOA_2001.shp')\n",
    "LSOA_2011 = gpd.read_file('preprocessed files/2011/LSOA_2011.shp')\n",
    "LSOA_2021 = gpd.read_file('preprocessed files/2021/LSOA_2021.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin city LSOA datasets\n",
    "birmingham_LSOA_2001 = birmingham_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "birmingham_LSOA_2001['geometry'] = birmingham_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(birmingham_LSOA_2001['geometry'])\n",
    "birmingham_LSOA_2001['geometry'] = birmingham_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(birmingham_LSOA_2001['geometry'])\n",
    "birmingham_LSOA_2001= birmingham_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "leicester_LSOA_2001 = leicester_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "leicester_LSOA_2001['geometry'] = leicester_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(leicester_LSOA_2001['geometry'])\n",
    "leicester_LSOA_2001['geometry'] = leicester_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(leicester_LSOA_2001['geometry'])\n",
    "leicester_LSOA_2001= leicester_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "bradford_LSOA_2001 = bradford_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "bradford_LSOA_2001['geometry'] = bradford_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(bradford_LSOA_2001['geometry'])\n",
    "bradford_LSOA_2001['geometry'] = bradford_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(bradford_LSOA_2001['geometry'])\n",
    "bradford_LSOA_2001= bradford_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "blackburn_LSOA_2001 = blackburn_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "blackburn_LSOA_2001['geometry'] = blackburn_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(blackburn_LSOA_2001['geometry'])\n",
    "blackburn_LSOA_2001['geometry'] = blackburn_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(blackburn_LSOA_2001['geometry'])\n",
    "blackburn_LSOA_2001= blackburn_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "oldham_LSOA_2001 = oldham_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "oldham_LSOA_2001['geometry'] = oldham_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(oldham_LSOA_2001['geometry'])\n",
    "oldham_LSOA_2001['geometry'] = oldham_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(oldham_LSOA_2001['geometry'])\n",
    "oldham_LSOA_2001= oldham_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "pendle_LSOA_2001 = pendle_2001.groupby(['LSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "pendle_LSOA_2001['geometry'] = pendle_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(pendle_LSOA_2001['geometry'])\n",
    "pendle_LSOA_2001['geometry'] = pendle_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(pendle_LSOA_2001['geometry'])\n",
    "pendle_LSOA_2001= pendle_LSOA_2001.set_geometry('geometry')\n",
    "\n",
    "london_LSOA_2001 = london_2001.groupby(['LSOACD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(LSOA_2021[['LSOACD','geometry']], on='LSOACD', how= 'left')\n",
    "london_LSOA_2001['geometry'] = london_LSOA_2001['LSOACD'].map(LSOA_2011.set_index('LSOACD')['geometry']).fillna(london_LSOA_2001['geometry'])\n",
    "london_LSOA_2001['geometry'] = london_LSOA_2001['LSOACD'].map(LSOA_2001.set_index('LSOACD')['geometry']).fillna(london_LSOA_2001['geometry'])\n",
    "london_LSOA_2001= london_LSOA_2001.set_geometry('geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['year', 'LSOACD', 'LSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "birmingham_LSOA_2001['total_pop'] = (birmingham_LSOA_2001['white'] + birmingham_LSOA_2001['asian'] +\n",
    "                                     birmingham_LSOA_2001['black'] + birmingham_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_LSOA_2001[f'{ethnicity}_fraction'] = round(birmingham_LSOA_2001[ethnicity]/birmingham_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in birmingham_LSOA_2001['LSOACD']:\n",
    "    df = birmingham_LSOA_2001[birmingham_LSOA_2001['LSOACD']== LSOA]\n",
    "    birmingham_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(birmingham_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "birmingham_LSOA_2001 = birmingham_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "leicester_LSOA_2001['total_pop'] = (leicester_LSOA_2001['white'] + leicester_LSOA_2001['asian'] +\n",
    "                                    leicester_LSOA_2001['black'] + leicester_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_LSOA_2001[f'{ethnicity}_fraction'] = round(leicester_LSOA_2001[ethnicity]/leicester_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in leicester_LSOA_2001['LSOACD']:\n",
    "    df = leicester_LSOA_2001[leicester_LSOA_2001['LSOACD']== LSOA]\n",
    "    leicester_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(leicester_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "leicester_LSOA_2001 = leicester_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "bradford_LSOA_2001['total_pop'] = (bradford_LSOA_2001['white'] + bradford_LSOA_2001['asian'] +\n",
    "                                   bradford_LSOA_2001['black'] + bradford_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_LSOA_2001[f'{ethnicity}_fraction'] = round(bradford_LSOA_2001[ethnicity]/bradford_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in bradford_LSOA_2001['LSOACD']:\n",
    "    df = bradford_LSOA_2001[bradford_LSOA_2001['LSOACD']== LSOA]\n",
    "    bradford_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(bradford_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "bradford_LSOA_2001 = bradford_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "blackburn_LSOA_2001['total_pop'] = (blackburn_LSOA_2001['white'] + blackburn_LSOA_2001['asian'] +\n",
    "                                    blackburn_LSOA_2001['black'] + blackburn_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_LSOA_2001[f'{ethnicity}_fraction'] = round(blackburn_LSOA_2001[ethnicity]/blackburn_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in blackburn_LSOA_2001['LSOACD']:\n",
    "    df = blackburn_LSOA_2001[blackburn_LSOA_2001['LSOACD']== LSOA]\n",
    "    blackburn_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(blackburn_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "blackburn_LSOA_2001 = blackburn_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "oldham_LSOA_2001['total_pop'] = (oldham_LSOA_2001['white'] + oldham_LSOA_2001['asian'] +\n",
    "                                 oldham_LSOA_2001['black'] + oldham_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_LSOA_2001[f'{ethnicity}_fraction'] = round(oldham_LSOA_2001[ethnicity]/oldham_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in oldham_LSOA_2001['LSOACD']:\n",
    "    df = oldham_LSOA_2001[oldham_LSOA_2001['LSOACD']== LSOA]\n",
    "    oldham_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(oldham_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "oldham_LSOA_2001 = oldham_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "pendle_LSOA_2001['total_pop'] = (pendle_LSOA_2001['white'] + pendle_LSOA_2001['asian'] +\n",
    "                                 pendle_LSOA_2001['black'] + pendle_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_LSOA_2001[f'{ethnicity}_fraction'] =  round(pendle_LSOA_2001[ethnicity]/pendle_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in pendle_LSOA_2001['LSOACD']:\n",
    "    df = pendle_LSOA_2001[pendle_LSOA_2001['LSOACD']== LSOA]\n",
    "    pendle_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(pendle_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "pendle_LSOA_2001 = pendle_LSOA_2001[col_order]\n",
    "\n",
    "# Creating LSOA_simpson and fraction column\n",
    "london_LSOA_2001['total_pop'] = (london_LSOA_2001['white'] + london_LSOA_2001['asian'] +\n",
    "                                     london_LSOA_2001['black'] + london_LSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_LSOA_2001[f'{ethnicity}_fraction'] = round(london_LSOA_2001[ethnicity]/london_LSOA_2001['total_pop'],3)\n",
    "LSOA_simpson = []\n",
    "for LSOA in london_LSOA_2001['LSOACD']:\n",
    "    df = london_LSOA_2001[london_LSOA_2001['LSOACD']== LSOA]\n",
    "    london_LSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LSOA_simpson.append(london_LSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_LSOA_2001['LSOA_simpson']= LSOA_simpson\n",
    "col_order = ['year', 'LSOACD','LADNM', 'LSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_LSOA_2001 = london_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSOA_2001 = gpd.read_file('preprocessed files/2001/MSOA_2001.shp')\n",
    "MSOA_2011 = gpd.read_file('preprocessed files/2011/MSOA_2011.shp')\n",
    "MSOA_2021 = gpd.read_file('preprocessed files/2021/MSOA_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatin city MSOA datasets\n",
    "birmingham_MSOA_2001 = birmingham_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "birmingham_MSOA_2001['geometry'] = birmingham_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(birmingham_MSOA_2001['geometry'])\n",
    "birmingham_MSOA_2001['geometry'] = birmingham_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(birmingham_MSOA_2001['geometry'])\n",
    "birmingham_MSOA_2001= birmingham_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "leicester_MSOA_2001 = leicester_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "leicester_MSOA_2001['geometry'] = leicester_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(leicester_MSOA_2001['geometry'])\n",
    "leicester_MSOA_2001['geometry'] = leicester_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(leicester_MSOA_2001['geometry'])\n",
    "leicester_MSOA_2001= leicester_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "bradford_MSOA_2001 = bradford_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "bradford_MSOA_2001['geometry'] = bradford_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(bradford_MSOA_2001['geometry'])\n",
    "bradford_MSOA_2001['geometry'] = bradford_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(bradford_MSOA_2001['geometry'])\n",
    "bradford_MSOA_2001= bradford_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "blackburn_MSOA_2001 = blackburn_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "blackburn_MSOA_2001['geometry'] = blackburn_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(blackburn_MSOA_2001['geometry'])\n",
    "blackburn_MSOA_2001['geometry'] = blackburn_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(blackburn_MSOA_2001['geometry'])\n",
    "blackburn_MSOA_2001= blackburn_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "oldham_MSOA_2001 = oldham_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "oldham_MSOA_2001['geometry'] = oldham_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(oldham_MSOA_2001['geometry'])\n",
    "oldham_MSOA_2001['geometry'] = oldham_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(oldham_MSOA_2001['geometry'])\n",
    "oldham_MSOA_2001= oldham_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "pendle_MSOA_2001 = pendle_2001.groupby(['MSOACD','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "pendle_MSOA_2001['geometry'] = pendle_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(pendle_MSOA_2001['geometry'])\n",
    "pendle_MSOA_2001['geometry'] = pendle_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(pendle_MSOA_2001['geometry'])\n",
    "pendle_MSOA_2001= pendle_MSOA_2001.set_geometry('geometry')\n",
    "\n",
    "london_MSOA_2001 = london_2001.groupby(['MSOACD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(MSOA_2021[['MSOACD','geometry']], on='MSOACD', how= 'left')\n",
    "london_MSOA_2001['geometry'] = london_MSOA_2001['MSOACD'].map(MSOA_2011.set_index('MSOACD')['geometry']).fillna(london_MSOA_2001['geometry'])\n",
    "london_MSOA_2001['geometry'] = london_MSOA_2001['MSOACD'].map(MSOA_2001.set_index('MSOACD')['geometry']).fillna(london_MSOA_2001['geometry'])\n",
    "london_MSOA_2001= london_MSOA_2001.set_geometry('geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['year', 'MSOACD', 'MSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "birmingham_MSOA_2001['total_pop'] = (birmingham_MSOA_2001['white'] + birmingham_MSOA_2001['asian'] +\n",
    "                                     birmingham_MSOA_2001['black'] + birmingham_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    birmingham_MSOA_2001[f'{ethnicity}_fraction'] = round(birmingham_MSOA_2001[ethnicity]/birmingham_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in birmingham_MSOA_2001['MSOACD']:\n",
    "    df = birmingham_MSOA_2001[birmingham_MSOA_2001['MSOACD']== MSOA]\n",
    "    birmingham_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(birmingham_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "birmingham_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "birmingham_MSOA_2001 = birmingham_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "leicester_MSOA_2001['total_pop'] = (leicester_MSOA_2001['white'] + leicester_MSOA_2001['asian'] +\n",
    "                                    leicester_MSOA_2001['black'] + leicester_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    leicester_MSOA_2001[f'{ethnicity}_fraction'] = round(leicester_MSOA_2001[ethnicity]/leicester_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in leicester_MSOA_2001['MSOACD']:\n",
    "    df = leicester_MSOA_2001[leicester_MSOA_2001['MSOACD']== MSOA]\n",
    "    leicester_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(leicester_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "leicester_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "leicester_MSOA_2001 = leicester_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "bradford_MSOA_2001['total_pop'] = (bradford_MSOA_2001['white'] + bradford_MSOA_2001['asian'] +\n",
    "                                   bradford_MSOA_2001['black'] + bradford_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    bradford_MSOA_2001[f'{ethnicity}_fraction'] = round(bradford_MSOA_2001[ethnicity]/bradford_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in bradford_MSOA_2001['MSOACD']:\n",
    "    df = bradford_MSOA_2001[bradford_MSOA_2001['MSOACD']== MSOA]\n",
    "    bradford_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(bradford_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "bradford_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "bradford_MSOA_2001 = bradford_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "blackburn_MSOA_2001['total_pop'] = (blackburn_MSOA_2001['white'] + blackburn_MSOA_2001['asian'] +\n",
    "                                    blackburn_MSOA_2001['black'] + blackburn_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    blackburn_MSOA_2001[f'{ethnicity}_fraction'] = round(blackburn_MSOA_2001[ethnicity]/blackburn_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in blackburn_MSOA_2001['MSOACD']:\n",
    "    df = blackburn_MSOA_2001[blackburn_MSOA_2001['MSOACD']== MSOA]\n",
    "    blackburn_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(blackburn_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "blackburn_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "blackburn_MSOA_2001 = blackburn_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "oldham_MSOA_2001['total_pop'] = (oldham_MSOA_2001['white'] + oldham_MSOA_2001['asian'] +\n",
    "                                 oldham_MSOA_2001['black'] + oldham_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    oldham_MSOA_2001[f'{ethnicity}_fraction'] = round(oldham_MSOA_2001[ethnicity]/oldham_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in oldham_MSOA_2001['MSOACD']:\n",
    "    df = oldham_MSOA_2001[oldham_MSOA_2001['MSOACD']== MSOA]\n",
    "    oldham_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(oldham_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "oldham_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "oldham_MSOA_2001 = oldham_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "pendle_MSOA_2001['total_pop'] = (pendle_MSOA_2001['white'] + pendle_MSOA_2001['asian'] +\n",
    "                                 pendle_MSOA_2001['black'] + pendle_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    pendle_MSOA_2001[f'{ethnicity}_fraction'] = round(pendle_MSOA_2001[ethnicity]/pendle_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in pendle_MSOA_2001['MSOACD']:\n",
    "    df = pendle_MSOA_2001[pendle_MSOA_2001['MSOACD']== MSOA]\n",
    "    pendle_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(pendle_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "pendle_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "pendle_MSOA_2001 = pendle_MSOA_2001[col_order]\n",
    "\n",
    "# Creating LMSOA_simpson and fraction column\n",
    "london_MSOA_2001['total_pop'] = (london_MSOA_2001['white'] + london_MSOA_2001['asian'] +\n",
    "                                 london_MSOA_2001['black'] + london_MSOA_2001['other'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_MSOA_2001[f'{ethnicity}_fraction'] = round(london_MSOA_2001[ethnicity]/london_MSOA_2001['total_pop'],3)\n",
    "MSOA_simpson = []\n",
    "for MSOA in london_MSOA_2001['MSOACD']:\n",
    "    df = london_MSOA_2001[london_MSOA_2001['MSOACD']== MSOA]\n",
    "    london_MSOA_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    MSOA_simpson.append(london_MSOA_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_MSOA_2001['MSOA_simpson']= MSOA_simpson\n",
    "col_order = ['year', 'MSOACD','LADNM', 'MSOA_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_MSOA_2001 = london_MSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAD_2001 = gpd.read_file('preprocessed files/2001/LAD_2001.shp')\n",
    "LAD_2011 = gpd.read_file('preprocessed files/2011/LAD_2011.shp')\n",
    "LAD_2021 = gpd.read_file('preprocessed files/2021/LAD_2021.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_LAD_2001 = london_2001.groupby(['LADCD','LADNM','year'])[['white','asian','black','other']].sum().reset_index().merge(LAD_2021[['LADCD','geometry']], on='LADCD', how= 'left')\n",
    "london_LAD_2001['geometry'] = london_LAD_2001['LADCD'].map(LAD_2011.set_index('LADCD')['geometry']).fillna(london_LAD_2001['geometry'])\n",
    "london_LAD_2001['geometry'] = london_LAD_2001['LADCD'].map(LAD_2021.set_index('LADCD')['geometry']).fillna(london_LAD_2001['geometry'])\n",
    "london_LAD_2001= london_LAD_2001.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LAD_simpson and fraction column\n",
    "london_LAD_2001['total_pop'] = (london_LAD_2001['white'] + london_LAD_2001['asian'] +\n",
    "                                london_LAD_2001['black'] + london_LAD_2001['other'])\n",
    "# Creating LAD_simpson and fraction column\n",
    "for ethnicity in ethnicity_list:\n",
    "    london_LAD_2001[f'{ethnicity}_fraction'] = round(london_LAD_2001[ethnicity]/london_LAD_2001['total_pop'],3)\n",
    "LAD_simpson = []\n",
    "for LAD in london_LAD_2001['LADCD']:\n",
    "    df = london_LAD_2001[london_LAD_2001['LADCD']== LAD]\n",
    "    london_LAD_simpson = simpson(df[['white','asian','black','other']].reset_index(drop= True))\n",
    "    LAD_simpson.append(london_LAD_simpson[0])\n",
    "\n",
    "# Reordering the columns\n",
    "london_LAD_2001['LAD_simpson']= LAD_simpson\n",
    "col_order = ['year', 'LADCD','LADNM', 'LAD_simpson',\n",
    "             'white', 'asian', 'black', 'other', 'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction', 'other_fraction', 'geometry']\n",
    "london_LAD_2001 = london_LAD_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birmingham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Birmingham\n",
    "# birmingham_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in birmingham_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in birmingham_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     birmingham_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/birmingham_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(birmingham_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Birmingham\n",
    "birmingham_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in birmingham_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in birmingham_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    birmingham_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/birmingham_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Birmingham\n",
    "birmingham_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in birmingham_2001['LSOACD'].unique():\n",
    "    lsoa_df = birmingham_2001[birmingham_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    birmingham_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/birmingham_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Birmingham\n",
    "birmingham_LSOA_OA_moran = {}\n",
    "for lsoa in birmingham_2001['LSOACD'].unique():\n",
    "    lsoa_df = birmingham_2001[birmingham_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),birmingham_LSOA_OA_borders_2001[lsoa])\n",
    "    birmingham_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in birmingham_LSOA_OA_moran.items()]\n",
    "\n",
    "birmingham_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_LSOA_2001 = birmingham_LSOA_2001.merge(birmingham_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "birmingham_LSOA_2001=birmingham_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Birmingham\n",
    "birmingham_MSOA_OA_borders_2001 = {}\n",
    "for msoa in birmingham_2001['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2001[birmingham_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    birmingham_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/birmingham_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Birmingham\n",
    "birmingham_MSOA_LSOA = pd.merge(birmingham_LSOA_2001,birmingham_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "birmingham_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in birmingham_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = birmingham_MSOA_LSOA[birmingham_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    birmingham_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/birmingham_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(birmingham_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MSOA_OA based moran- Birmingham\n",
    "birmingham_MSOA_OA_moran = {}\n",
    "for msoa in birmingham_2001['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2001[birmingham_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),birmingham_MSOA_OA_borders_2001[msoa])\n",
    "    birmingham_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in birmingham_MSOA_OA_moran.items()]\n",
    "\n",
    "birmingham_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_MSOA_2001 = birmingham_MSOA_2001.merge(birmingham_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Birmingham\n",
    "birmingham_MSOA_LSOA_moran = {}\n",
    "for msoa in birmingham_2001['MSOACD'].unique():\n",
    "    msoa_df = birmingham_2001[birmingham_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,birmingham_MSOA_LSOA_borders_2001[msoa])\n",
    "    birmingham_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in birmingham_MSOA_LSOA_moran.items()]\n",
    "\n",
    "birmingham_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "birmingham_MSOA_2001 = birmingham_MSOA_2001.merge(birmingham_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "birmingham_MSOA_2001=birmingham_MSOA_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leicester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Leicester\n",
    "# leicester_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in leicester_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in leicester_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     leicester_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/leicester_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(leicester_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Leicester\n",
    "leicester_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in leicester_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in leicester_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    leicester_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/leicester_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Leicester\n",
    "leicester_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in leicester_2001['LSOACD'].unique():\n",
    "    lsoa_df = leicester_2001[leicester_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    leicester_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/leicester_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Leicester\n",
    "leicester_LSOA_OA_moran = {}\n",
    "for lsoa in leicester_2001['LSOACD'].unique():\n",
    "    lsoa_df = leicester_2001[leicester_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),leicester_LSOA_OA_borders_2001[lsoa])\n",
    "    leicester_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in leicester_LSOA_OA_moran.items()]\n",
    "\n",
    "leicester_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_LSOA_2001 = leicester_LSOA_2001.merge(leicester_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "leicester_LSOA_2001=leicester_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Leicester\n",
    "leicester_MSOA_OA_borders_2001 = {}\n",
    "for msoa in leicester_2001['MSOACD'].unique():\n",
    "    msoa_df = leicester_2001[leicester_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    leicester_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/leicester_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Leicester\n",
    "leicester_MSOA_LSOA = pd.merge(leicester_LSOA_2001,leicester_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "leicester_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in leicester_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = leicester_MSOA_LSOA[leicester_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    leicester_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/leicester_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(leicester_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Leicester\n",
    "leicester_MSOA_OA_moran = {}\n",
    "for msoa in leicester_2001['MSOACD'].unique():\n",
    "    msoa_df = leicester_2001[leicester_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),leicester_MSOA_OA_borders_2001[msoa])\n",
    "    leicester_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in leicester_MSOA_OA_moran.items()]\n",
    "\n",
    "leicester_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_MSOA_2001 = leicester_MSOA_2001.merge(leicester_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Leicester\n",
    "leicester_MSOA_LSOA_moran = {}\n",
    "for msoa in leicester_2001['MSOACD'].unique():\n",
    "    msoa_df = leicester_2001[leicester_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,leicester_MSOA_LSOA_borders_2001[msoa])\n",
    "    leicester_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in leicester_MSOA_LSOA_moran.items()]\n",
    "\n",
    "leicester_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "leicester_MSOA_2001 = leicester_MSOA_2001.merge(leicester_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "leicester_MSOA_2001=leicester_MSOA_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bradford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Bradford\n",
    "# bradford_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in bradford_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in bradford_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     bradford_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/bradford_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(bradford_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Bradford\n",
    "bradford_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in bradford_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in bradford_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    bradford_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/bradford_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Bradford\n",
    "bradford_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in bradford_2001['LSOACD'].unique():\n",
    "    lsoa_df = bradford_2001[bradford_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    bradford_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/bradford_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Bradford\n",
    "bradford_LSOA_OA_moran = {}\n",
    "for lsoa in bradford_2001['LSOACD'].unique():\n",
    "    lsoa_df = bradford_2001[bradford_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),bradford_LSOA_OA_borders_2001[lsoa])\n",
    "    bradford_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in bradford_LSOA_OA_moran.items()]\n",
    "\n",
    "bradford_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_LSOA_2001 = bradford_LSOA_2001.merge(bradford_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "bradford_LSOA_2001=bradford_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Bradford\n",
    "bradford_MSOA_OA_borders_2001 = {}\n",
    "for msoa in bradford_2001['MSOACD'].unique():\n",
    "    msoa_df = bradford_2001[bradford_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    bradford_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/bradford_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Bradford\n",
    "bradford_MSOA_LSOA = pd.merge(bradford_LSOA_2001,bradford_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "bradford_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in bradford_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = bradford_MSOA_LSOA[bradford_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    bradford_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/bradford_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(bradford_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Bradford\n",
    "bradford_MSOA_OA_moran = {}\n",
    "for msoa in bradford_2001['MSOACD'].unique():\n",
    "    msoa_df = bradford_2001[bradford_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),bradford_MSOA_OA_borders_2001[msoa])\n",
    "    bradford_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in bradford_MSOA_OA_moran.items()]\n",
    "\n",
    "bradford_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_MSOA_2001 = bradford_MSOA_2001.merge(bradford_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Bradford\n",
    "bradford_MSOA_LSOA_moran = {}\n",
    "for msoa in bradford_2001['MSOACD'].unique():\n",
    "    msoa_df = bradford_2001[bradford_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,bradford_MSOA_LSOA_borders_2001[msoa])\n",
    "    bradford_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in bradford_MSOA_LSOA_moran.items()]\n",
    "\n",
    "bradford_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "bradford_MSOA_2001 = bradford_MSOA_2001.merge(bradford_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "bradford_MSOA_2001=bradford_MSOA_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackburn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Blackburn\n",
    "# blackburn_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in blackburn_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in blackburn_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     blackburn_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/blackburn_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(blackburn_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Blackburn\n",
    "blackburn_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in blackburn_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in blackburn_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    blackburn_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/blackburn_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Blackburn\n",
    "blackburn_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in blackburn_2001['LSOACD'].unique():\n",
    "    lsoa_df = blackburn_2001[blackburn_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    blackburn_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/blackburn_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Blackburn\n",
    "blackburn_LSOA_OA_moran = {}\n",
    "for lsoa in blackburn_2001['LSOACD'].unique():\n",
    "    lsoa_df = blackburn_2001[blackburn_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),blackburn_LSOA_OA_borders_2001[lsoa])\n",
    "    blackburn_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in blackburn_LSOA_OA_moran.items()]\n",
    "\n",
    "blackburn_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_LSOA_2001 = blackburn_LSOA_2001.merge(blackburn_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "blackburn_LSOA_2001=blackburn_LSOA_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Blackburn\n",
    "blackburn_MSOA_OA_borders_2001 = {}\n",
    "for msoa in blackburn_2001['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2001[blackburn_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    blackburn_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/blackburn_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Blackburn\n",
    "blackburn_MSOA_LSOA = pd.merge(blackburn_LSOA_2001,blackburn_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "blackburn_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in blackburn_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = blackburn_MSOA_LSOA[blackburn_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    blackburn_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/blackburn_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(blackburn_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# MSOA_OA based moran- Blackburn\n",
    "blackburn_MSOA_OA_moran = {}\n",
    "for msoa in blackburn_2001['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2001[blackburn_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),blackburn_MSOA_OA_borders_2001[msoa])\n",
    "    blackburn_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in blackburn_MSOA_OA_moran.items()]\n",
    "\n",
    "blackburn_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_MSOA_2001 = blackburn_MSOA_2001.merge(blackburn_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# MSOA_LSOA based moran- Blackburn\n",
    "blackburn_MSOA_LSOA_moran = {}\n",
    "for msoa in blackburn_2001['MSOACD'].unique():\n",
    "    msoa_df = blackburn_2001[blackburn_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,blackburn_MSOA_LSOA_borders_2001[msoa])\n",
    "    blackburn_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in blackburn_MSOA_LSOA_moran.items()]\n",
    "\n",
    "blackburn_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "blackburn_MSOA_2001 = blackburn_MSOA_2001.merge(blackburn_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "blackburn_MSOA_2001=blackburn_MSOA_2001[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oldham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Oldham\n",
    "# oldham_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in oldham_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in oldham_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     oldham_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/oldham_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(oldham_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Oldham\n",
    "oldham_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in oldham_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in oldham_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    oldham_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/oldham_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Oldham\n",
    "oldham_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in oldham_2001['LSOACD'].unique():\n",
    "    lsoa_df = oldham_2001[oldham_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    oldham_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/oldham_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Oldham\n",
    "oldham_LSOA_OA_moran = {}\n",
    "for lsoa in oldham_2001['LSOACD'].unique():\n",
    "    lsoa_df = oldham_2001[oldham_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),oldham_LSOA_OA_borders_2001[lsoa])\n",
    "    oldham_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in oldham_LSOA_OA_moran.items()]\n",
    "\n",
    "oldham_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_LSOA_2001 = oldham_LSOA_2001.merge(oldham_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "oldham_LSOA_2001=oldham_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Oldham\n",
    "oldham_MSOA_OA_borders_2001 = {}\n",
    "for msoa in oldham_2001['MSOACD'].unique():\n",
    "    msoa_df = oldham_2001[oldham_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    oldham_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/oldham_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Oldham\n",
    "oldham_MSOA_LSOA = pd.merge(oldham_LSOA_2001,oldham_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "oldham_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in oldham_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = oldham_MSOA_LSOA[oldham_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    oldham_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/oldham_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(oldham_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- Oldham\n",
    "oldham_MSOA_OA_moran = {}\n",
    "for msoa in oldham_2001['MSOACD'].unique():\n",
    "    msoa_df = oldham_2001[oldham_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),oldham_MSOA_OA_borders_2001[msoa])\n",
    "    oldham_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in oldham_MSOA_OA_moran.items()]\n",
    "\n",
    "oldham_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_MSOA_2001 = oldham_MSOA_2001.merge(oldham_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- Oldham\n",
    "oldham_MSOA_LSOA_moran = {}\n",
    "for msoa in oldham_2001['MSOACD'].unique():\n",
    "    msoa_df = oldham_2001[oldham_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,oldham_MSOA_LSOA_borders_2001[msoa])\n",
    "    oldham_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in oldham_MSOA_LSOA_moran.items()]\n",
    "\n",
    "oldham_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "oldham_MSOA_2001 = oldham_MSOA_2001.merge(oldham_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "oldham_MSOA_2001=oldham_MSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- Pendle\n",
    "# pendle_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in pendle_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in pendle_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     pendle_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/pendle_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(pendle_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- Pendle\n",
    "pendle_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in pendle_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in pendle_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    pendle_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/pendle_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- Pendle\n",
    "pendle_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in pendle_2001['LSOACD'].unique():\n",
    "    lsoa_df = pendle_2001[pendle_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    pendle_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/pendle_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_LSOA_OA_borders_2001, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- Pendle\n",
    "pendle_LSOA_OA_moran = {}\n",
    "for lsoa in pendle_2001['LSOACD'].unique():\n",
    "    lsoa_df = pendle_2001[pendle_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),pendle_LSOA_OA_borders_2001[lsoa])\n",
    "    pendle_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in pendle_LSOA_OA_moran.items()]\n",
    "\n",
    "pendle_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_LSOA_2001 = pendle_LSOA_2001.merge(pendle_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "pendle_LSOA_2001=pendle_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- Pendle\n",
    "pendle_MSOA_OA_borders_2001 = {}\n",
    "for msoa in pendle_2001['MSOACD'].unique():\n",
    "    msoa_df = pendle_2001[pendle_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    pendle_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/pendle_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_MSOA_OA_borders_2001, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- Pendle\n",
    "pendle_MSOA_LSOA = pd.merge(pendle_LSOA_2001,pendle_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "pendle_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in pendle_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = pendle_MSOA_LSOA[pendle_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    pendle_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/pendle_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(pendle_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# MSOA_OA based moran- Pendle\n",
    "pendle_MSOA_OA_moran = {}\n",
    "for msoa in pendle_2001['MSOACD'].unique():\n",
    "    msoa_df = pendle_2001[pendle_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),pendle_MSOA_OA_borders_2001[msoa])\n",
    "    pendle_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in pendle_MSOA_OA_moran.items()]\n",
    "\n",
    "pendle_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_MSOA_2001 = pendle_MSOA_2001.merge(pendle_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- Pendle\n",
    "pendle_MSOA_LSOA_moran = {}\n",
    "for msoa in pendle_2001['MSOACD'].unique():\n",
    "    msoa_df = pendle_2001[pendle_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,pendle_MSOA_LSOA_borders_2001[msoa])\n",
    "    pendle_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in pendle_MSOA_LSOA_moran.items()]\n",
    "\n",
    "pendle_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "pendle_MSOA_2001 = pendle_MSOA_2001.merge(pendle_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "pendle_MSOA_2001=pendle_MSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating shared border dictionary at OA level- London\n",
    "# london_OA_borders_2001 = {}\n",
    "\n",
    "# for idx1, row1 in london_2001.set_index('OACD').iterrows():\n",
    "#     borders = []\n",
    "#     for idx2, row2 in london_2001.set_index('OACD').iterrows():\n",
    "#         if idx1 != idx2:\n",
    "#             if row1.geometry.intersects(row2.geometry):\n",
    "#                 borders.append(idx2)\n",
    "#     london_OA_borders_2001[idx1] = borders\n",
    "    \n",
    "# with open('preprocessed files/2001/london_OA_borders_2001.pkl', 'wb') as f:\n",
    "#     pickle.dump(london_OA_borders_2001, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA level- London\n",
    "london_LSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in london_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in london_LSOA_2001.set_index('LSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    london_LSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/london_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(london_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at LSOA_OA level- London\n",
    "london_LSOA_OA_borders_2001 = {}\n",
    "for lsoa in london_2001['LSOACD'].unique():\n",
    "    lsoa_df = london_2001[london_2001['LSOACD'] == lsoa]\n",
    "    oa_borders = {}\n",
    "    for idx1, row1 in lsoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in lsoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        oa_borders[idx1] = borders\n",
    "    london_LSOA_OA_borders_2001[lsoa] = oa_borders\n",
    "with open('preprocessed files/2001/london_LSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(london_LSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n",
      "C:\\Users\\niloo\\AppData\\Local\\Temp\\ipykernel_21240\\1030671252.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  moran_results[col] = round(moran_numerator/moran_denominator, 3)\n"
     ]
    }
   ],
   "source": [
    "# Adding moran index to the city LSOA dataset- London\n",
    "london_LSOA_OA_moran = {}\n",
    "for lsoa in london_2001['LSOACD'].unique():\n",
    "    lsoa_df = london_2001[london_2001['LSOACD'] == lsoa]\n",
    "    OA_moran = moran(lsoa_df[['OACD','white','asian','black','other']].set_index('OACD'),london_LSOA_OA_borders_2001[lsoa])\n",
    "    london_LSOA_OA_moran[lsoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'LSOACD': key,\n",
    "              'white_moran': value['OA_moran']['white'],\n",
    "              'asian_moran': value['OA_moran']['asian'], \n",
    "              'black_moran': value['OA_moran']['black'],\n",
    "              'other_moran': value['OA_moran']['other'], \n",
    "              } for key, value in london_LSOA_OA_moran.items()]\n",
    "\n",
    "london_LSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_LSOA_2001 = london_LSOA_2001.merge(london_LSOA_OA_moran_2001[['LSOACD','white_moran','asian_moran']], \n",
    "                                                  on= 'LSOACD', how= 'left')\n",
    "col_order = ['year', 'LSOACD', 'LSOA_simpson','white_moran', 'asian_moran', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "london_LSOA_2001=london_LSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA level- London\n",
    "london_MSOA_borders_2001 = {}\n",
    "\n",
    "for idx1, row1 in london_MSOA_2001.set_index('MSOACD').iterrows():\n",
    "    borders = []\n",
    "    for idx2, row2 in london_MSOA_2001.set_index('MSOACD').iterrows():\n",
    "        if idx1 != idx2:\n",
    "            if row1.geometry.intersects(row2.geometry):\n",
    "                borders.append(idx2)\n",
    "    london_MSOA_borders_2001[idx1] = borders\n",
    "\n",
    "with open('preprocessed files/2001/london_MSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_OA level- London\n",
    "london_MSOA_OA_borders_2001 = {}\n",
    "for msoa in london_2001['MSOACD'].unique():\n",
    "    msoa_df = london_2001[london_2001['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('OACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('OACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    london_MSOA_OA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/london_MSOA_OA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_OA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating shared border dictionary at MSOA_LSOA level- London\n",
    "london_MSOA_LSOA = pd.merge(london_LSOA_2001,london_2001.groupby('LSOACD').agg({'MSOACD': 'first'}).reset_index(), on = 'LSOACD', how = 'left')\n",
    "london_MSOA_LSOA_borders_2001 = {}\n",
    "for msoa in london_MSOA_LSOA['MSOACD'].unique():\n",
    "    msoa_df = london_MSOA_LSOA[london_MSOA_LSOA['MSOACD'] == msoa]\n",
    "    lsoa_borders = {}\n",
    "    for idx1, row1 in msoa_df.set_index('LSOACD').iterrows():\n",
    "        borders = []\n",
    "        for idx2, row2 in msoa_df.set_index('LSOACD').iterrows():\n",
    "            if idx1 != idx2:\n",
    "                if row1.geometry.intersects(row2.geometry):\n",
    "                    borders.append(idx2)\n",
    "        lsoa_borders[idx1] = borders\n",
    "    london_MSOA_LSOA_borders_2001[msoa] = lsoa_borders\n",
    "with open('preprocessed files/2001/london_MSOA_LSOA_borders_2001.pkl', 'wb') as f:\n",
    "    pickle.dump(london_MSOA_LSOA_borders_2001, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSOA_OA based moran- London\n",
    "london_MSOA_OA_moran = {}\n",
    "for msoa in london_2001['MSOACD'].unique():\n",
    "    msoa_df = london_2001[london_2001['MSOACD'] == msoa]\n",
    "    OA_moran = moran(msoa_df[['OACD','white','asian','black','other']].set_index('OACD'),london_MSOA_OA_borders_2001[msoa])\n",
    "    london_MSOA_OA_moran[msoa] = {'OA_moran':OA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_OA': value['OA_moran']['white'],\n",
    "              'asian_moran_OA': value['OA_moran']['asian'], \n",
    "              'black_moran_OA': value['OA_moran']['black'],\n",
    "              'other_moran_OA': value['OA_moran']['other'], \n",
    "              } for key, value in london_MSOA_OA_moran.items()]\n",
    "\n",
    "london_MSOA_OA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_MSOA_2001 = london_MSOA_2001.merge(london_MSOA_OA_moran_2001[['MSOACD','white_moran_OA','asian_moran_OA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# MSOA_LSOA based moran- London\n",
    "london_MSOA_LSOA_moran = {}\n",
    "for msoa in london_2001['MSOACD'].unique():\n",
    "    msoa_df = london_2001[london_2001['MSOACD'] == msoa]\n",
    "    msoa_df = msoa_df.groupby('LSOACD')[['white','asian','black','other']].sum().reset_index().set_index('LSOACD')\n",
    "    LSOA_moran = moran(msoa_df,london_MSOA_LSOA_borders_2001[msoa])\n",
    "    london_MSOA_LSOA_moran[msoa] = {'LSOA_moran':LSOA_moran}\n",
    "\n",
    "flat_dict = [{'MSOACD': key,\n",
    "              'white_moran_LSOA': value['LSOA_moran']['white'],\n",
    "              'asian_moran_LSOA': value['LSOA_moran']['asian'], \n",
    "              'black_moran_LSOA': value['LSOA_moran']['black'],\n",
    "              'other_moran_LSOA': value['LSOA_moran']['other'], \n",
    "              } for key, value in london_MSOA_LSOA_moran.items()]\n",
    "\n",
    "london_MSOA_LSOA_moran_2001 = pd.DataFrame(flat_dict)\n",
    "\n",
    "london_MSOA_2001 = london_MSOA_2001.merge(london_MSOA_LSOA_moran_2001[['MSOACD','white_moran_LSOA','asian_moran_LSOA']], \n",
    "                                                  on= 'MSOACD', how= 'left')\n",
    "\n",
    "# Reordering the columns\n",
    "col_order = ['year', 'MSOACD', 'MSOA_simpson','white_moran_OA', 'asian_moran_OA', 'white_moran_LSOA', 'asian_moran_LSOA', 'white', 'asian', 'black', 'other',\n",
    "       'total_pop', 'white_fraction', 'asian_fraction', 'black_fraction',\n",
    "       'other_fraction', 'geometry']\n",
    "\n",
    "london_MSOA_2001=london_MSOA_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white_frac</th>\n",
       "      <th>asian_frac</th>\n",
       "      <th>black_frac</th>\n",
       "      <th>other_frac</th>\n",
       "      <th>OA_simpson</th>\n",
       "      <th>LSOA_simpson</th>\n",
       "      <th>MSOA_simpson</th>\n",
       "      <th>LAD_simpson</th>\n",
       "      <th>London_simpson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>7171998</td>\n",
       "      <td>5103176</td>\n",
       "      <td>1059689</td>\n",
       "      <td>782851</td>\n",
       "      <td>226282</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  total_population    white    asian   black   other  white_frac  \\\n",
       "0  2001           7171998  5103176  1059689  782851  226282       0.712   \n",
       "\n",
       "   asian_frac  black_frac  other_frac  OA_simpson  LSOA_simpson  MSOA_simpson  \\\n",
       "0       0.148       0.109       0.032       0.618         0.609         0.602   \n",
       "\n",
       "   LAD_simpson  London_simpson  \n",
       "0        0.574            0.54  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating simpson dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA, MSOA and LAD level simpson index inside London\n",
    "OA_simp_london_2001 = simpson(london_2001[['white','asian','black','other']])\n",
    "LSOA_simp_london_2001 = simpson(london_2001.groupby(['LSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_simp_london_2001 = simpson(london_2001.groupby(['MSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_simp_london_2001 = simpson(london_2001.groupby(['LADCD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "\n",
    "country_dic_sim_2001 = {'OA_simpson':OA_simp_london_2001[0], 'LSOA_simpson':LSOA_simp_london_2001[0],\n",
    "                        'MSOA_simpson':MSOA_simp_london_2001[0], 'LAD_simpson':LAD_simp_london_2001[0], 'london':LAD_simp_london_2001[1]}\n",
    "\n",
    "flat_dict = [{'year': 2001, 'total_population': london_2001['total_pop'].sum(),\n",
    "              'white': london_2001['white'].sum(),\n",
    "              'asian': london_2001['asian'].sum(),\n",
    "              'black': london_2001['black'].sum(),\n",
    "              'other': london_2001['other'].sum(),              \n",
    "              'white_frac': round(london_2001['white'].sum()/london_2001['total_pop'].sum(),3),\n",
    "              'asian_frac': round(london_2001['asian'].sum()/london_2001['total_pop'].sum(),3),\n",
    "              'black_frac': round(london_2001['black'].sum()/london_2001['total_pop'].sum(),3),\n",
    "              'other_frac': round(london_2001['other'].sum()/london_2001['total_pop'].sum(),3),\n",
    "              'OA_simpson':OA_simp_london_2001[0], 'LSOA_simpson':LSOA_simp_london_2001[0],'MSOA_simpson':MSOA_simp_london_2001[0], \n",
    "              'LAD_simpson':LAD_simp_london_2001[0], 'London_simpson':LAD_simp_london_2001[1]}]\n",
    "\n",
    "london_simpson_2001 = pd.DataFrame(flat_dict)\n",
    "london_simpson_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>OA_white_diss</th>\n",
       "      <th>LSOA_white_diss</th>\n",
       "      <th>MSOA_white_diss</th>\n",
       "      <th>LAD_white_diss</th>\n",
       "      <th>OA_asian_diss</th>\n",
       "      <th>LSOA_asian_diss</th>\n",
       "      <th>MSOA_asian_diss</th>\n",
       "      <th>LAD_asian_diss</th>\n",
       "      <th>OA_black_diss</th>\n",
       "      <th>LSOA_black_diss</th>\n",
       "      <th>MSOA_black_diss</th>\n",
       "      <th>LAD_black_diss</th>\n",
       "      <th>OA_other_diss</th>\n",
       "      <th>LSOA_other_diss</th>\n",
       "      <th>MSOA_other_diss</th>\n",
       "      <th>LAD_other_diss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  OA_white_diss  LSOA_white_diss  MSOA_white_diss  LAD_white_diss  \\\n",
       "0  2001          0.407            0.382            0.363           0.264   \n",
       "\n",
       "   OA_asian_diss  LSOA_asian_diss  MSOA_asian_diss  LAD_asian_diss  \\\n",
       "0          0.436            0.409            0.394            0.32   \n",
       "\n",
       "   OA_black_diss  LSOA_black_diss  MSOA_black_diss  LAD_black_diss  \\\n",
       "0          0.455            0.427            0.408           0.322   \n",
       "\n",
       "   OA_other_diss  LSOA_other_diss  MSOA_other_diss  LAD_other_diss  \n",
       "0          0.271            0.192            0.165           0.126  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating London dissimilarity index dataset for year 2001.\n",
    "# Calculating OA, LSOA, MSOA and LAD level dissimilarity index inside London\n",
    "\n",
    "OA_diss_london_2001 = dissimilarity(london_2001[['white','asian','black','other']])\n",
    "LSOA_diss_london_2001 = dissimilarity(london_2001.groupby(['LSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "MSOA_diss_london_2001 = dissimilarity(london_2001.groupby(['MSOACD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "LAD_diss_london_2001 = dissimilarity(london_2001.groupby(['LADCD'])[['white','asian','black','other']].sum().reset_index()[['white','asian','black','other']])\n",
    "london_dic_diss_2001 = {'OA_level':OA_diss_london_2001, 'LSOA_level':LSOA_diss_london_2001,\n",
    "                        'MSOA_level':MSOA_diss_london_2001, 'LAD_level':LAD_diss_london_2001}\n",
    "\n",
    "flat_dict = [{'year': 2001,\n",
    "              'OA_white_diss': london_dic_diss_2001['OA_level']['white'], 'LSOA_white_diss': london_dic_diss_2001['LSOA_level']['white'],\n",
    "              'MSOA_white_diss': london_dic_diss_2001['MSOA_level']['white'], 'LAD_white_diss': london_dic_diss_2001['LAD_level']['white'],\n",
    "              'OA_asian_diss': london_dic_diss_2001['OA_level']['asian'], 'LSOA_asian_diss': london_dic_diss_2001['LSOA_level']['asian'],\n",
    "              'MSOA_asian_diss': london_dic_diss_2001['MSOA_level']['asian'], 'LAD_asian_diss': london_dic_diss_2001['LAD_level']['asian'],\n",
    "              'OA_black_diss': london_dic_diss_2001['OA_level']['black'], 'LSOA_black_diss': london_dic_diss_2001['LSOA_level']['black'],\n",
    "              'MSOA_black_diss': london_dic_diss_2001['MSOA_level']['black'], 'LAD_black_diss': london_dic_diss_2001['LAD_level']['black'],\n",
    "              'OA_other_diss': london_dic_diss_2001['OA_level']['other'], 'LSOA_other_diss': london_dic_diss_2001['LSOA_level']['other'],\n",
    "              'MSOA_other_diss': london_dic_diss_2001['MSOA_level']['other'], 'LAD_other_diss': london_dic_diss_2001['LAD_level']['other']}]\n",
    "\n",
    "\n",
    "london_dissimilarity_2001 = pd.DataFrame(flat_dict)\n",
    "london_dissimilarity_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed files/2001/london_OA_borders_2001.pkl', 'rb') as f:\n",
    "    london_OA_borders_2001 = pickle.load(f)\n",
    "with open('preprocessed files/2001/london_LSOA_borders_2001.pkl', 'rb') as f:\n",
    "    london_LSOA_borders_2001 = pickle.load(f)\n",
    "with open('preprocessed files/2001/london_MSOA_borders_2001.pkl', 'rb') as f:\n",
    "    london_MSOA_borders_2001 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_mor_london_2001= {}\n",
    "\n",
    "OA_mor_london_2001 = moran(london_2001[['OACD','white','asian','black','other']].set_index('OACD'),london_OA_borders_2001)\n",
    "LSOA_mor_london_2001 = moran(london_2001.groupby(['LSOACD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],london_LSOA_borders_2001)\n",
    "MSOA_mor_london_2001 = moran(london_2001.groupby(['MSOACD'])[['white','asian','black','other']].sum()[['white','asian','black','other']],london_MSOA_borders_2001)\n",
    "dic_mor_london_2001 = {'OA':OA_mor_london_2001, 'LSOA':LSOA_mor_london_2001, 'MSOA':MSOA_mor_london_2001}\n",
    "\n",
    "flat_dict = {}\n",
    "for level, values in dic_mor_london_2001.items():\n",
    "    for ethnicity, value in values.items():\n",
    "        flat_dict[f\"{level}_{ethnicity}_mor\"] = value\n",
    "\n",
    "london_moran_2001 = pd.DataFrame([flat_dict])\n",
    "london_moran_2001['year']= 2001\n",
    "london_moran_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>other</th>\n",
       "      <th>white_frac</th>\n",
       "      <th>asian_frac</th>\n",
       "      <th>black_frac</th>\n",
       "      <th>other_frac</th>\n",
       "      <th>...</th>\n",
       "      <th>OA_black_mor</th>\n",
       "      <th>OA_other_mor</th>\n",
       "      <th>LSOA_white_mor</th>\n",
       "      <th>LSOA_asian_mor</th>\n",
       "      <th>LSOA_black_mor</th>\n",
       "      <th>LSOA_other_mor</th>\n",
       "      <th>MSOA_white_mor</th>\n",
       "      <th>MSOA_asian_mor</th>\n",
       "      <th>MSOA_black_mor</th>\n",
       "      <th>MSOA_other_mor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>7171998</td>\n",
       "      <td>5103176</td>\n",
       "      <td>1059689</td>\n",
       "      <td>782851</td>\n",
       "      <td>226282</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  total_population    white    asian   black   other  white_frac  \\\n",
       "0  2001           7171998  5103176  1059689  782851  226282       0.712   \n",
       "\n",
       "   asian_frac  black_frac  other_frac  ...  OA_black_mor  OA_other_mor  \\\n",
       "0       0.148       0.109       0.032  ...         0.759         0.318   \n",
       "\n",
       "   LSOA_white_mor  LSOA_asian_mor  LSOA_black_mor  LSOA_other_mor  \\\n",
       "0           0.847           0.856           0.803           0.599   \n",
       "\n",
       "   MSOA_white_mor  MSOA_asian_mor  MSOA_black_mor  MSOA_other_mor  \n",
       "0           0.804           0.804           0.793           0.728  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_indexes_2001 = pd.merge(london_simpson_2001,london_dissimilarity_2001, how='left')\n",
    "london_indexes_2001 = london_indexes_2001.merge(london_moran_2001, how='left')\n",
    "london_indexes_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_indexes_2001['LADCD'] = 'E00000000'\n",
    "london_indexes_2001['LADNM'] = 'London'\n",
    "col_order = ['year', 'LADCD', 'LADNM', 'white', 'asian', 'black', 'other', 'total_population', \n",
    "             'white_frac', 'asian_frac', 'black_frac', 'other_frac', \n",
    "             'OA_simpson', 'LSOA_simpson', 'MSOA_simpson', 'LAD_simpson', 'London_simpson',\n",
    "             'OA_white_diss', 'LSOA_white_diss', 'MSOA_white_diss',\n",
    "             'OA_asian_diss', 'LSOA_asian_diss', 'MSOA_asian_diss', \n",
    "             'OA_black_diss', 'LSOA_black_diss', 'MSOA_black_diss', \n",
    "             'OA_other_diss', 'LSOA_other_diss', 'MSOA_other_diss',\n",
    "             'OA_white_mor', 'LSOA_white_mor','MSOA_white_mor', \n",
    "             'OA_asian_mor', 'LSOA_asian_mor', 'MSOA_asian_mor',\n",
    "             'OA_black_mor', 'LSOA_black_mor', 'MSOA_black_mor', \n",
    "             'OA_other_mor', 'LSOA_other_mor', 'MSOA_other_mor']\n",
    "london_indexes_2001 = london_indexes_2001[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_LSOA_2001.to_csv('preprocessed files/2001/birmingham_LSOA_2001.csv', index= False)\n",
    "leicester_LSOA_2001.to_csv('preprocessed files/2001/leicester_LSOA_2001.csv', index= False)\n",
    "bradford_LSOA_2001.to_csv('preprocessed files/2001/bradford_LSOA_2001.csv', index= False)\n",
    "blackburn_LSOA_2001.to_csv('preprocessed files/2001/blackburn_LSOA_2001.csv', index= False)\n",
    "oldham_LSOA_2001.to_csv('preprocessed files/2001/oldham_LSOA_2001.csv', index= False)\n",
    "pendle_LSOA_2001.to_csv('preprocessed files/2001/pendle_LSOA_2001.csv', index= False)\n",
    "london_LSOA_2001.to_csv('preprocessed files/2001/london_LSOA_2001.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "birmingham_MSOA_2001.to_csv('preprocessed files/2001/birmingham_MSOA_2001.csv', index= False)\n",
    "leicester_MSOA_2001.to_csv('preprocessed files/2001/leicester_MSOA_2001.csv', index= False)\n",
    "bradford_MSOA_2001.to_csv('preprocessed files/2001/bradford_MSOA_2001.csv', index= False)\n",
    "blackburn_MSOA_2001.to_csv('preprocessed files/2001/blackburn_MSOA_2001.csv', index= False)\n",
    "oldham_MSOA_2001.to_csv('preprocessed files/2001/oldham_MSOA_2001.csv', index= False)\n",
    "pendle_MSOA_2001.to_csv('preprocessed files/2001/pendle_MSOA_2001.csv', index= False)\n",
    "london_MSOA_2001.to_csv('preprocessed files/2001/london_MSOA_2001.csv', index= False)\n",
    "london_LAD_2001.to_csv('preprocessed files/2001/london_LAD_2001.csv', index= False)\n",
    "london_indexes_2001.to_csv('preprocessed files/2001/london_indexes_2001.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
